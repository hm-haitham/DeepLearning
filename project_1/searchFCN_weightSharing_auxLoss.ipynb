{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"searchFCN_weightSharing_auxLoss.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fcDggHfSYnOD"},"source":["# DEEP LEARNING PROJECT 1\n","---"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589487427532,"user_tz":-120,"elapsed":1052,"user":{"displayName":"Ben Dhiaf Meryem","photoUrl":"","userId":"04968261287100866991"}},"id":"Pi4WHKYtYnOE","outputId":"3c1007c8-9e9e-4fe6-a5c6-760c9d53d325","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589487427536,"user_tz":-120,"elapsed":1032,"user":{"displayName":"Ben Dhiaf Meryem","photoUrl":"","userId":"04968261287100866991"}},"id":"JP9ut-b0YnOI","outputId":"96644877-aab7-443d-c816-e419426dddb5","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/deep"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/deep\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6TDFGtcvYnOM","colab":{}},"source":["INPUT_SIZE = (2, 14, 14)\n","rounds = 10\n","\n","import torch.nn as nn\n","import numpy as np\n","\n","NB_SAMPLES = 1000\n","DATA_DIR = './data'\n","\n","NUMBER_OF_CLASSES = 10\n","\n","WIDTH_HEIGHT = 14\n","SINGLE_IMAGE_SIZE = WIDTH_HEIGHT * WIDTH_HEIGHT\n","DOUBLE_IMAGE_SIZE = 2 * SINGLE_IMAGE_SIZE\n","\n","# ----Train Config-----#\n","LEARNING_RATE = 0.001\n","TRAIN_BATCH_SIZE = 5\n","SUB_CRITERION = nn.CrossEntropyLoss()\n","FINAL_CRITERION = nn.BCELoss()\n","EPOCHS = 20\n","\n","# ----AuxLoss Config-----#\n","ALPHA = 0.5\n","\n","BEST_ALPHA_O = 0\n","\n","# ----Search Config-----#\n","FCNEURONS = [32,64,128, 256,512]\n","NB_LAYERS = [1, 2]\n","ALPHAS = np.linspace(0, 1, 10)\n","\n","#----Test Config-----#\n","TEST_BATCH_SIZE = NB_SAMPLES\n","\n","#----OscarNet Config-----#\n","OSCAR_NET_NAME = \"oscar_net\"\n","OSCAR_NET_HIDDEN_LAYER = 64\n","OSCAR_NET_NB_HIDDEN = 1\n","\n","OSCAR_BEST_HIDDEN = 0\n","OSCAR_BEST_NB = 0\n","\n","#----DesmondNet Config-----#\n","DESMOND_NET_NAME = \"desmond_net\"\n","DESMOND_NET_HIDDEN_LAYER = 64\n","DESMOND_NET_NB_HIDDEN = 1\n","\n","DESMOND_BEST_HIDDEN = 0\n","DESMOND_BEST_NB = 0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fFbkKRS2YnOP"},"source":["# Helpers"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GgmaKIvtYnOQ","colab":{}},"source":["############################################# HELPERS ###############################\n","\n","import torch\n","from torchvision import datasets\n","import os\n","import time\n","from pathlib import Path\n","\n","\n","######################################################################\n","# The data\n","\n","def convert_to_one_hot_labels(input, target):\n","    tmp = input.new_zeros(target.size(0), target.max() + 1)\n","    #set ones\n","    tmp.scatter_(1, target.view(-1, 1), 1.0)\n","    return tmp\n","\n","def load_data(cifar = None, one_hot_labels = False, normalize = False, flatten = True):\n","\n","    data_dir = './data'\n","\n","    if (cifar is not None and cifar):\n","        print('* Using CIFAR')\n","        cifar_train_set = datasets.CIFAR10(data_dir + '/cifar10/', train = True, download = True)\n","        cifar_test_set = datasets.CIFAR10(data_dir + '/cifar10/', train = False, download = True)\n","\n","        train_input = torch.from_numpy(cifar_train_set.data)\n","        train_input = train_input.transpose(3, 1).transpose(2, 3).float()\n","        train_target = torch.tensor(cifar_train_set.targets, dtype = torch.int64)\n","\n","        test_input = torch.from_numpy(cifar_test_set.data).float()\n","        test_input = test_input.transpose(3, 1).transpose(2, 3).float()\n","        test_target = torch.tensor(cifar_test_set.targets, dtype = torch.int64)\n","\n","    else:\n","        print('* Using MNIST')\n","        mnist_train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n","        mnist_test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n","\n","        train_input = mnist_train_set.data.view(-1, 1, 28, 28).float()\n","        train_target = mnist_train_set.targets\n","        test_input = mnist_test_set.data.view(-1, 1, 28, 28).float()\n","        test_target = mnist_test_set.targets\n","\n","    if flatten:\n","        train_input = train_input.clone().reshape(train_input.size(0), -1)\n","        test_input = test_input.clone().reshape(test_input.size(0), -1)\n","        \n","        \n","    train_input = train_input.narrow(0, 0, 1000)\n","    train_target = train_target.narrow(0, 0, 1000)\n","    test_input = test_input.narrow(0, 0, 1000)\n","    test_target = test_target.narrow(0, 0, 1000)\n","\n","    print('** Use {:d} train and {:d} test samples'.format(train_input.size(0), test_input.size(0)))\n","\n","    if one_hot_labels:\n","        train_target = convert_to_one_hot_labels(train_input, train_target)\n","        test_target = convert_to_one_hot_labels(test_input, test_target)\n","\n","    if normalize:\n","        mu, std = train_input.mean(), train_input.std()\n","        train_input.sub_(mu).div_(std)\n","        test_input.sub_(mu).div_(std)\n","\n","    return train_input, train_target, test_input, test_target\n","\n","######################################################################\n","\n","def mnist_to_pairs(nb, input, target):\n","    input = torch.functional.F.avg_pool2d(input, kernel_size = 2)\n","    a = torch.randperm(input.size(0))\n","    a = a[:2 * nb].view(nb, 2)\n","    input = torch.cat((input[a[:, 0]], input[a[:, 1]]), 1)\n","    classes = target[a]\n","    target = (classes[:, 0] <= classes[:, 1]).long()\n","    return input, target, classes\n","\n","######################################################################\n","\n","def generate_pair_sets(nb):\n","\n","    data_dir = DATA_DIR\n","\n","    train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n","    train_input = train_set.data.view(-1, 1, 28, 28).float()\n","    train_target = train_set.targets\n","\n","    test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n","    test_input = test_set.data.view(-1, 1, 28, 28).float()\n","    test_target = test_set.targets\n","\n","    return mnist_to_pairs(nb, train_input, train_target) + \\\n","           mnist_to_pairs(nb, test_input, test_target)\n","\n","######################################################################\n","\n","######################################################################\n","\n","def save_model(model, epoch=None, loss=None, save_dir=None, specific_name=None):\n","\n","    if epoch and loss and save_dir and specific_name:\n","        model_name = model.model_name\n","        timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n","        file_name = f\"{timestr}_{model_name}_epoch_{epoch}_loss_{loss:03.3f}.pt\"\n","        Path(save_dir).mkdir(exist_ok=True)\n","        file_path = Path(save_dir) / file_name\n","        torch.save(model.state_dict(), str(file_path))\n","    elif save_dir and specific_name:\n","        file_path = Path(save_dir) / specific_name\n","        torch.save(model.state_dict(), str(file_path))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y8gFJvENYnOU"},"source":["# Modules"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Gc_iLbh4YnOV","colab":{}},"source":["import torch.nn as nn\n","import torch\n","from torch.nn import functional as F\n","import math\n","\n","class OscarNet(nn.Module):\n","\n","    def __init__(self, nb_hidden_layers= OSCAR_NET_NB_HIDDEN, hidden_layer = OSCAR_NET_HIDDEN_LAYER):\n","        super(OscarNet, self).__init__()\n","        self.model_name = OSCAR_NET_NAME\n","        \n","        if nb_hidden_layers < 1:\n","            raise Exception(\"Minimum 1 hidden layers for \" + self.model_name)\n","        \n","        self.hiddens = nn.ModuleList([nn.Sequential(nn.Linear(hidden_layer, hidden_layer), nn.LeakyReLU(), nn.Dropout(p=0.2)) for i in range(nb_hidden_layers-1)])\n","\n","        self.hiddens.insert(0,nn.Sequential(nn.Linear(SINGLE_IMAGE_SIZE, hidden_layer), nn.LeakyReLU(), nn.Dropout(p=0.2)))\n","        \n","        self.output = nn.Linear(hidden_layer, NUMBER_OF_CLASSES)\n","\n","    def forward(self, x):\n","        flattened = x.view(x.size(0),-1)\n","        \n","        hid = flattened\n","        \n","        for block in self.hiddens:\n","            hid = block(hid)\n","        \n","        out = self.output(hid)\n","        \n","        return F.softmax(out, dim=1), out\n","\n","\n","class DesmondNet(nn.Module):\n","\n","    def __init__(self, left_net, right_net = None, nb_hidden_layers = DESMOND_NET_NB_HIDDEN, hidden_layer=DESMOND_NET_HIDDEN_LAYER, soft = False):\n","        super(DesmondNet, self).__init__()\n","        self.model_name = DESMOND_NET_NAME\n","        \n","        if nb_hidden_layers < 0:\n","            raise Exception(\"Minimum 0 hidden layers for \" + self.model_name)\n","        \n","        self.subnets = nn.ModuleList([left_net])\n","        \n","        self.soft = soft\n","        \n","        if right_net == None :\n","            self.weight_sharing = True\n","        else :\n","            self.weight_sharing = False\n","            self.subnets.append(right_net)\n","        \n","        self.hiddens = nn.ModuleList()\n","        \n","        if nb_hidden_layers > 0:\n","            self.hiddens = nn.ModuleList([nn.Sequential(nn.Linear(hidden_layer, hidden_layer), nn.LeakyReLU(), nn.Dropout(p=0.2)) for i in range(nb_hidden_layers-1)])\n","\n","            self.hiddens.insert(0,nn.Sequential(nn.Linear(NUMBER_OF_CLASSES*2, hidden_layer), nn.LeakyReLU(), nn.Dropout(p=0.2)))\n","\n","            self.output = nn.Linear(hidden_layer, 1)\n","            \n","        if nb_hidden_layers == 0:\n","            self.output = nn.Linear(NUMBER_OF_CLASSES*2, 1)\n","\n","    def forward(self, x):\n","        #SPLIT x which is of size [N, 2, 14, 14] to two distinct tensors of size [N, 1, 14, 14]\n","        input1 = x[:,0:1,:,:]   #(batch_size,1,14,14)\n","        input2 = x[:,1:2,:,:]   #(batch_size,1,14,14)\n","        \n","        lefted, lefted_no = self.subnets[0](input1)\n","        if self.weight_sharing :\n","            righted, righted_no = self.subnets[0](input2)\n","        else :\n","            righted, righted_no = self.subnets[1](input2)\n","        \n","        #CONCAT lefted and righted which are of size [N,10] each to a single tensor of size [N,20]\n","        if(self.soft):\n","            hid = torch.cat((lefted, righted),1)\n","        else:\n","            hid = torch.cat((lefted_no, righted_no),1)\n","        \n","        for block in self.hiddens:\n","            hid = block(hid)\n","        \n","        out = self.output(hid)\n","        \n","        return torch.sigmoid(out), lefted_no, righted_no"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z0CjF9L5YnOY"},"source":["# Train & Predict"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kRy1GordYnOZ","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","from torch.optim.lr_scheduler import StepLR\n","\n","def train_siamese(model, \n","                  dataloader, \n","                  test_dataloader,\n","                  epochs = EPOCHS,\n","                  final_criterion = FINAL_CRITERION, \n","                  learning_rate = LEARNING_RATE,\n","                  aux_loss = False,\n","                  sub_criterion = SUB_CRITERION, \n","                  alpha = ALPHA):\n","    \n","    cuda = torch.cuda.is_available()\n","    if cuda:\n","        model = model.to(device=\"cuda\")\n","\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # gamma is the decaying factor, after every 1 epoch new_lr = lr*gamma \n","    scheduler = StepLR(optimizer, step_size=1, gamma = 0.9)\n","\n","    training_losses = []\n","    training_acc = []\n","    \n","    training_losses_l = []\n","    \n","    training_losses_r = []\n","    \n","    test_losses = []\n","    test_acc = []\n","    \n","    test_losses_l = []\n","    \n","    test_losses_r = []\n","\n","    for epoch in range(1, epochs+1):  \n","        model.train()\n","        \n","        sum_loss_epoch = 0\n","        total = 0\n","        correct = 0\n","        accuracy_epoch = 0\n","        \n","        sum_loss_epoch_l = 0\n","        \n","        sum_loss_epoch_r = 0\n","        \n","        for ind_batch, sample_batched in enumerate(dataloader):\n","            \n","            images = sample_batched[\"images\"]\n","            labels = sample_batched[\"bool_labels\"]\n","            digit_labels = sample_batched[\"digit_labels\"]\n","            \n","            labels = labels.unsqueeze(1)\n","            \n","            if cuda:\n","                images = images.to(device=\"cuda\")\n","                labels = labels.to(device=\"cuda\")\n","                digit_labels = digit_labels.to(device=\"cuda\")\n","\n","            optimizer.zero_grad()\n","                       \n","            output, lefted, righted = model(images)\n","            \n","            loss = final_criterion(output.flatten(), labels.float().flatten())\n","            loss_left = sub_criterion(lefted, digit_labels[:,0])\n","            loss_right = sub_criterion(righted, digit_labels[:,1])\n","            \n","            if aux_loss:\n","                loss = alpha * loss + ((1-alpha)/2) * loss_left + ((1-alpha)/2) * loss_right\n","\n","            loss.require_grad = True\n","            loss.backward()\n","\n","            optimizer.step()\n","            \n","            #update the accuracy \n","            total += images.size(0)  \n","            correct += (output.round() == labels).sum() \n","            \n","            # if ind_batch % 250 == 0:\n","                # print(\"[Epoch {}, Batch {}/{}]:  [Loss: {:.2f}]\".format(epoch, ind_batch, len(dataloader), loss) )\n","                \n","            #add the loss for this batch to the total loss of the epoch\n","            sum_loss_epoch = sum_loss_epoch + loss.item()\n","            sum_loss_epoch_l = sum_loss_epoch_l + loss_left.item()\n","            sum_loss_epoch_r = sum_loss_epoch_r + loss_right.item()\n","            \n","        scheduler.step()\n","        #compute the mean to obtain the loss for this epoch \n","        mean_loss = sum_loss_epoch / float(len(dataloader))\n","        mean_loss_l = sum_loss_epoch_l / float(len(dataloader))\n","        mean_loss_r = sum_loss_epoch_r / float(len(dataloader))\n","        \n","        # print(\"At epoch {0} the training loss is {1}\".format(epoch, mean_loss) )\n","        training_losses.append(mean_loss)\n","        \n","        accuracy_epoch = float(correct) / float(total)\n","        # print(\"At epoch {0} the training accuracy is {1}\".format(epoch, accuracy_epoch) )\n","        training_acc.append(accuracy_epoch)\n","        \n","        training_losses_l.append(mean_loss_l)\n","        training_losses_r.append(mean_loss_r)\n","        \n","#         print('epoch {0}/{1}'.format(epoch, epochs))\n","        \n","        test_loss, test_accuracy, test_loss_l, test_loss_r = predict_siamese(model,\n","                                                                     test_dataloader,\n","                                                                     final_criterion,\n","                                                                     aux_loss,\n","                                                                     sub_criterion,\n","                                                                     alpha)\n","        \n","        test_losses.append(test_loss)\n","        test_acc.append(test_accuracy)\n","        test_losses_l.append(test_loss_l)\n","        test_losses_r.append(test_loss_r)\n","        \n","    return training_losses, training_acc, training_losses_l, training_losses_r, test_losses, test_acc, test_losses_l, test_losses_r\n","\n","\n","def predict_siamese(model, \n","            dataloader,\n","            final_criterion = FINAL_CRITERION,\n","            aux_loss = False,\n","            sub_criterion = SUB_CRITERION, \n","            alpha = ALPHA):\n","    \n","    model.eval()\n","    \n","    cuda = torch.cuda.is_available()\n","    if cuda:\n","        model = model.to(device=\"cuda\")\n","        \n","    sum_loss = 0\n","    total = 0\n","    correct = 0\n","    accuracy = 0\n","\n","    sum_loss_l = 0\n","\n","    sum_loss_r = 0\n","\n","    for ind_batch, sample_batched in enumerate(dataloader):\n","\n","        images = sample_batched[\"images\"]\n","        labels = sample_batched[\"bool_labels\"]\n","        digit_labels = sample_batched[\"digit_labels\"]\n","        \n","        if cuda:\n","            images = images.to(device=\"cuda\")\n","            labels = labels.to(device=\"cuda\")\n","            digit_labels = digit_labels.to(device=\"cuda\")\n","\n","        output, lefted, righted = model(images)\n","        \n","        labels = labels.unsqueeze(1)\n","\n","        loss = final_criterion(output.flatten(), labels.float().flatten())\n","        loss_left = sub_criterion(lefted, digit_labels[:,0])\n","        loss_right = sub_criterion(righted, digit_labels[:,1])\n","\n","        if aux_loss:\n","            loss = alpha * loss + ((1-alpha)/2) * loss_left + ((1-alpha)/2) * loss_right\n","\n","        #update the accuracy \n","        total += images.size(0)  \n","        correct += (output.round() == labels).sum() \n","\n","        #add the loss for this batch to the total loss of the epoch\n","        sum_loss = sum_loss + loss.item()\n","        sum_loss_l = sum_loss_l + loss_left.item()\n","        sum_loss_r = sum_loss_r + loss_right.item()\n","\n","    #compute the mean to obtain the loss for this epoch \n","    mean_loss = sum_loss / float(len(dataloader))\n","    mean_loss_l = sum_loss_l / float(len(dataloader))\n","    mean_loss_r = sum_loss_r / float(len(dataloader))\n","    \n","    # print(\"The test loss is {0}\".format(mean_loss) )\n","\n","    accuracy = float(correct) / float(total)\n","    # print(\"The test accuracy is {0}\".format(accuracy) )\n","        \n","    return mean_loss, accuracy, mean_loss_l, mean_loss_r"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W_zXzV_9YnOd"},"source":["# Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4WLoz_k9YnOe","colab":{}},"source":["######## DATA #####################################################\n","import torch.utils.data as data\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from torch.utils.data import Dataset\n","\n","\n","class PairDataset(Dataset):\n","\n","    def __init__(self, data, bool_labels, digit_labels = None):\n","        self.images = data\n","        self.bool_labels = bool_labels\n","        \n","        if digit_labels is not None:\n","            self.digit_labels = digit_labels\n","\n","    def __len__(self):\n","        # override the class method. return the length of data\n","        return len(self.bool_labels)\n","\n","    def __getitem__(self, idx):\n","        # override the class method. return the item at the index(idx)\n","        if self.digit_labels is not None:\n","            sample = {\"images\" : self.images[idx],\n","                      \"bool_labels\" : self.bool_labels[idx],\n","                      \"digit_labels\" : self.digit_labels[idx]}\n","        else:\n","            sample = {\"images\" : self.images[idx],\n","                      \"bool_labels\" : self.bool_labels[idx]}\n","            \n","        return sample\n","    \n","class SingleDataset(Dataset):\n","\n","    def __init__(self, data, digit_labels):\n","        self.images = data\n","        self.digit_labels = digit_labels\n","\n","    def __len__(self):\n","        # override the class method. return the length of data\n","        return len(self.digit_labels)\n","\n","    def __getitem__(self, idx):\n","        # override the class method. return the item at the index(idx)\n","        sample = {\"images\" : self.images[idx],\n","                  \"digit_labels\" : self.digit_labels[idx]}\n","            \n","        return sample\n","\n","\n","\n","pairs = generate_pair_sets(NB_SAMPLES)\n","\n","train_dataset = PairDataset(pairs[0], pairs[1], pairs[2])\n","train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n","\n","test_dataset = PairDataset(pairs[3], pairs[4], pairs[5])\n","test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=True)\n","\n","##############################################################"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u8aSrRTSYnOi"},"source":["# FCNEURONS (inner network) search"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589488882578,"user_tz":-120,"elapsed":1455106,"user":{"displayName":"Ben Dhiaf Meryem","photoUrl":"","userId":"04968261287100866991"}},"id":"bdWWp_7KYnOi","outputId":"68c83aeb-91ce-41e6-fadd-12bbcca5dfb3","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["cuda = torch.cuda.is_available()\n","if cuda:\n","    print(\"CUDA available\")\n","else:\n","    print(\"NO CUDA\")\n","\n","round_results_nb_neurons_inner = [] #3D\n","\n","for i in range(rounds):\n","    results = [] #training_losses, training_acc, test_losses, test_acc\n","    \n","    print('round {0} start'.format(i+1))\n","    \n","    for ind1, nb in enumerate(NB_LAYERS):\n","        results_tmp = []\n","        \n","        for ind2, n in enumerate(FCNEURONS):\n","        \n","            classifier = OscarNet(nb_hidden_layers = nb, hidden_layer = n)\n","\n","            model = DesmondNet(classifier)\n","\n","            training_losses, training_acc, _, _, test_losses, test_acc, _, _ = train_siamese(model = model,\n","                                         dataloader = train_dataloader,\n","                                         test_dataloader = test_dataloader,\n","                                         epochs = EPOCHS,\n","                                         final_criterion = FINAL_CRITERION, \n","                                         learning_rate = LEARNING_RATE,\n","                                         aux_loss = True,\n","                                         sub_criterion = SUB_CRITERION, \n","                                         alpha = ALPHA)\n","\n","            print('{0}/{1}'.format(ind1 * len(FCNEURONS) + ind2 + 1, len(NB_LAYERS) * len(FCNEURONS)))\n","            print('With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : {0}/{1}/{2}/{3}/{4}'.format(nb,\n","                                                                                                                   n,\n","                                                                                                                   DESMOND_NET_NB_HIDDEN,\n","                                                                                                                   DESMOND_NET_HIDDEN_LAYER,\n","                                                                                                                   ALPHA))\n","            final_test_loss, final_test_loss_acc = test_losses[-1], test_acc[-1]\n","            print(\"On the test set we obtain a loss of {:.2f} and an accuracy of {:.2f}\".format(final_test_loss,final_test_loss_acc))\n","\n","            results_tmp.append([training_losses, training_acc, test_losses, test_acc])\n","    \n","        results.append(results_tmp)\n","    \n","    print('round {0} end'.format(i+1))\n","    round_results_nb_neurons_inner.append(results)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["CUDA available\n","round 1 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.45 and an accuracy of 0.86\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.85\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.86\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.88\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.53 and an accuracy of 0.88\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.88\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.89\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.89\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.45 and an accuracy of 0.89\n","round 1 end\n","round 2 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.87\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.87\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.87\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.48 and an accuracy of 0.86\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.53 and an accuracy of 0.88\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.90\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.89\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.90\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.50 and an accuracy of 0.90\n","round 2 end\n","round 3 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.43 and an accuracy of 0.87\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.85\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.87\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.87\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.55 and an accuracy of 0.88\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.88\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.30 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.56 and an accuracy of 0.91\n","round 3 end\n","round 4 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.48 and an accuracy of 0.85\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.85\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.85\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.89\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.57 and an accuracy of 0.87\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.88\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.89\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.48 and an accuracy of 0.90\n","round 4 end\n","round 5 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.47 and an accuracy of 0.84\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.88\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.86\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.47 and an accuracy of 0.87\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.49 and an accuracy of 0.88\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.90\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.89\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.90\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.55 and an accuracy of 0.90\n","round 5 end\n","round 6 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.86\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.87\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.88\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.47 and an accuracy of 0.86\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.58 and an accuracy of 0.87\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.90\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.89\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.50 and an accuracy of 0.89\n","round 6 end\n","round 7 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.85\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.86\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.88\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.87\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.56 and an accuracy of 0.88\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.89\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.50 and an accuracy of 0.90\n","round 7 end\n","round 8 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.47 and an accuracy of 0.84\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.87\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.86\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.88\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.49 and an accuracy of 0.87\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.90\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.43 and an accuracy of 0.90\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.90\n","round 8 end\n","round 9 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.85\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.86\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.86\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.88\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.51 and an accuracy of 0.89\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.30 and an accuracy of 0.90\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.43 and an accuracy of 0.90\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.90\n","round 9 end\n","round 10 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/32/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.85\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/64/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.87\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/128/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.88\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/256/1/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.87\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 1/512/1/64/0.5\n","On the test set we obtain a loss of 0.55 and an accuracy of 0.88\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/32/1/64/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.91\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/64/1/64/0.5\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.90\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/128/1/64/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.89\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.89\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/512/1/64/0.5\n","On the test set we obtain a loss of 0.47 and an accuracy of 0.89\n","round 10 end\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589488882589,"user_tz":-120,"elapsed":1454893,"user":{"displayName":"Ben Dhiaf Meryem","photoUrl":"","userId":"04968261287100866991"}},"id":"wZ-5nlPnaMpx","outputId":"6818c013-d889-4752-d343-c2e483a9c58d","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["np.savez(\"results-fcns-nb_fcneurons_inner_search\",round_results_nb_neurons_inner)\n","\n","copy_of = np.array(round_results_nb_neurons_inner).copy()\n","\n","last_accs_only = copy_of[:, :, :, 3, EPOCHS-1]\n","\n","means_fcni = last_accs_only.mean(axis=0)\n","stds_fcni = last_accs_only.std(axis=0)\n","\n","print(means_fcni)\n","print(stds_fcni)\n","\n","raveled_i_max = np.argmax(means_fcni)\n","\n","print(raveled_i_max)\n","\n","unraveled_i_max = np.unravel_index(raveled_i_max, means_fcni.shape)\n","\n","print(unraveled_i_max)\n","\n","best_nb_hidden_inner = NB_LAYERS[unraveled_i_max[0]]\n","best_hidden_layer_inner = FCNEURONS[unraveled_i_max[1]]\n","\n","print(best_nb_hidden_inner)\n","print(best_hidden_layer_inner)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[[0.8545 0.864  0.8675 0.8722 0.8776]\n"," [0.8896 0.8978 0.8983 0.8983 0.8969]]\n","[[0.00941541 0.00781025 0.00824924 0.00778203 0.00631189]\n"," [0.00971802 0.00713863 0.00436005 0.00760329 0.00450444]]\n","8\n","(1, 3)\n","2\n","256\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QMkJ6jtRYnOp"},"source":["# FCNEURONS (outer network) search"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589490531292,"user_tz":-120,"elapsed":391192,"user":{"displayName":"Ben Dhiaf Meryem","photoUrl":"","userId":"04968261287100866991"}},"id":"--_IEE_vYnOp","outputId":"4122ecd9-1d0f-492e-e239-a0112cf94e5c","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["cuda = torch.cuda.is_available()\n","if cuda:\n","    print(\"CUDA available\")\n","else:\n","    print(\"NO CUDA\")\n","\n","round_results_nb_neurons_outer = [] #3D\n","\n","for i in range(rounds):\n","    results = [] #training_losses, training_acc, test_losses, test_acc\n","    \n","    print('round {0} start'.format(i+1))\n","    \n","    for ind1, nb in enumerate(NB_LAYERS):\n","        results_tmp = []\n","        \n","        for ind2, n in enumerate(FCNEURONS):\n","        \n","            classifier = OscarNet(nb_hidden_layers = best_nb_hidden_inner, hidden_layer = best_hidden_layer_inner)\n","\n","            model = DesmondNet(classifier, nb_hidden_layers = nb, hidden_layer = n)\n","\n","            training_losses, training_acc, _, _, test_losses, test_acc, _, _ = train_siamese(model = model,\n","                                         dataloader = train_dataloader,\n","                                         test_dataloader = test_dataloader,\n","                                         epochs = EPOCHS,\n","                                         final_criterion = FINAL_CRITERION, \n","                                         learning_rate = LEARNING_RATE,\n","                                         aux_loss = True,\n","                                         sub_criterion = SUB_CRITERION, \n","                                         alpha = ALPHA)\n","\n","            print('{0}/{1}'.format(ind1 * len(FCNEURONS) + ind2 + 1, len(NB_LAYERS) * len(FCNEURONS)))\n","            print('With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : {0}/{1}/{2}/{3}/{4}'.format(best_nb_hidden_inner,\n","                                                                                                                   best_hidden_layer_inner,\n","                                                                                                                   nb,\n","                                                                                                                   n,\n","                                                                                                                   ALPHA))\n","            final_test_loss, final_test_loss_acc = test_losses[-1], test_acc[-1]\n","            print(\"On the test set we obtain a loss of {:.2f} and an accuracy of {:.2f}\".format(final_test_loss,final_test_loss_acc))\n","\n","            results_tmp.append([training_losses, training_acc, test_losses, test_acc])\n","    \n","        results.append(results_tmp)\n","    \n","    print('round {0} end'.format(i+1))\n","    round_results_nb_neurons_outer.append(results)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["CUDA available\n","round 1 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.90\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.43 and an accuracy of 0.90\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.90\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.90\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.90\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.92\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.93\n","round 1 end\n","round 2 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.90\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.92\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.90\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.92\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.91\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.90\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.43 and an accuracy of 0.92\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.53 and an accuracy of 0.92\n","round 2 end\n","round 3 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.89\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.90\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.90\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.91\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.90\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.49 and an accuracy of 0.90\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.90\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.92\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.92\n","round 3 end\n","round 4 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.89\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.91\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.91\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.92\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.48 and an accuracy of 0.91\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.90\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.92\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.93\n","round 4 end\n","round 5 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.89\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.90\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.91\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.91\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.90\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.92\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.92\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.91\n","round 5 end\n","round 6 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.89\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.91\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.90\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.91\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.91\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.49 and an accuracy of 0.90\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.47 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.91\n","round 6 end\n","round 7 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.90\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.90\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.91\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.90\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.91\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.43 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.92\n","round 7 end\n","round 8 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.90\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.90\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.89\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.91\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.91\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.90\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.92\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.47 and an accuracy of 0.92\n","round 8 end\n","round 9 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.89\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.47 and an accuracy of 0.90\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.90\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.91\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.90\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.90\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.92\n","round 9 end\n","round 10 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/32/0.5\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.89\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/64/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.90\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/128/0.5\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.91\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/256/0.5\n","On the test set we obtain a loss of 0.45 and an accuracy of 0.91\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/1/512/0.5\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/32/0.5\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.89\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/64/0.5\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/128/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/256/0.5\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.5\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.92\n","round 10 end\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589490531294,"user_tz":-120,"elapsed":57,"user":{"displayName":"Ben Dhiaf Meryem","photoUrl":"","userId":"04968261287100866991"}},"id":"GCJVe1bFYnOs","outputId":"2860bc12-57d1-4c3c-bdc0-226b5bce7ec3","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["np.savez(\"results-fcns-nb_fcneurons_outer_search\",round_results_nb_neurons_outer)\n","\n","copy_of = np.array(round_results_nb_neurons_outer).copy()\n","\n","last_accs_only = copy_of[:, :, :, 3, EPOCHS-1]\n","\n","means_fcno = last_accs_only.mean(axis=0)\n","stds_fcno = last_accs_only.std(axis=0)\n","\n","print(means_fcno)\n","print(stds_fcno)\n","\n","raveled_i_max = np.argmax(means_fcno)\n","\n","print(raveled_i_max)\n","\n","unraveled_i_max = np.unravel_index(raveled_i_max, means_fcno.shape)\n","\n","print(unraveled_i_max)\n","\n","best_nb_hidden_outer = NB_LAYERS[unraveled_i_max[0]]\n","best_hidden_layer_outer = FCNEURONS[unraveled_i_max[1]]\n","\n","print(best_nb_hidden_outer)\n","print(best_hidden_layer_outer)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[[0.8946 0.9038 0.9028 0.9086 0.9108]\n"," [0.8933 0.9047 0.911  0.9138 0.9182]]\n","[[0.00407922 0.00663023 0.00575847 0.0051225  0.00754718]\n"," [0.00549636 0.00679779 0.00471169 0.00437721 0.00552811]]\n","9\n","(1, 4)\n","2\n","512\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eVcWGR-TYnOv"},"source":["# ALPHA search"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589492262899,"user_tz":-120,"elapsed":1731620,"user":{"displayName":"Ben Dhiaf Meryem","photoUrl":"","userId":"04968261287100866991"}},"id":"ikImPLAVYnOw","outputId":"3ead9956-805b-48c5-9db2-13e09e60c59d","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["cuda = torch.cuda.is_available()\n","if cuda:\n","    print(\"CUDA available\")\n","else:\n","    print(\"NO CUDA\")\n","\n","round_results_alpha = [] #3D\n","\n","for i in range(rounds):\n","    results = [] #training_losses, training_acc, test_losses, test_acc\n","    \n","    print('round {0} start'.format(i+1))\n","    \n","    for ind, a in enumerate(ALPHAS):\n","        \n","        classifier = OscarNet(nb_hidden_layers = best_nb_hidden_inner, hidden_layer = best_hidden_layer_inner)\n","\n","        model = DesmondNet(classifier, nb_hidden_layers = best_nb_hidden_outer, hidden_layer = best_hidden_layer_outer)\n","        \n","        training_losses, training_acc, _, _, test_losses, test_acc, _, _ = train_siamese(model = model,\n","                                     dataloader = train_dataloader,\n","                                     test_dataloader = test_dataloader,\n","                                     epochs = EPOCHS,\n","                                     final_criterion = FINAL_CRITERION, \n","                                     learning_rate = LEARNING_RATE,\n","                                     aux_loss = True,\n","                                     sub_criterion = SUB_CRITERION, \n","                                     alpha = a)\n","        \n","        print('{0}/{1}'.format(ind+1, len(ALPHAS)))\n","        print('With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : {0}/{1}/{2}/{3}/{4}'.format(best_nb_hidden_inner,\n","                                                                                                                best_hidden_layer_inner,\n","                                                                                                                best_nb_hidden_outer,\n","                                                                                                                best_hidden_layer_outer,\n","                                                                                                                round(a, 2)))\n","        final_test_loss, final_test_loss_acc = test_losses[-1], test_acc[-1]\n","        print(\"On the test set we obtain a loss of {:.2f} and an accuracy of {:.2f}\".format(final_test_loss,final_test_loss_acc))\n","        \n","        results.append([training_losses, training_acc, test_losses, test_acc])\n","    \n","    \n","    print('round {0} end'.format(i+1))\n","    round_results_alpha.append(results)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["CUDA available\n","round 1 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.55\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.92\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.92\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.92\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.48 and an accuracy of 0.91\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.92\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.55 and an accuracy of 0.92\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.52 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.48 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 1.00 and an accuracy of 0.87\n","round 1 end\n","round 2 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.30 and an accuracy of 0.47\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.94\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.92\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.93\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.93\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.92\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.57 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.48 and an accuracy of 0.92\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 0.92 and an accuracy of 0.86\n","round 2 end\n","round 3 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.31 and an accuracy of 0.45\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.93\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.93\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.92\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.31 and an accuracy of 0.93\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.62 and an accuracy of 0.92\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.54 and an accuracy of 0.92\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 1.00 and an accuracy of 0.87\n","round 3 end\n","round 4 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.31 and an accuracy of 0.52\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.31 and an accuracy of 0.93\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.30 and an accuracy of 0.93\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.92\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.40 and an accuracy of 0.92\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.50 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.92\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.66 and an accuracy of 0.90\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 0.91 and an accuracy of 0.90\n","round 4 end\n","round 5 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.48\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.29 and an accuracy of 0.93\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.91\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.93\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.93\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.91\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.91\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.62 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.80 and an accuracy of 0.90\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 1.09 and an accuracy of 0.87\n","round 5 end\n","round 6 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.29 and an accuracy of 0.52\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.92\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.92\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.92\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.44 and an accuracy of 0.92\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.53 and an accuracy of 0.92\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.58 and an accuracy of 0.92\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.70 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 0.81 and an accuracy of 0.87\n","round 6 end\n","round 7 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.47\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.29 and an accuracy of 0.93\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.93\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.92\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.39 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.92\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.59 and an accuracy of 0.92\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.37 and an accuracy of 0.92\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.58 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 0.84 and an accuracy of 0.88\n","round 7 end\n","round 8 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.58\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.93\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.93\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.92\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.36 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.92\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.35 and an accuracy of 0.92\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.48 and an accuracy of 0.93\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.47 and an accuracy of 0.90\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 1.21 and an accuracy of 0.87\n","round 8 end\n","round 9 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.29 and an accuracy of 0.53\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.93\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.31 and an accuracy of 0.93\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.91\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.92\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.38 and an accuracy of 0.92\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.50 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.69 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 1.36 and an accuracy of 0.87\n","round 9 end\n","round 10 start\n","1/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.0\n","On the test set we obtain a loss of 0.26 and an accuracy of 0.51\n","2/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.11\n","On the test set we obtain a loss of 0.33 and an accuracy of 0.93\n","3/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.22\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.93\n","4/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.33\n","On the test set we obtain a loss of 0.32 and an accuracy of 0.93\n","5/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.44\n","On the test set we obtain a loss of 0.34 and an accuracy of 0.92\n","6/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.56\n","On the test set we obtain a loss of 0.48 and an accuracy of 0.91\n","7/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.67\n","On the test set we obtain a loss of 0.41 and an accuracy of 0.92\n","8/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.78\n","On the test set we obtain a loss of 0.42 and an accuracy of 0.91\n","9/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/0.89\n","On the test set we obtain a loss of 0.46 and an accuracy of 0.91\n","10/10\n","With parameters nb_hid_inner/hid_inner/nb_hid_out/hid_outer/alpha : 2/256/2/512/1.0\n","On the test set we obtain a loss of 0.88 and an accuracy of 0.86\n","round 10 end\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589492262903,"user_tz":-120,"elapsed":71,"user":{"displayName":"Ben Dhiaf Meryem","photoUrl":"","userId":"04968261287100866991"}},"id":"_i2A84p6YnOz","outputId":"82e1a252-00cf-4926-b334-db34f140632d","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["np.savez(\"results-alpha\".format(TRAIN_BATCH_SIZE),round_results_alpha)\n","\n","copy_of = np.array(round_results_alpha).copy()\n","\n","last_accs_only = copy_of[:, :, 3, EPOCHS-1]\n","\n","means_alpha = last_accs_only.mean(axis=0)\n","stds_alpha = last_accs_only.std(axis=0)\n","\n","print(means_alpha)\n","print(stds_alpha)\n","\n","i_max = np.argmax(means_alpha)\n","\n","print(i_max)\n","\n","best_alpha = ALPHAS[i_max]\n","\n","print(best_alpha)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[0.5075 0.9295 0.9243 0.9222 0.9209 0.9184 0.9174 0.9158 0.9073 0.873 ]\n","[0.03854154 0.00520096 0.00695773 0.00561783 0.0047     0.00553534\n"," 0.00465188 0.00602993 0.00511957 0.00913236]\n","1\n","0.1111111111111111\n"],"name":"stdout"}]}]}