{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import helpers\n",
    "import config\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from models.BasicNet import BasicNet\n",
    "from train import train_basic\n",
    "from predict import predict_basic\n",
    "\n",
    "from models.CNN import CNN\n",
    "from models.FCN import FCN \n",
    "\n",
    "from models.SiameseNet import SiameseNet\n",
    "from train import train_siamese\n",
    "from predict import predict_siamese\n",
    "\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import PairDataset\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = helpers.generate_pair_sets(config.NB_SAMPLES)\n",
    "\n",
    "train_dataset = PairDataset(pairs[0], pairs[1], pairs[2])\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size= config.TRAIN_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = PairDataset(pairs[3], pairs[4], pairs[5])\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=config.TEST_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 512]         201,216\n",
      "            Linear-2                    [-1, 1]             513\n",
      "================================================================\n",
      "Total params: 201,729\n",
      "Trainable params: 201,729\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.77\n",
      "Estimated Total Size (MB): 0.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(BasicNet(), (1 ,2, 14, 14)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "At epoch 1 the loss is 9.208371364773356\n",
      "At epoch 1 the accuracy is 0.488\n",
      "epoch 1/20\n",
      "The test loss is 7.154966831207275\n",
      "The test accuracy is 0.559\n",
      "At epoch 2 the loss is 5.961136649219206\n",
      "At epoch 2 the accuracy is 0.57\n",
      "epoch 2/20\n",
      "The test loss is 4.910558223724365\n",
      "The test accuracy is 0.622\n",
      "At epoch 3 the loss is 4.596130375476133\n",
      "At epoch 3 the accuracy is 0.654\n",
      "epoch 3/20\n",
      "The test loss is 4.281219005584717\n",
      "The test accuracy is 0.653\n",
      "At epoch 4 the loss is 3.882668521091671\n",
      "At epoch 4 the accuracy is 0.678\n",
      "epoch 4/20\n",
      "The test loss is 3.69779634475708\n",
      "The test accuracy is 0.677\n",
      "At epoch 5 the loss is 3.383673670848284\n",
      "At epoch 5 the accuracy is 0.691\n",
      "epoch 5/20\n",
      "The test loss is 3.4035844802856445\n",
      "The test accuracy is 0.681\n",
      "At epoch 6 the loss is 2.956588275920701\n",
      "At epoch 6 the accuracy is 0.711\n",
      "epoch 6/20\n",
      "The test loss is 3.1581661701202393\n",
      "The test accuracy is 0.692\n",
      "At epoch 7 the loss is 2.595300279397895\n",
      "At epoch 7 the accuracy is 0.715\n",
      "epoch 7/20\n",
      "The test loss is 3.000606060028076\n",
      "The test accuracy is 0.695\n",
      "At epoch 8 the loss is 2.361743494375304\n",
      "At epoch 8 the accuracy is 0.712\n",
      "epoch 8/20\n",
      "The test loss is 2.7887566089630127\n",
      "The test accuracy is 0.703\n",
      "At epoch 9 the loss is 2.1777686464985235\n",
      "At epoch 9 the accuracy is 0.722\n",
      "epoch 9/20\n",
      "The test loss is 2.678129196166992\n",
      "The test accuracy is 0.698\n",
      "At epoch 10 the loss is 2.0132499445825585\n",
      "At epoch 10 the accuracy is 0.723\n",
      "epoch 10/20\n",
      "The test loss is 2.6155881881713867\n",
      "The test accuracy is 0.706\n",
      "At epoch 11 the loss is 1.8714791286062447\n",
      "At epoch 11 the accuracy is 0.738\n",
      "epoch 11/20\n",
      "The test loss is 2.5414791107177734\n",
      "The test accuracy is 0.704\n",
      "At epoch 12 the loss is 1.7953825459009511\n",
      "At epoch 12 the accuracy is 0.737\n",
      "epoch 12/20\n",
      "The test loss is 2.44244647026062\n",
      "The test accuracy is 0.703\n",
      "At epoch 13 the loss is 1.6947915484309266\n",
      "At epoch 13 the accuracy is 0.751\n",
      "epoch 13/20\n",
      "The test loss is 2.3891663551330566\n",
      "The test accuracy is 0.706\n",
      "At epoch 14 the loss is 1.630354117133437\n",
      "At epoch 14 the accuracy is 0.754\n",
      "epoch 14/20\n",
      "The test loss is 2.372056245803833\n",
      "The test accuracy is 0.71\n",
      "At epoch 15 the loss is 1.584807609359758\n",
      "At epoch 15 the accuracy is 0.758\n",
      "epoch 15/20\n",
      "The test loss is 2.3173563480377197\n",
      "The test accuracy is 0.708\n",
      "At epoch 16 the loss is 1.538950729935362\n",
      "At epoch 16 the accuracy is 0.749\n",
      "epoch 16/20\n",
      "The test loss is 2.3037140369415283\n",
      "The test accuracy is 0.71\n",
      "At epoch 17 the loss is 1.5033715357425215\n",
      "At epoch 17 the accuracy is 0.762\n",
      "epoch 17/20\n",
      "The test loss is 2.2428555488586426\n",
      "The test accuracy is 0.702\n",
      "At epoch 18 the loss is 1.4677210154497897\n",
      "At epoch 18 the accuracy is 0.766\n",
      "epoch 18/20\n",
      "The test loss is 2.2476351261138916\n",
      "The test accuracy is 0.715\n",
      "At epoch 19 the loss is 1.4465178225827209\n",
      "At epoch 19 the accuracy is 0.768\n",
      "epoch 19/20\n",
      "The test loss is 2.198594331741333\n",
      "The test accuracy is 0.71\n",
      "At epoch 20 the loss is 1.4179511630686898\n",
      "At epoch 20 the accuracy is 0.765\n",
      "epoch 20/20\n",
      "The test loss is 2.1548562049865723\n",
      "The test accuracy is 0.702\n",
      "With 5 batch size and 20 epochs and 0.001 learning rate we get :\n",
      "The test loss is 2.154857873916626\n",
      "The test accuracy is 0.702\n",
      "On the test set we obtain a loss of 2.15 and an accuracy of 0.70\n",
      "Round 1\n",
      "At epoch 1 the loss is 5.032806900389562\n",
      "At epoch 1 the accuracy is 0.631\n",
      "epoch 1/20\n",
      "The test loss is 3.1461455821990967\n",
      "The test accuracy is 0.69\n",
      "At epoch 2 the loss is 3.1398391385459514\n",
      "At epoch 2 the accuracy is 0.705\n",
      "epoch 2/20\n",
      "The test loss is 2.730924129486084\n",
      "The test accuracy is 0.723\n",
      "At epoch 3 the loss is 2.5972732388778024\n",
      "At epoch 3 the accuracy is 0.715\n",
      "epoch 3/20\n",
      "The test loss is 2.484761953353882\n",
      "The test accuracy is 0.726\n",
      "At epoch 4 the loss is 2.269873283067852\n",
      "At epoch 4 the accuracy is 0.718\n",
      "epoch 4/20\n",
      "The test loss is 2.34047269821167\n",
      "The test accuracy is 0.726\n",
      "At epoch 5 the loss is 2.068607899994879\n",
      "At epoch 5 the accuracy is 0.735\n",
      "epoch 5/20\n",
      "The test loss is 2.189847230911255\n",
      "The test accuracy is 0.731\n",
      "At epoch 6 the loss is 1.9095883338427229\n",
      "At epoch 6 the accuracy is 0.75\n",
      "epoch 6/20\n",
      "The test loss is 2.1308085918426514\n",
      "The test accuracy is 0.734\n",
      "At epoch 7 the loss is 1.7345337831867618\n",
      "At epoch 7 the accuracy is 0.76\n",
      "epoch 7/20\n",
      "The test loss is 1.9977390766143799\n",
      "The test accuracy is 0.736\n",
      "At epoch 8 the loss is 1.6529862754065676\n",
      "At epoch 8 the accuracy is 0.759\n",
      "epoch 8/20\n",
      "The test loss is 1.9366272687911987\n",
      "The test accuracy is 0.724\n",
      "At epoch 9 the loss is 1.5029948372557833\n",
      "At epoch 9 the accuracy is 0.775\n",
      "epoch 9/20\n",
      "The test loss is 1.875266432762146\n",
      "The test accuracy is 0.725\n",
      "At epoch 10 the loss is 1.4207375610993496\n",
      "At epoch 10 the accuracy is 0.776\n",
      "epoch 10/20\n",
      "The test loss is 1.8520222902297974\n",
      "The test accuracy is 0.718\n",
      "At epoch 11 the loss is 1.3368724415371582\n",
      "At epoch 11 the accuracy is 0.778\n",
      "epoch 11/20\n",
      "The test loss is 1.8683624267578125\n",
      "The test accuracy is 0.727\n",
      "At epoch 12 the loss is 1.322823295125877\n",
      "At epoch 12 the accuracy is 0.784\n",
      "epoch 12/20\n",
      "The test loss is 1.7739413976669312\n",
      "The test accuracy is 0.721\n",
      "At epoch 13 the loss is 1.226253401822869\n",
      "At epoch 13 the accuracy is 0.779\n",
      "epoch 13/20\n",
      "The test loss is 1.7281558513641357\n",
      "The test accuracy is 0.722\n",
      "At epoch 14 the loss is 1.1801487757162885\n",
      "At epoch 14 the accuracy is 0.788\n",
      "epoch 14/20\n",
      "The test loss is 1.7063089609146118\n",
      "The test accuracy is 0.72\n",
      "At epoch 15 the loss is 1.1387702409132543\n",
      "At epoch 15 the accuracy is 0.794\n",
      "epoch 15/20\n",
      "The test loss is 1.686785101890564\n",
      "The test accuracy is 0.716\n",
      "At epoch 16 the loss is 1.1118075741183846\n",
      "At epoch 16 the accuracy is 0.797\n",
      "epoch 16/20\n",
      "The test loss is 1.6685030460357666\n",
      "The test accuracy is 0.715\n",
      "At epoch 17 the loss is 1.0862150379777085\n",
      "At epoch 17 the accuracy is 0.799\n",
      "epoch 17/20\n",
      "The test loss is 1.6477049589157104\n",
      "The test accuracy is 0.714\n",
      "At epoch 18 the loss is 1.064730104054761\n",
      "At epoch 18 the accuracy is 0.807\n",
      "epoch 18/20\n",
      "The test loss is 1.6383143663406372\n",
      "The test accuracy is 0.719\n",
      "At epoch 19 the loss is 1.0468289221335727\n",
      "At epoch 19 the accuracy is 0.801\n",
      "epoch 19/20\n",
      "The test loss is 1.6219760179519653\n",
      "The test accuracy is 0.71\n",
      "At epoch 20 the loss is 1.0326620302654193\n",
      "At epoch 20 the accuracy is 0.794\n",
      "epoch 20/20\n",
      "The test loss is 1.6114903688430786\n",
      "The test accuracy is 0.713\n",
      "With 5 batch size and 20 epochs and 0.001 learning rate we get :\n",
      "The test loss is 1.6114907264709473\n",
      "The test accuracy is 0.713\n",
      "On the test set we obtain a loss of 1.61 and an accuracy of 0.71\n",
      "Round 2\n",
      "At epoch 1 the loss is 6.041191079802811\n",
      "At epoch 1 the accuracy is 0.579\n",
      "epoch 1/20\n",
      "The test loss is 5.050614833831787\n",
      "The test accuracy is 0.614\n",
      "At epoch 2 the loss is 4.070101031060931\n",
      "At epoch 2 the accuracy is 0.661\n",
      "epoch 2/20\n",
      "The test loss is 4.654520511627197\n",
      "The test accuracy is 0.664\n",
      "At epoch 3 the loss is 3.356796433536431\n",
      "At epoch 3 the accuracy is 0.704\n",
      "epoch 3/20\n",
      "The test loss is 3.591055393218994\n",
      "The test accuracy is 0.686\n",
      "At epoch 4 the loss is 3.009337443524745\n",
      "At epoch 4 the accuracy is 0.741\n",
      "epoch 4/20\n",
      "The test loss is 3.313093900680542\n",
      "The test accuracy is 0.707\n",
      "At epoch 5 the loss is 2.7089964592276727\n",
      "At epoch 5 the accuracy is 0.739\n",
      "epoch 5/20\n",
      "The test loss is 3.1739726066589355\n",
      "The test accuracy is 0.714\n",
      "At epoch 6 the loss is 2.4372751732580435\n",
      "At epoch 6 the accuracy is 0.751\n",
      "epoch 6/20\n",
      "The test loss is 2.9019510746002197\n",
      "The test accuracy is 0.72\n",
      "At epoch 7 the loss is 2.306371222978271\n",
      "At epoch 7 the accuracy is 0.763\n",
      "epoch 7/20\n",
      "The test loss is 2.8343493938446045\n",
      "The test accuracy is 0.725\n",
      "At epoch 8 the loss is 2.125617402733553\n",
      "At epoch 8 the accuracy is 0.763\n",
      "epoch 8/20\n",
      "The test loss is 2.65817928314209\n",
      "The test accuracy is 0.724\n",
      "At epoch 9 the loss is 1.9731818316502967\n",
      "At epoch 9 the accuracy is 0.775\n",
      "epoch 9/20\n",
      "The test loss is 2.6355478763580322\n",
      "The test accuracy is 0.727\n",
      "At epoch 10 the loss is 1.8939430106814643\n",
      "At epoch 10 the accuracy is 0.78\n",
      "epoch 10/20\n",
      "The test loss is 2.5504813194274902\n",
      "The test accuracy is 0.727\n",
      "At epoch 11 the loss is 1.801665729817899\n",
      "At epoch 11 the accuracy is 0.781\n",
      "epoch 11/20\n",
      "The test loss is 2.3829004764556885\n",
      "The test accuracy is 0.706\n",
      "At epoch 12 the loss is 1.6923876038071535\n",
      "At epoch 12 the accuracy is 0.784\n",
      "epoch 12/20\n",
      "The test loss is 2.4055473804473877\n",
      "The test accuracy is 0.73\n",
      "At epoch 13 the loss is 1.6266709400321997\n",
      "At epoch 13 the accuracy is 0.788\n",
      "epoch 13/20\n",
      "The test loss is 2.346174716949463\n",
      "The test accuracy is 0.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 14 the loss is 1.5871610383267\n",
      "At epoch 14 the accuracy is 0.778\n",
      "epoch 14/20\n",
      "The test loss is 2.2451210021972656\n",
      "The test accuracy is 0.712\n",
      "At epoch 15 the loss is 1.534011637370877\n",
      "At epoch 15 the accuracy is 0.788\n",
      "epoch 15/20\n",
      "The test loss is 2.254706382751465\n",
      "The test accuracy is 0.72\n",
      "At epoch 16 the loss is 1.4990523172367376\n",
      "At epoch 16 the accuracy is 0.786\n",
      "epoch 16/20\n",
      "The test loss is 2.215400218963623\n",
      "The test accuracy is 0.72\n",
      "At epoch 17 the loss is 1.4367194652300714\n",
      "At epoch 17 the accuracy is 0.785\n",
      "epoch 17/20\n",
      "The test loss is 2.1716761589050293\n",
      "The test accuracy is 0.715\n",
      "At epoch 18 the loss is 1.4386565386014576\n",
      "At epoch 18 the accuracy is 0.793\n",
      "epoch 18/20\n",
      "The test loss is 2.205018997192383\n",
      "The test accuracy is 0.721\n",
      "At epoch 19 the loss is 1.3969319034049068\n",
      "At epoch 19 the accuracy is 0.79\n",
      "epoch 19/20\n",
      "The test loss is 2.1412293910980225\n",
      "The test accuracy is 0.717\n",
      "At epoch 20 the loss is 1.334750336140114\n",
      "At epoch 20 the accuracy is 0.792\n",
      "epoch 20/20\n",
      "The test loss is 2.1115379333496094\n",
      "The test accuracy is 0.717\n",
      "With 5 batch size and 20 epochs and 0.001 learning rate we get :\n",
      "The test loss is 2.111536979675293\n",
      "The test accuracy is 0.717\n",
      "On the test set we obtain a loss of 2.11 and an accuracy of 0.72\n",
      "Round 3\n",
      "At epoch 1 the loss is 4.98955191156907\n",
      "At epoch 1 the accuracy is 0.543\n",
      "epoch 1/20\n",
      "The test loss is 4.487072467803955\n",
      "The test accuracy is 0.587\n",
      "At epoch 2 the loss is 3.4886273331585835\n",
      "At epoch 2 the accuracy is 0.626\n",
      "epoch 2/20\n",
      "The test loss is 3.378926992416382\n",
      "The test accuracy is 0.625\n",
      "At epoch 3 the loss is 2.8067829100443604\n",
      "At epoch 3 the accuracy is 0.663\n",
      "epoch 3/20\n",
      "The test loss is 2.819035053253174\n",
      "The test accuracy is 0.646\n",
      "At epoch 4 the loss is 2.2713535307270285\n",
      "At epoch 4 the accuracy is 0.695\n",
      "epoch 4/20\n",
      "The test loss is 2.4858944416046143\n",
      "The test accuracy is 0.675\n",
      "At epoch 5 the loss is 1.9782358867920424\n",
      "At epoch 5 the accuracy is 0.7\n",
      "epoch 5/20\n",
      "The test loss is 2.177945137023926\n",
      "The test accuracy is 0.676\n",
      "At epoch 6 the loss is 1.6787764890778294\n",
      "At epoch 6 the accuracy is 0.726\n",
      "epoch 6/20\n",
      "The test loss is 2.168226480484009\n",
      "The test accuracy is 0.687\n",
      "At epoch 7 the loss is 1.5587116802922083\n",
      "At epoch 7 the accuracy is 0.739\n",
      "epoch 7/20\n",
      "The test loss is 1.9210857152938843\n",
      "The test accuracy is 0.676\n",
      "At epoch 8 the loss is 1.3809565143642248\n",
      "At epoch 8 the accuracy is 0.735\n",
      "epoch 8/20\n",
      "The test loss is 1.8317742347717285\n",
      "The test accuracy is 0.681\n",
      "At epoch 9 the loss is 1.2864932680067762\n",
      "At epoch 9 the accuracy is 0.749\n",
      "epoch 9/20\n",
      "The test loss is 1.7672443389892578\n",
      "The test accuracy is 0.677\n",
      "At epoch 10 the loss is 1.1793959273441033\n",
      "At epoch 10 the accuracy is 0.765\n",
      "epoch 10/20\n",
      "The test loss is 1.7016340494155884\n",
      "The test accuracy is 0.68\n",
      "At epoch 11 the loss is 1.1120061314372287\n",
      "At epoch 11 the accuracy is 0.759\n",
      "epoch 11/20\n",
      "The test loss is 1.6796315908432007\n",
      "The test accuracy is 0.681\n",
      "At epoch 12 the loss is 1.0531566745313468\n",
      "At epoch 12 the accuracy is 0.765\n",
      "epoch 12/20\n",
      "The test loss is 1.6231564283370972\n",
      "The test accuracy is 0.687\n",
      "At epoch 13 the loss is 1.0138994213783008\n",
      "At epoch 13 the accuracy is 0.764\n",
      "epoch 13/20\n",
      "The test loss is 1.5907328128814697\n",
      "The test accuracy is 0.691\n",
      "At epoch 14 the loss is 0.9759312156205852\n",
      "At epoch 14 the accuracy is 0.779\n",
      "epoch 14/20\n",
      "The test loss is 1.604127287864685\n",
      "The test accuracy is 0.693\n",
      "At epoch 15 the loss is 0.9451348390048951\n",
      "At epoch 15 the accuracy is 0.779\n",
      "epoch 15/20\n",
      "The test loss is 1.5778142213821411\n",
      "The test accuracy is 0.692\n",
      "At epoch 16 the loss is 0.909692876284098\n",
      "At epoch 16 the accuracy is 0.786\n",
      "epoch 16/20\n",
      "The test loss is 1.5109741687774658\n",
      "The test accuracy is 0.694\n",
      "At epoch 17 the loss is 0.8902464173165208\n",
      "At epoch 17 the accuracy is 0.791\n",
      "epoch 17/20\n",
      "The test loss is 1.4957914352416992\n",
      "The test accuracy is 0.693\n",
      "At epoch 18 the loss is 0.8617562795179401\n",
      "At epoch 18 the accuracy is 0.788\n",
      "epoch 18/20\n",
      "The test loss is 1.4793649911880493\n",
      "The test accuracy is 0.697\n",
      "At epoch 19 the loss is 0.8531956712549436\n",
      "At epoch 19 the accuracy is 0.792\n",
      "epoch 19/20\n",
      "The test loss is 1.46900475025177\n",
      "The test accuracy is 0.699\n",
      "At epoch 20 the loss is 0.8280699725911836\n",
      "At epoch 20 the accuracy is 0.797\n",
      "epoch 20/20\n",
      "The test loss is 1.4575409889221191\n",
      "The test accuracy is 0.7\n",
      "With 5 batch size and 20 epochs and 0.001 learning rate we get :\n",
      "The test loss is 1.4575412273406982\n",
      "The test accuracy is 0.7\n",
      "On the test set we obtain a loss of 1.46 and an accuracy of 0.70\n",
      "Round 4\n",
      "At epoch 1 the loss is 6.080966552452546\n",
      "At epoch 1 the accuracy is 0.556\n",
      "epoch 1/20\n",
      "The test loss is 5.429702281951904\n",
      "The test accuracy is 0.591\n",
      "At epoch 2 the loss is 3.828208740462924\n",
      "At epoch 2 the accuracy is 0.647\n",
      "epoch 2/20\n",
      "The test loss is 3.803680419921875\n",
      "The test accuracy is 0.638\n",
      "At epoch 3 the loss is 3.026437850562087\n",
      "At epoch 3 the accuracy is 0.713\n",
      "epoch 3/20\n",
      "The test loss is 3.1104440689086914\n",
      "The test accuracy is 0.669\n",
      "At epoch 4 the loss is 2.5335848094358524\n",
      "At epoch 4 the accuracy is 0.717\n",
      "epoch 4/20\n",
      "The test loss is 2.7408089637756348\n",
      "The test accuracy is 0.674\n",
      "At epoch 5 the loss is 2.184722096662613\n",
      "At epoch 5 the accuracy is 0.732\n",
      "epoch 5/20\n",
      "The test loss is 2.5506138801574707\n",
      "The test accuracy is 0.691\n",
      "At epoch 6 the loss is 1.9435351475835767\n",
      "At epoch 6 the accuracy is 0.747\n",
      "epoch 6/20\n",
      "The test loss is 2.395825147628784\n",
      "The test accuracy is 0.698\n",
      "At epoch 7 the loss is 1.7455270897218724\n",
      "At epoch 7 the accuracy is 0.75\n",
      "epoch 7/20\n",
      "The test loss is 2.362626552581787\n",
      "The test accuracy is 0.683\n",
      "At epoch 8 the loss is 1.636346458370531\n",
      "At epoch 8 the accuracy is 0.754\n",
      "epoch 8/20\n",
      "The test loss is 2.214545488357544\n",
      "The test accuracy is 0.697\n",
      "At epoch 9 the loss is 1.5330829004947726\n",
      "At epoch 9 the accuracy is 0.757\n",
      "epoch 9/20\n",
      "The test loss is 2.143221616744995\n",
      "The test accuracy is 0.709\n",
      "At epoch 10 the loss is 1.4542622043653954\n",
      "At epoch 10 the accuracy is 0.759\n",
      "epoch 10/20\n",
      "The test loss is 2.109445095062256\n",
      "The test accuracy is 0.705\n",
      "At epoch 11 the loss is 1.3697413334044852\n",
      "At epoch 11 the accuracy is 0.766\n",
      "epoch 11/20\n",
      "The test loss is 2.046985387802124\n",
      "The test accuracy is 0.701\n",
      "At epoch 12 the loss is 1.303666244130348\n",
      "At epoch 12 the accuracy is 0.781\n",
      "epoch 12/20\n",
      "The test loss is 2.0332956314086914\n",
      "The test accuracy is 0.694\n",
      "At epoch 13 the loss is 1.2488419819912675\n",
      "At epoch 13 the accuracy is 0.777\n",
      "epoch 13/20\n",
      "The test loss is 1.9974521398544312\n",
      "The test accuracy is 0.692\n",
      "At epoch 14 the loss is 1.2123182525173433\n",
      "At epoch 14 the accuracy is 0.784\n",
      "epoch 14/20\n",
      "The test loss is 1.9243261814117432\n",
      "The test accuracy is 0.698\n",
      "At epoch 15 the loss is 1.183385621367853\n",
      "At epoch 15 the accuracy is 0.781\n",
      "epoch 15/20\n",
      "The test loss is 1.8923869132995605\n",
      "The test accuracy is 0.699\n",
      "At epoch 16 the loss is 1.1377986663868205\n",
      "At epoch 16 the accuracy is 0.786\n",
      "epoch 16/20\n",
      "The test loss is 1.8820500373840332\n",
      "The test accuracy is 0.701\n",
      "At epoch 17 the loss is 1.1100596869342008\n",
      "At epoch 17 the accuracy is 0.791\n",
      "epoch 17/20\n",
      "The test loss is 1.8603813648223877\n",
      "The test accuracy is 0.697\n",
      "At epoch 18 the loss is 1.0903943881608302\n",
      "At epoch 18 the accuracy is 0.792\n",
      "epoch 18/20\n",
      "The test loss is 1.8625233173370361\n",
      "The test accuracy is 0.695\n",
      "At epoch 19 the loss is 1.0670203582563682\n",
      "At epoch 19 the accuracy is 0.802\n",
      "epoch 19/20\n",
      "The test loss is 1.8310604095458984\n",
      "The test accuracy is 0.698\n",
      "At epoch 20 the loss is 1.0510490966903483\n",
      "At epoch 20 the accuracy is 0.793\n",
      "epoch 20/20\n",
      "The test loss is 1.8685096502304077\n",
      "The test accuracy is 0.7\n",
      "With 5 batch size and 20 epochs and 0.001 learning rate we get :\n",
      "The test loss is 1.8685095310211182\n",
      "The test accuracy is 0.7\n",
      "On the test set we obtain a loss of 1.87 and an accuracy of 0.70\n",
      "Round 5\n",
      "At epoch 1 the loss is 8.120235899437585\n",
      "At epoch 1 the accuracy is 0.517\n",
      "epoch 1/20\n",
      "The test loss is 6.920555114746094\n",
      "The test accuracy is 0.563\n",
      "At epoch 2 the loss is 5.814941186857822\n",
      "At epoch 2 the accuracy is 0.596\n",
      "epoch 2/20\n",
      "The test loss is 5.288015842437744\n",
      "The test accuracy is 0.608\n",
      "At epoch 3 the loss is 4.45754998576993\n",
      "At epoch 3 the accuracy is 0.654\n",
      "epoch 3/20\n",
      "The test loss is 4.233293056488037\n",
      "The test accuracy is 0.637\n",
      "At epoch 4 the loss is 3.762203624664353\n",
      "At epoch 4 the accuracy is 0.686\n",
      "epoch 4/20\n",
      "The test loss is 3.7180826663970947\n",
      "The test accuracy is 0.661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 5 the loss is 3.2809466743022613\n",
      "At epoch 5 the accuracy is 0.697\n",
      "epoch 5/20\n",
      "The test loss is 3.5567634105682373\n",
      "The test accuracy is 0.67\n",
      "At epoch 6 the loss is 3.018751443030803\n",
      "At epoch 6 the accuracy is 0.716\n",
      "epoch 6/20\n",
      "The test loss is 3.1936569213867188\n",
      "The test accuracy is 0.681\n",
      "At epoch 7 the loss is 2.7298477278975586\n",
      "At epoch 7 the accuracy is 0.729\n",
      "epoch 7/20\n",
      "The test loss is 3.0292410850524902\n",
      "The test accuracy is 0.687\n",
      "At epoch 8 the loss is 2.521595188907854\n",
      "At epoch 8 the accuracy is 0.745\n",
      "epoch 8/20\n",
      "The test loss is 2.935152053833008\n",
      "The test accuracy is 0.695\n",
      "At epoch 9 the loss is 2.3683678998218443\n",
      "At epoch 9 the accuracy is 0.752\n",
      "epoch 9/20\n",
      "The test loss is 2.8265371322631836\n",
      "The test accuracy is 0.692\n",
      "At epoch 10 the loss is 2.189604528070215\n",
      "At epoch 10 the accuracy is 0.756\n",
      "epoch 10/20\n",
      "The test loss is 2.6146457195281982\n",
      "The test accuracy is 0.691\n",
      "At epoch 11 the loss is 2.0346364576890776\n",
      "At epoch 11 the accuracy is 0.754\n",
      "epoch 11/20\n",
      "The test loss is 2.6432642936706543\n",
      "The test accuracy is 0.695\n",
      "At epoch 12 the loss is 1.8671425496564036\n",
      "At epoch 12 the accuracy is 0.762\n",
      "epoch 12/20\n",
      "The test loss is 2.339034080505371\n",
      "The test accuracy is 0.694\n",
      "At epoch 13 the loss is 1.7662535707556197\n",
      "At epoch 13 the accuracy is 0.77\n",
      "epoch 13/20\n",
      "The test loss is 2.311204671859741\n",
      "The test accuracy is 0.694\n",
      "At epoch 14 the loss is 1.6990313593032282\n",
      "At epoch 14 the accuracy is 0.771\n",
      "epoch 14/20\n",
      "The test loss is 2.2449588775634766\n",
      "The test accuracy is 0.696\n",
      "At epoch 15 the loss is 1.6238856427573967\n",
      "At epoch 15 the accuracy is 0.777\n",
      "epoch 15/20\n",
      "The test loss is 2.2913026809692383\n",
      "The test accuracy is 0.694\n",
      "At epoch 16 the loss is 1.5935337638030653\n",
      "At epoch 16 the accuracy is 0.78\n",
      "epoch 16/20\n",
      "The test loss is 2.17458438873291\n",
      "The test accuracy is 0.695\n",
      "At epoch 17 the loss is 1.5419633171645473\n",
      "At epoch 17 the accuracy is 0.777\n",
      "epoch 17/20\n",
      "The test loss is 2.1666128635406494\n",
      "The test accuracy is 0.692\n",
      "At epoch 18 the loss is 1.4741408580930755\n",
      "At epoch 18 the accuracy is 0.777\n",
      "epoch 18/20\n",
      "The test loss is 2.0977938175201416\n",
      "The test accuracy is 0.696\n",
      "At epoch 19 the loss is 1.4222716147051977\n",
      "At epoch 19 the accuracy is 0.779\n",
      "epoch 19/20\n",
      "The test loss is 2.12424373626709\n",
      "The test accuracy is 0.694\n",
      "At epoch 20 the loss is 1.401513381341283\n",
      "At epoch 20 the accuracy is 0.784\n",
      "epoch 20/20\n",
      "The test loss is 2.063667058944702\n",
      "The test accuracy is 0.692\n",
      "With 5 batch size and 20 epochs and 0.001 learning rate we get :\n",
      "The test loss is 2.0636682510375977\n",
      "The test accuracy is 0.692\n",
      "On the test set we obtain a loss of 2.06 and an accuracy of 0.69\n",
      "Round 6\n",
      "At epoch 1 the loss is 6.3501854149758\n",
      "At epoch 1 the accuracy is 0.59\n",
      "epoch 1/20\n",
      "The test loss is 5.1591949462890625\n",
      "The test accuracy is 0.618\n",
      "At epoch 2 the loss is 4.144265065976101\n",
      "At epoch 2 the accuracy is 0.649\n",
      "epoch 2/20\n",
      "The test loss is 3.670736789703369\n",
      "The test accuracy is 0.67\n",
      "At epoch 3 the loss is 3.2166468081704114\n",
      "At epoch 3 the accuracy is 0.705\n",
      "epoch 3/20\n",
      "The test loss is 3.108146905899048\n",
      "The test accuracy is 0.686\n",
      "At epoch 4 the loss is 2.7133102824939783\n",
      "At epoch 4 the accuracy is 0.715\n",
      "epoch 4/20\n",
      "The test loss is 3.1403098106384277\n",
      "The test accuracy is 0.695\n",
      "At epoch 5 the loss is 2.3640531798284576\n",
      "At epoch 5 the accuracy is 0.734\n",
      "epoch 5/20\n",
      "The test loss is 2.4524292945861816\n",
      "The test accuracy is 0.707\n",
      "At epoch 6 the loss is 2.0816291409882592\n",
      "At epoch 6 the accuracy is 0.736\n",
      "epoch 6/20\n",
      "The test loss is 2.24993896484375\n",
      "The test accuracy is 0.692\n",
      "At epoch 7 the loss is 1.8955067431950297\n",
      "At epoch 7 the accuracy is 0.748\n",
      "epoch 7/20\n",
      "The test loss is 2.27240252494812\n",
      "The test accuracy is 0.722\n",
      "At epoch 8 the loss is 1.7865712491940142\n",
      "At epoch 8 the accuracy is 0.739\n",
      "epoch 8/20\n",
      "The test loss is 2.0496344566345215\n",
      "The test accuracy is 0.72\n",
      "At epoch 9 the loss is 1.5926420496497553\n",
      "At epoch 9 the accuracy is 0.751\n",
      "epoch 9/20\n",
      "The test loss is 1.9282722473144531\n",
      "The test accuracy is 0.723\n",
      "At epoch 10 the loss is 1.4711326556487803\n",
      "At epoch 10 the accuracy is 0.761\n",
      "epoch 10/20\n",
      "The test loss is 1.81914484500885\n",
      "The test accuracy is 0.719\n",
      "At epoch 11 the loss is 1.3761920531669625\n",
      "At epoch 11 the accuracy is 0.766\n",
      "epoch 11/20\n",
      "The test loss is 1.8431323766708374\n",
      "The test accuracy is 0.72\n",
      "At epoch 12 the loss is 1.324430236347083\n",
      "At epoch 12 the accuracy is 0.776\n",
      "epoch 12/20\n",
      "The test loss is 1.7835395336151123\n",
      "The test accuracy is 0.725\n",
      "At epoch 13 the loss is 1.2497493394149024\n",
      "At epoch 13 the accuracy is 0.772\n",
      "epoch 13/20\n",
      "The test loss is 1.6662367582321167\n",
      "The test accuracy is 0.714\n",
      "At epoch 14 the loss is 1.2294786569964191\n",
      "At epoch 14 the accuracy is 0.767\n",
      "epoch 14/20\n",
      "The test loss is 1.6918212175369263\n",
      "The test accuracy is 0.726\n",
      "At epoch 15 the loss is 1.2026717633691693\n",
      "At epoch 15 the accuracy is 0.776\n",
      "epoch 15/20\n",
      "The test loss is 1.6618030071258545\n",
      "The test accuracy is 0.723\n",
      "At epoch 16 the loss is 1.156299671823308\n",
      "At epoch 16 the accuracy is 0.777\n",
      "epoch 16/20\n",
      "The test loss is 1.603669285774231\n",
      "The test accuracy is 0.715\n",
      "At epoch 17 the loss is 1.1204302702545157\n",
      "At epoch 17 the accuracy is 0.777\n",
      "epoch 17/20\n",
      "The test loss is 1.5926495790481567\n",
      "The test accuracy is 0.721\n",
      "At epoch 18 the loss is 1.0821106923968897\n",
      "At epoch 18 the accuracy is 0.776\n",
      "epoch 18/20\n",
      "The test loss is 1.5780222415924072\n",
      "The test accuracy is 0.719\n",
      "At epoch 19 the loss is 1.0661869947000742\n",
      "At epoch 19 the accuracy is 0.775\n",
      "epoch 19/20\n",
      "The test loss is 1.579517126083374\n",
      "The test accuracy is 0.721\n",
      "At epoch 20 the loss is 1.0489153634556714\n",
      "At epoch 20 the accuracy is 0.783\n",
      "epoch 20/20\n",
      "The test loss is 1.551734209060669\n",
      "The test accuracy is 0.717\n",
      "With 5 batch size and 20 epochs and 0.001 learning rate we get :\n",
      "The test loss is 1.5517343282699585\n",
      "The test accuracy is 0.717\n",
      "On the test set we obtain a loss of 1.55 and an accuracy of 0.72\n",
      "Round 7\n",
      "At epoch 1 the loss is 5.618579940587381\n",
      "At epoch 1 the accuracy is 0.573\n",
      "epoch 1/20\n",
      "The test loss is 4.621758937835693\n",
      "The test accuracy is 0.593\n",
      "At epoch 2 the loss is 3.8557448037838005\n",
      "At epoch 2 the accuracy is 0.636\n",
      "epoch 2/20\n",
      "The test loss is 3.5897035598754883\n",
      "The test accuracy is 0.645\n",
      "At epoch 3 the loss is 3.247488912497764\n",
      "At epoch 3 the accuracy is 0.677\n",
      "epoch 3/20\n",
      "The test loss is 3.19299054145813\n",
      "The test accuracy is 0.652\n",
      "At epoch 4 the loss is 2.627742236874789\n",
      "At epoch 4 the accuracy is 0.699\n",
      "epoch 4/20\n",
      "The test loss is 2.8116097450256348\n",
      "The test accuracy is 0.666\n",
      "At epoch 5 the loss is 2.3022570040939287\n",
      "At epoch 5 the accuracy is 0.719\n",
      "epoch 5/20\n",
      "The test loss is 2.5695135593414307\n",
      "The test accuracy is 0.672\n",
      "At epoch 6 the loss is 2.0746105661830616\n",
      "At epoch 6 the accuracy is 0.728\n",
      "epoch 6/20\n",
      "The test loss is 2.4410390853881836\n",
      "The test accuracy is 0.683\n",
      "At epoch 7 the loss is 1.8655210294469913\n",
      "At epoch 7 the accuracy is 0.736\n",
      "epoch 7/20\n",
      "The test loss is 2.1897263526916504\n",
      "The test accuracy is 0.681\n",
      "At epoch 8 the loss is 1.6960422986250956\n",
      "At epoch 8 the accuracy is 0.752\n",
      "epoch 8/20\n",
      "The test loss is 2.109788179397583\n",
      "The test accuracy is 0.68\n",
      "At epoch 9 the loss is 1.5495290459362332\n",
      "At epoch 9 the accuracy is 0.754\n",
      "epoch 9/20\n",
      "The test loss is 2.052213430404663\n",
      "The test accuracy is 0.679\n",
      "At epoch 10 the loss is 1.4360677335157925\n",
      "At epoch 10 the accuracy is 0.766\n",
      "epoch 10/20\n",
      "The test loss is 1.933385968208313\n",
      "The test accuracy is 0.685\n",
      "At epoch 11 the loss is 1.358979938780576\n",
      "At epoch 11 the accuracy is 0.772\n",
      "epoch 11/20\n",
      "The test loss is 1.9145464897155762\n",
      "The test accuracy is 0.68\n",
      "At epoch 12 the loss is 1.3037171550832818\n",
      "At epoch 12 the accuracy is 0.77\n",
      "epoch 12/20\n",
      "The test loss is 1.8454691171646118\n",
      "The test accuracy is 0.687\n",
      "At epoch 13 the loss is 1.2486425171684823\n",
      "At epoch 13 the accuracy is 0.782\n",
      "epoch 13/20\n",
      "The test loss is 1.7888820171356201\n",
      "The test accuracy is 0.694\n",
      "At epoch 14 the loss is 1.2090907360328584\n",
      "At epoch 14 the accuracy is 0.793\n",
      "epoch 14/20\n",
      "The test loss is 1.7615244388580322\n",
      "The test accuracy is 0.696\n",
      "At epoch 15 the loss is 1.1456765083034361\n",
      "At epoch 15 the accuracy is 0.786\n",
      "epoch 15/20\n",
      "The test loss is 1.7610801458358765\n",
      "The test accuracy is 0.697\n",
      "At epoch 16 the loss is 1.126322384840314\n",
      "At epoch 16 the accuracy is 0.784\n",
      "epoch 16/20\n",
      "The test loss is 1.690346121788025\n",
      "The test accuracy is 0.7\n",
      "At epoch 17 the loss is 1.0950887344498994\n",
      "At epoch 17 the accuracy is 0.787\n",
      "epoch 17/20\n",
      "The test loss is 1.6699650287628174\n",
      "The test accuracy is 0.703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 18 the loss is 1.0699016274737188\n",
      "At epoch 18 the accuracy is 0.788\n",
      "epoch 18/20\n",
      "The test loss is 1.654755711555481\n",
      "The test accuracy is 0.705\n",
      "At epoch 19 the loss is 1.0509642232670557\n",
      "At epoch 19 the accuracy is 0.79\n",
      "epoch 19/20\n",
      "The test loss is 1.6395505666732788\n",
      "The test accuracy is 0.703\n",
      "At epoch 20 the loss is 1.023572402400241\n",
      "At epoch 20 the accuracy is 0.791\n",
      "epoch 20/20\n",
      "The test loss is 1.6194223165512085\n",
      "The test accuracy is 0.7\n",
      "With 5 batch size and 20 epochs and 0.001 learning rate we get :\n",
      "The test loss is 1.6194214820861816\n",
      "The test accuracy is 0.7\n",
      "On the test set we obtain a loss of 1.62 and an accuracy of 0.70\n",
      "Round 8\n",
      "At epoch 1 the loss is 4.496217960462345\n",
      "At epoch 1 the accuracy is 0.622\n",
      "epoch 1/20\n",
      "The test loss is 3.6201348304748535\n",
      "The test accuracy is 0.678\n",
      "At epoch 2 the loss is 3.1720415491462246\n",
      "At epoch 2 the accuracy is 0.675\n",
      "epoch 2/20\n",
      "The test loss is 3.260530710220337\n",
      "The test accuracy is 0.691\n",
      "At epoch 3 the loss is 2.7379823205967826\n",
      "At epoch 3 the accuracy is 0.694\n",
      "epoch 3/20\n",
      "The test loss is 2.900886058807373\n",
      "The test accuracy is 0.7\n",
      "At epoch 4 the loss is 2.4368434605444556\n",
      "At epoch 4 the accuracy is 0.719\n",
      "epoch 4/20\n",
      "The test loss is 2.642199993133545\n",
      "The test accuracy is 0.713\n",
      "At epoch 5 the loss is 2.2140521001187636\n",
      "At epoch 5 the accuracy is 0.733\n",
      "epoch 5/20\n",
      "The test loss is 2.561091661453247\n",
      "The test accuracy is 0.721\n",
      "At epoch 6 the loss is 1.9567881750845604\n",
      "At epoch 6 the accuracy is 0.729\n",
      "epoch 6/20\n",
      "The test loss is 2.7119343280792236\n",
      "The test accuracy is 0.704\n",
      "At epoch 7 the loss is 1.8051317619511225\n",
      "At epoch 7 the accuracy is 0.735\n",
      "epoch 7/20\n",
      "The test loss is 2.301166296005249\n",
      "The test accuracy is 0.709\n",
      "At epoch 8 the loss is 1.6958926907232978\n",
      "At epoch 8 the accuracy is 0.757\n",
      "epoch 8/20\n",
      "The test loss is 2.272404670715332\n",
      "The test accuracy is 0.709\n",
      "At epoch 9 the loss is 1.5750028930471125\n",
      "At epoch 9 the accuracy is 0.761\n",
      "epoch 9/20\n",
      "The test loss is 2.109135627746582\n",
      "The test accuracy is 0.712\n",
      "At epoch 10 the loss is 1.4682524271662443\n",
      "At epoch 10 the accuracy is 0.765\n",
      "epoch 10/20\n",
      "The test loss is 2.037890911102295\n",
      "The test accuracy is 0.712\n",
      "At epoch 11 the loss is 1.3456192162810539\n",
      "At epoch 11 the accuracy is 0.758\n",
      "epoch 11/20\n",
      "The test loss is 2.0410077571868896\n",
      "The test accuracy is 0.716\n",
      "At epoch 12 the loss is 1.3139158889442841\n",
      "At epoch 12 the accuracy is 0.772\n",
      "epoch 12/20\n",
      "The test loss is 2.0073838233947754\n",
      "The test accuracy is 0.713\n",
      "At epoch 13 the loss is 1.2444242049574314\n",
      "At epoch 13 the accuracy is 0.774\n",
      "epoch 13/20\n",
      "The test loss is 1.9475889205932617\n",
      "The test accuracy is 0.716\n",
      "At epoch 14 the loss is 1.1774030243219693\n",
      "At epoch 14 the accuracy is 0.775\n",
      "epoch 14/20\n",
      "The test loss is 1.9759761095046997\n",
      "The test accuracy is 0.709\n",
      "At epoch 15 the loss is 1.1334164445075772\n",
      "At epoch 15 the accuracy is 0.774\n",
      "epoch 15/20\n",
      "The test loss is 1.89267897605896\n",
      "The test accuracy is 0.711\n",
      "At epoch 16 the loss is 1.1159180562439723\n",
      "At epoch 16 the accuracy is 0.773\n",
      "epoch 16/20\n",
      "The test loss is 1.8800702095031738\n",
      "The test accuracy is 0.71\n",
      "At epoch 17 the loss is 1.064715631571089\n",
      "At epoch 17 the accuracy is 0.776\n",
      "epoch 17/20\n",
      "The test loss is 1.8912729024887085\n",
      "The test accuracy is 0.703\n",
      "At epoch 18 the loss is 1.044963182344436\n",
      "At epoch 18 the accuracy is 0.778\n",
      "epoch 18/20\n",
      "The test loss is 1.7927982807159424\n",
      "The test accuracy is 0.71\n",
      "At epoch 19 the loss is 1.0204326772334753\n",
      "At epoch 19 the accuracy is 0.777\n",
      "epoch 19/20\n",
      "The test loss is 1.7907025814056396\n",
      "The test accuracy is 0.708\n",
      "At epoch 20 the loss is 0.9961674294104159\n",
      "At epoch 20 the accuracy is 0.781\n",
      "epoch 20/20\n",
      "The test loss is 1.7658836841583252\n",
      "The test accuracy is 0.713\n",
      "With 5 batch size and 20 epochs and 0.001 learning rate we get :\n",
      "The test loss is 1.7658833265304565\n",
      "The test accuracy is 0.713\n",
      "On the test set we obtain a loss of 1.77 and an accuracy of 0.71\n",
      "Round 9\n",
      "At epoch 1 the loss is 6.903410305996135\n",
      "At epoch 1 the accuracy is 0.57\n",
      "epoch 1/20\n",
      "The test loss is 4.385149002075195\n",
      "The test accuracy is 0.629\n",
      "At epoch 2 the loss is 3.973683811131374\n",
      "At epoch 2 the accuracy is 0.673\n",
      "epoch 2/20\n",
      "The test loss is 3.2188172340393066\n",
      "The test accuracy is 0.679\n",
      "At epoch 3 the loss is 3.1826595261477904\n",
      "At epoch 3 the accuracy is 0.707\n",
      "epoch 3/20\n",
      "The test loss is 2.8184800148010254\n",
      "The test accuracy is 0.706\n",
      "At epoch 4 the loss is 2.7116442567035564\n",
      "At epoch 4 the accuracy is 0.725\n",
      "epoch 4/20\n",
      "The test loss is 2.5793917179107666\n",
      "The test accuracy is 0.71\n",
      "At epoch 5 the loss is 2.2838632901559874\n",
      "At epoch 5 the accuracy is 0.738\n",
      "epoch 5/20\n",
      "The test loss is 2.492727279663086\n",
      "The test accuracy is 0.703\n",
      "At epoch 6 the loss is 2.0362609245683005\n",
      "At epoch 6 the accuracy is 0.758\n",
      "epoch 6/20\n",
      "The test loss is 2.386869430541992\n",
      "The test accuracy is 0.707\n",
      "At epoch 7 the loss is 1.826028881373452\n",
      "At epoch 7 the accuracy is 0.757\n",
      "epoch 7/20\n",
      "The test loss is 2.2694759368896484\n",
      "The test accuracy is 0.714\n",
      "At epoch 8 the loss is 1.6606853860250144\n",
      "At epoch 8 the accuracy is 0.771\n",
      "epoch 8/20\n",
      "The test loss is 2.195896863937378\n",
      "The test accuracy is 0.711\n",
      "At epoch 9 the loss is 1.5539225451918275\n",
      "At epoch 9 the accuracy is 0.768\n",
      "epoch 9/20\n",
      "The test loss is 2.2779572010040283\n",
      "The test accuracy is 0.704\n",
      "At epoch 10 the loss is 1.4703822874881824\n",
      "At epoch 10 the accuracy is 0.782\n",
      "epoch 10/20\n",
      "The test loss is 2.1024551391601562\n",
      "The test accuracy is 0.713\n",
      "At epoch 11 the loss is 1.360666179745349\n",
      "At epoch 11 the accuracy is 0.778\n",
      "epoch 11/20\n",
      "The test loss is 2.063581705093384\n",
      "The test accuracy is 0.702\n",
      "At epoch 12 the loss is 1.2834018829532396\n",
      "At epoch 12 the accuracy is 0.796\n",
      "epoch 12/20\n",
      "The test loss is 2.0288338661193848\n",
      "The test accuracy is 0.702\n",
      "At epoch 13 the loss is 1.2523295548037323\n",
      "At epoch 13 the accuracy is 0.793\n",
      "epoch 13/20\n",
      "The test loss is 2.030730962753296\n",
      "The test accuracy is 0.701\n",
      "At epoch 14 the loss is 1.2167984119537822\n",
      "At epoch 14 the accuracy is 0.798\n",
      "epoch 14/20\n",
      "The test loss is 1.9744473695755005\n",
      "The test accuracy is 0.705\n",
      "At epoch 15 the loss is 1.1612186605713213\n",
      "At epoch 15 the accuracy is 0.8\n",
      "epoch 15/20\n",
      "The test loss is 1.9966027736663818\n",
      "The test accuracy is 0.699\n",
      "At epoch 16 the loss is 1.136742977887343\n",
      "At epoch 16 the accuracy is 0.793\n",
      "epoch 16/20\n",
      "The test loss is 1.946853756904602\n",
      "The test accuracy is 0.709\n",
      "At epoch 17 the loss is 1.096428503986059\n",
      "At epoch 17 the accuracy is 0.807\n",
      "epoch 17/20\n",
      "The test loss is 1.9280071258544922\n",
      "The test accuracy is 0.701\n",
      "At epoch 18 the loss is 1.0791131046988676\n",
      "At epoch 18 the accuracy is 0.806\n",
      "epoch 18/20\n",
      "The test loss is 1.9197356700897217\n",
      "The test accuracy is 0.701\n",
      "At epoch 19 the loss is 1.0480583720977688\n",
      "At epoch 19 the accuracy is 0.808\n",
      "epoch 19/20\n",
      "The test loss is 1.8773460388183594\n",
      "The test accuracy is 0.708\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-06e708bc9ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBasicNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtraining_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_basic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.00001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep Learning\\project1 Ghassen\\DeepLearning\\project_1\\train.py\u001b[0m in \u001b[0;36mtrain_basic\u001b[1;34m(model, dataloader, test_dataloader, epochs, learning_rate)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0maccuracy_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mind_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "round_results = [] #3D\n",
    "    \n",
    "for i in range(rounds):\n",
    "    print(\"Round {0}\".format(i))\n",
    "\n",
    "    results = [] #training_losses, training_acc, test_losses, test_acc\n",
    "    \n",
    "    model = BasicNet()\n",
    "    \n",
    "    training_losses, training_acc, test_losses, test_acc = train_basic(model, train_dataloader, test_dataloader, epochs = config.EPOCHS,  learning_rate= 0.00001)\n",
    "\n",
    "    results.append([training_losses, training_acc, test_losses, test_acc])\n",
    "              \n",
    "    print(\"With {0} batch size and {1} epochs and {2} learning rate we get :\".format(config.TRAIN_BATCH_SIZE, config.EPOCHS, config.LEARNING_RATE))\n",
    "    \n",
    "    final_test_loss, final_test_loss_acc = predict_basic(model, test_dataloader)\n",
    "    print(\"On the test set we obtain a loss of {:.2f} and an accuracy of {:.2f}\".format(final_test_loss,final_test_loss_acc))\n",
    "      \n",
    "    round_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array(round_results).mean(axis= 0).reshape((4,20))\n",
    "std  = np.array(round_results).std(axis = 0).reshape((4,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize= (14,8))\n",
    "\n",
    "ax1.plot(means[0], color = 'r', label = 'training loss')\n",
    "ax1.plot(means[2], color = 'b',  linestyle='dashed', label = 'test loss')\n",
    "        \n",
    "ax1.fill_between(range(len(means[0])), means[0] - std[0], means[0] + std[0], alpha = 0.2, color = 'r')\n",
    "ax1.fill_between(range(len(means[2])), means[2] - std[2], means[2] + std[2], alpha = 0.2, color = 'b')\n",
    "\n",
    "ax2.plot(means[1], color = 'r', label = 'training accuracy')\n",
    "ax2.plot(means[3], color = 'b', linestyle='dashed', label = 'test accuracy')\n",
    "\n",
    "ax2.fill_between(range(len(means[1])), means[1]- std[1], means[1]+ std[1], alpha = 0.2, color = 'r')\n",
    "ax2.fill_between(range(len(means[3])), means[3]- std[3], means[3]+ std[3], alpha = 0.2, color = 'b')\n",
    "\n",
    "ax1.set_title('Training Binary Cross Entropy Loss')\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"BCE\")\n",
    "\n",
    "ax2.set_title('Training accuracy}')\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax1.legend(loc = 'upper right')\n",
    "ax2.legend(loc = 'lower right')\n",
    "plt.subplots_adjust(left=0.07, right=0.93, wspace=0.25, hspace=0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to assess the difference w/o aux loss and weight sharing for each subnet configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = [\n",
    "    (weight_sharing, aux_loss)\n",
    "    \n",
    "    for weight_sharing in [False,True]\n",
    "    for aux_loss in [False,True]\n",
    "]\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_hid_inner = 2\n",
    "hid_inner = 128\n",
    "nb_hid_out = 2\n",
    "hid_outer = 256\n",
    "alpha = 0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results_fcn(subnet_type, cnn_nb_hidden_layers = config.FCN_NB_HIDDEN, \n",
    "                    hidden_layer = config.FCN_HIDDEN_LAYER,\n",
    "                    nb_hidden_layers_out = config.SIAMESE_NET_NB_HIDDEN,\n",
    "                    hidden_layer_out = config.SIAMESE_NET_HIDDEN_LAYER,\n",
    "                    alpha = config.ALPHA): \n",
    "\n",
    "    round_results = []\n",
    "\n",
    "    for i in range(rounds):\n",
    "        results = [] #training_losses, training_acc, test_losses, test_acc\n",
    "        \n",
    "        for weight_sharing, aux_loss in configuration:\n",
    "            subnet1 = FCN(nb_hidden_layers, hidden_layer)\n",
    "            subnet2 = FCN(nb_hidden_layers, hidden_layer)\n",
    "            \n",
    "            print('Model for weight_sharing = {0} and aux loss = {1} on round {2} with subnet {3}'.format(weight_sharing, aux_loss, \n",
    "                                                                                                          i,subnet_type))\n",
    "            \n",
    "            if(weight_sharing):\n",
    "                model = SiameseNet(subnet1, None, nb_hidden_layers_out, hidden_layer_out)\n",
    "            else: \n",
    "                model = SiameseNet(subnet1, subnet2, nb_hidden_layers_out, hidden_layer_out)\n",
    "            \n",
    "            training_losses, training_acc, _, _, test_losses, test_acc, _, _ = train_siamese(\n",
    "                    model = model, dataloader = train_dataloader, test_dataloader = test_dataloader, aux_loss = aux_loss, alpha = alpha)        \n",
    "            \n",
    "            final_test_loss, final_test_loss_acc, _, _ = predict_siamese(model, test_dataloader, aux_loss, alpha)\n",
    "            print(\"In epoch 20, on the test set we obtain a loss of {:.2f} and an accuracy of {:.2f}\".format(final_test_loss,final_test_loss_acc))\n",
    "            results.append([training_losses, training_acc, test_losses, test_acc])\n",
    "\n",
    "        round_results.append(results)\n",
    "\n",
    "    return round_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results_cnn(subnet_type, nb_hidden_layers = config.CNN_NB_HIDDEN, \n",
    "                    base_channel_size = config.CNN_BASE_CHANNEL_SIZE, \n",
    "                    hidden_layer = config.CNN_HIDDEN_LAYER,\n",
    "                    kernel_size = config.CNN_KERNEL_SIZE,\n",
    "                    nb_hidden_layers_out = config.SIAMESE_NET_NB_HIDDEN,\n",
    "                    hidden_layer_out = config.SIAMESE_NET_HIDDEN_LAYER,\n",
    "                    alpha = config.ALPHA): \n",
    "\n",
    "    round_results = []\n",
    "\n",
    "    for i in range(rounds):\n",
    "        results = [] #training_losses, training_acc, test_losses, test_acc\n",
    "        \n",
    "        for weight_sharing, aux_loss in configuration:\n",
    "            subnet1 = CNN(nb_hidden_layers, base_channel_size, hidden_layer, kernel_size)\n",
    "            subnet2 = CNN(nb_hidden_layers, base_channel_size, hidden_layer, kernel_size)\n",
    "            \n",
    "            print('Model for weight_sharing = {0} and aux loss = {1} on round {2} with subnet {3}'.format(weight_sharing, aux_loss, \n",
    "                                                                                                          i,subnet_type))\n",
    "            \n",
    "            if(weight_sharing):\n",
    "                model = SiameseNet(subnet1, None, nb_hidden_layers_out, hidden_layer_out)\n",
    "            else: \n",
    "                model = SiameseNet(subnet1, subnet2, nb_hidden_layers_out, hidden_layer_out)\n",
    "            \n",
    "            training_losses, training_acc, _, _, test_losses, test_acc, _, _ = train_siamese(\n",
    "                    model = model, dataloader = train_dataloader, test_dataloader = test_dataloader, aux_loss = aux_loss, alpha = alpha)        \n",
    "            \n",
    "            final_test_loss, final_test_loss_acc, _, _ = predict_siamese(model, test_dataloader, aux_loss, alpha)\n",
    "            print(\"In epoch 20, on the test set we obtain a loss of {:.2f} and an accuracy of {:.2f}\".format(final_test_loss,final_test_loss_acc))\n",
    "            results.append([training_losses, training_acc, test_losses, test_acc])\n",
    "\n",
    "        round_results.append(results)\n",
    "\n",
    "    return round_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_results(round_results, subnet_type):\n",
    "    \n",
    "    colors = ['b', 'g', 'r', 'm']\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize= (14,8))\n",
    "\n",
    "    means = np.array(round_results).mean(axis= 0)\n",
    "    std  = np.array(round_results).std(axis = 0)\n",
    "    dict_word = {False :'without', True : 'with'}\n",
    "    for i, (r,s,p) in enumerate( zip(means,std,configuration) ):\n",
    "\n",
    "        ax1.plot(r[0], color = colors[i], label = 'training loss {0} WS and {1} AL'.format(dict_word[p[0]], dict_word[p[1]]))\n",
    "        ax1.plot(r[2], color = colors[i],  linestyle='dashed', label = 'test loss {0} WS and {1} AL'.format(dict_word[p[0]], dict_word[p[1]]))\n",
    "\n",
    "        ax1.fill_between(range(len(r[0])), r[0] - s[0], r[0]+ s[0], alpha = 0.2, color = colors[i])\n",
    "        ax1.fill_between(range(len(r[2])), r[2]- s[2], r[2]+ s[2], alpha = 0.2, color = colors[i])\n",
    "\n",
    "        ax2.plot(r[1], color = colors[i], label = 'training accuracy {0} WS and {1} AL'.format(dict_word[p[0]], dict_word[p[1]]))\n",
    "        ax2.plot(r[3], color = colors[i], linestyle='dashed', label = 'test accuracy {0} WS and {1} AL'.format(dict_word[p[0]], dict_word[p[1]]))\n",
    "\n",
    "        ax2.fill_between(range(len(r[1])), r[1]- s[1], r[1]+ s[1], alpha = 0.2, color = colors[i])\n",
    "        ax2.fill_between(range(len(r[3])), r[3]- s[3], r[3]+ s[3], alpha = 0.2, color = colors[i])\n",
    "\n",
    "    ax1.set_title('Training Binary Cross Entropy with {0} subnets'.format(subnet_type))\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"BCE\")\n",
    "\n",
    "    ax2.set_title('Training accuracy with {0} subnets'.format(subnet_type))\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "\n",
    "    ax1.legend(loc = 'upper right')\n",
    "    ax2.legend(loc = 'lower right')\n",
    "    plt.subplots_adjust(left=0.07, right=0.93, wspace=0.25, hspace=0.35)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subnets : FCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (hiddens): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=196, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2)\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for weight_sharing = False and aux loss = False on round 0 with subnet FCN\n",
      "At epoch 1 the training loss is 0.7093432312831283\n",
      "At epoch 1 the training accuracy is 0.67\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.512701566349715\n",
      "At epoch 2 the training accuracy is 0.767\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.43372718602418897\n",
      "At epoch 3 the training accuracy is 0.796\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.3627730870619416\n",
      "At epoch 4 the training accuracy is 0.842\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.30547858572099357\n",
      "At epoch 5 the training accuracy is 0.858\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.2500088803895051\n",
      "At epoch 6 the training accuracy is 0.891\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.24746858013531892\n",
      "At epoch 7 the training accuracy is 0.895\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.19546023795963266\n",
      "At epoch 8 the training accuracy is 0.926\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.15647080349706813\n",
      "At epoch 9 the training accuracy is 0.936\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.13177371335128554\n",
      "At epoch 10 the training accuracy is 0.955\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.11108204836582444\n",
      "At epoch 11 the training accuracy is 0.958\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.08448328442459342\n",
      "At epoch 12 the training accuracy is 0.971\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.05657927575393842\n",
      "At epoch 13 the training accuracy is 0.986\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.059532499353205266\n",
      "At epoch 14 the training accuracy is 0.978\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.06086204978154285\n",
      "At epoch 15 the training accuracy is 0.981\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.060240748071537384\n",
      "At epoch 16 the training accuracy is 0.979\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.040439451961465235\n",
      "At epoch 17 the training accuracy is 0.986\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.04806257007673992\n",
      "At epoch 18 the training accuracy is 0.985\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.025852846965771902\n",
      "At epoch 19 the training accuracy is 0.991\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.02604675733198917\n",
      "At epoch 20 the training accuracy is 0.992\n",
      "epoch 20/20\n",
      "The test loss is 0.7114266157150269\n",
      "The test accuracy is 0.845\n",
      "In epoch 20, on the test set we obtain a loss of 0.71 and an accuracy of 0.84\n",
      "Model for weight_sharing = False and aux loss = True on round 0 with subnet FCN\n",
      "At epoch 1 the training loss is 2.6855472111701966\n",
      "At epoch 1 the training accuracy is 0.645\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.7759703405201435\n",
      "At epoch 2 the training accuracy is 0.743\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.578925211019814\n",
      "At epoch 3 the training accuracy is 0.802\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.4813825786858797\n",
      "At epoch 4 the training accuracy is 0.806\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.40714338776655495\n",
      "At epoch 5 the training accuracy is 0.841\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.35331427421420813\n",
      "At epoch 6 the training accuracy is 0.856\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.28494968006387356\n",
      "At epoch 7 the training accuracy is 0.876\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.25947707014158367\n",
      "At epoch 8 the training accuracy is 0.899\n",
      "epoch 8/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-2d0a856bbcf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mround_results_FCN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FCN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-96-aa9c31983981>\u001b[0m in \u001b[0;36mcompute_results\u001b[1;34m(subnet_type, nb_hidden_layers, base_channel_size, hidden_layer, kernel_size, nb_hidden_layers_out, hidden_layer_out, alpha)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             training_losses, training_acc, _, _, test_losses, test_acc, _, _ = train_siamese(\n\u001b[1;32m---> 31\u001b[1;33m                     model = model, dataloader = train_dataloader, test_dataloader = test_dataloader, aux_loss = aux_loss, alpha = alpha)        \n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mfinal_test_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_test_loss_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_siamese\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep Learning\\project1 Ghassen\\DeepLearning\\project_1\\train.py\u001b[0m in \u001b[0;36mtrain_siamese\u001b[1;34m(model, dataloader, test_dataloader, epochs, learning_rate, aux_loss, alpha)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlefted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrighted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_criterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep Learning\\project1 Ghassen\\DeepLearning\\project_1\\models\\SiameseNet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mrighted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrighted_no\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubnets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mrighted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrighted_no\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubnets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m#CONCAT lefted and righted which are of size [N,10] each to a single tensor of size [N,20]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep Learning\\project1 Ghassen\\DeepLearning\\project_1\\models\\FCN.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mhid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "round_results_FCN = compute_results_fcn('FCN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_results(round_results_FCN,'FCN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_FCN = np.array(round_results_FCN).mean(axis= 0)\n",
    "means_FCN[:,3,19] #test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_hid_inner = 2\n",
    "hid_inner = 128\n",
    "nb_hid_out = 2\n",
    "hid_outer = 256\n",
    "alpha = 0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subnet : CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_net): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.2)\n",
       "    (4): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Dropout(p=0.2)\n",
       "  )\n",
       "  (fc_net): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2)\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for weight_sharing = False and aux loss = False on round 0 with subnet CNN\n",
      "At epoch 1 the training loss is 0.6787641170620918\n",
      "At epoch 1 the training accuracy is 0.59\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.592758045643568\n",
      "At epoch 2 the training accuracy is 0.683\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.5553010483458638\n",
      "At epoch 3 the training accuracy is 0.701\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.5190081244334579\n",
      "At epoch 4 the training accuracy is 0.733\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.47487174116075037\n",
      "At epoch 5 the training accuracy is 0.765\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.45780751932412383\n",
      "At epoch 6 the training accuracy is 0.789\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.45320733565837146\n",
      "At epoch 7 the training accuracy is 0.77\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.44558409839868546\n",
      "At epoch 8 the training accuracy is 0.785\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.4168048155494034\n",
      "At epoch 9 the training accuracy is 0.796\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.41685901444405316\n",
      "At epoch 10 the training accuracy is 0.814\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.3892689791880548\n",
      "At epoch 11 the training accuracy is 0.822\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.39428582778200505\n",
      "At epoch 12 the training accuracy is 0.816\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.38046878926921635\n",
      "At epoch 13 the training accuracy is 0.813\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.35538256459869444\n",
      "At epoch 14 the training accuracy is 0.85\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.37664922184776517\n",
      "At epoch 15 the training accuracy is 0.823\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.36057996096089484\n",
      "At epoch 16 the training accuracy is 0.83\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.3547557546664029\n",
      "At epoch 17 the training accuracy is 0.84\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.36286765765398743\n",
      "At epoch 18 the training accuracy is 0.846\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.33998377982527017\n",
      "At epoch 19 the training accuracy is 0.847\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.35943024515174327\n",
      "At epoch 20 the training accuracy is 0.834\n",
      "epoch 20/20\n",
      "The test loss is 0.3584410846233368\n",
      "The test accuracy is 0.844\n",
      "In epoch 20, on the test set we obtain a loss of 0.36 and an accuracy of 0.84\n",
      "Model for weight_sharing = False and aux loss = True on round 0 with subnet CNN\n",
      "At epoch 1 the training loss is 2.559002334475517\n",
      "At epoch 1 the training accuracy is 0.532\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 1.2472318413853645\n",
      "At epoch 2 the training accuracy is 0.649\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 1.042366418838501\n",
      "At epoch 3 the training accuracy is 0.709\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.9591985630989075\n",
      "At epoch 4 the training accuracy is 0.714\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.8559599684178829\n",
      "At epoch 5 the training accuracy is 0.745\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.8026405417174101\n",
      "At epoch 6 the training accuracy is 0.754\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.7522794934362174\n",
      "At epoch 7 the training accuracy is 0.74\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.7116274986416101\n",
      "At epoch 8 the training accuracy is 0.773\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.6784351850301027\n",
      "At epoch 9 the training accuracy is 0.771\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.6343047434091568\n",
      "At epoch 10 the training accuracy is 0.782\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.627916536256671\n",
      "At epoch 11 the training accuracy is 0.788\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.5956734967976809\n",
      "At epoch 12 the training accuracy is 0.809\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.5834738082811236\n",
      "At epoch 13 the training accuracy is 0.797\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.5530234246328473\n",
      "At epoch 14 the training accuracy is 0.809\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.5238324712216854\n",
      "At epoch 15 the training accuracy is 0.829\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.5391009019315243\n",
      "At epoch 16 the training accuracy is 0.821\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.5167607846856117\n",
      "At epoch 17 the training accuracy is 0.817\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.4937986573949456\n",
      "At epoch 18 the training accuracy is 0.834\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.5058175231516361\n",
      "At epoch 19 the training accuracy is 0.832\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.5215912483632564\n",
      "At epoch 20 the training accuracy is 0.827\n",
      "epoch 20/20\n",
      "The test loss is 0.3455561399459839\n",
      "The test accuracy is 0.876\n",
      "In epoch 20, on the test set we obtain a loss of 0.35 and an accuracy of 0.88\n",
      "Model for weight_sharing = True and aux loss = False on round 0 with subnet CNN\n",
      "At epoch 1 the training loss is 0.7113813042640686\n",
      "At epoch 1 the training accuracy is 0.57\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.6045439474284648\n",
      "At epoch 2 the training accuracy is 0.676\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.5446158921346068\n",
      "At epoch 3 the training accuracy is 0.729\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.5479983527213335\n",
      "At epoch 4 the training accuracy is 0.718\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.5138867180794477\n",
      "At epoch 5 the training accuracy is 0.742\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.4869667390920222\n",
      "At epoch 6 the training accuracy is 0.759\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.48783960159868\n",
      "At epoch 7 the training accuracy is 0.77\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.4559329290129244\n",
      "At epoch 8 the training accuracy is 0.776\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.44603085635229944\n",
      "At epoch 9 the training accuracy is 0.781\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.448272691629827\n",
      "At epoch 10 the training accuracy is 0.786\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.4292296923696995\n",
      "At epoch 11 the training accuracy is 0.813\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.4219047769904137\n",
      "At epoch 12 the training accuracy is 0.805\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.40327034461311995\n",
      "At epoch 13 the training accuracy is 0.81\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.4087682744022459\n",
      "At epoch 14 the training accuracy is 0.814\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.3990552267432213\n",
      "At epoch 15 the training accuracy is 0.81\n",
      "epoch 15/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-c16dec27e4ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mround_results_CNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CNN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-106-dc574cacf0b5>\u001b[0m in \u001b[0;36mcompute_results\u001b[1;34m(subnet_type, nb_hidden_layers, base_channel_size, hidden_layer, kernel_size, nb_hidden_layers_out, hidden_layer_out, alpha)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             training_losses, training_acc, _, _, test_losses, test_acc, _, _ = train_siamese(\n\u001b[1;32m---> 31\u001b[1;33m                     model = model, dataloader = train_dataloader, test_dataloader = test_dataloader, aux_loss = aux_loss, alpha = alpha)        \n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mfinal_test_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_test_loss_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_siamese\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep Learning\\project1 Ghassen\\DeepLearning\\project_1\\train.py\u001b[0m in \u001b[0;36mtrain_siamese\u001b[1;34m(model, dataloader, test_dataloader, epochs, learning_rate, aux_loss, alpha)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Ridha\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "round_results_CNN = compute_results('CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_results(round_results_CNN, 'CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_CNN = np.array(round_results_CNN).mean(axis= 0)\n",
    "means_CNN[:,3,19] #test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_CNN = np.array(round_results_CNN).std(axis= 0)\n",
    "std_CNN[:,3,19] #test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_hid_inner = 2\n",
    "hid_inner = 521\n",
    "base_channel = 24\n",
    "kernel_size = 3\n",
    "nb_hid_out = 2\n",
    "hid_outer = 512\n",
    "alpha =  0.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for weight_sharing = False and aux loss = False on round 0 with subnet CNN\n",
      "At epoch 1 the training loss is 0.7137428545206785\n",
      "At epoch 1 the training accuracy is 0.607\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.6140838127210736\n",
      "At epoch 2 the training accuracy is 0.697\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.5426720384322107\n",
      "At epoch 3 the training accuracy is 0.755\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.48608803885988894\n",
      "At epoch 4 the training accuracy is 0.761\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.42975855138152835\n",
      "At epoch 5 the training accuracy is 0.796\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.3943245276645757\n",
      "At epoch 6 the training accuracy is 0.823\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.3410231212433428\n",
      "At epoch 7 the training accuracy is 0.849\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.3068881966662593\n",
      "At epoch 8 the training accuracy is 0.871\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.27986150774755514\n",
      "At epoch 9 the training accuracy is 0.884\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.25346926715690643\n",
      "At epoch 10 the training accuracy is 0.895\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.23648003182199318\n",
      "At epoch 11 the training accuracy is 0.907\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.17560217567486688\n",
      "At epoch 12 the training accuracy is 0.93\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.15712776799568018\n",
      "At epoch 13 the training accuracy is 0.938\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.14197398490472551\n",
      "At epoch 14 the training accuracy is 0.947\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.14595150806281823\n",
      "At epoch 15 the training accuracy is 0.947\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.10134993508275329\n",
      "At epoch 16 the training accuracy is 0.967\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.1179280223891601\n",
      "At epoch 17 the training accuracy is 0.963\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.06624751215541551\n",
      "At epoch 18 the training accuracy is 0.981\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.08145857853738744\n",
      "At epoch 19 the training accuracy is 0.971\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.06301554848447495\n",
      "At epoch 20 the training accuracy is 0.973\n",
      "epoch 20/20\n",
      "The test loss is 0.4304213225841522\n",
      "The test accuracy is 0.876\n",
      "In epoch 20, on the test set we obtain a loss of 0.43 and an accuracy of 0.88\n",
      "Model for weight_sharing = False and aux loss = True on round 0 with subnet CNN\n",
      "At epoch 1 the training loss is 1.1095058581233024\n",
      "At epoch 1 the training accuracy is 0.68\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.6301752807572484\n",
      "At epoch 2 the training accuracy is 0.777\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.4894571507722139\n",
      "At epoch 3 the training accuracy is 0.815\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.38133260524715296\n",
      "At epoch 4 the training accuracy is 0.846\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.3170666053844616\n",
      "At epoch 5 the training accuracy is 0.877\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.2383173383655958\n",
      "At epoch 6 the training accuracy is 0.906\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.241098251582589\n",
      "At epoch 7 the training accuracy is 0.917\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.1830101944223861\n",
      "At epoch 8 the training accuracy is 0.937\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.12115272787632421\n",
      "At epoch 9 the training accuracy is 0.955\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.0960458628267952\n",
      "At epoch 10 the training accuracy is 0.976\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.07598423193794587\n",
      "At epoch 11 the training accuracy is 0.976\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.13098380434930731\n",
      "At epoch 12 the training accuracy is 0.961\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.08270478683640249\n",
      "At epoch 13 the training accuracy is 0.973\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.08453282083793966\n",
      "At epoch 14 the training accuracy is 0.984\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.05229523020100715\n",
      "At epoch 15 the training accuracy is 0.985\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.039616747482250504\n",
      "At epoch 16 the training accuracy is 0.99\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.0381607182434027\n",
      "At epoch 17 the training accuracy is 0.987\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.018601873770303427\n",
      "At epoch 18 the training accuracy is 0.996\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.02506737275165733\n",
      "At epoch 19 the training accuracy is 0.994\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.028209725954441184\n",
      "At epoch 20 the training accuracy is 0.993\n",
      "epoch 20/20\n",
      "The test loss is 0.19817432761192322\n",
      "The test accuracy is 0.968\n",
      "In epoch 20, on the test set we obtain a loss of 0.20 and an accuracy of 0.97\n",
      "Model for weight_sharing = True and aux loss = False on round 0 with subnet CNN\n",
      "At epoch 1 the training loss is 0.6136410598084331\n",
      "At epoch 1 the training accuracy is 0.709\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.47867473421618345\n",
      "At epoch 2 the training accuracy is 0.777\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.43139316625427454\n",
      "At epoch 3 the training accuracy is 0.807\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.37353013216983527\n",
      "At epoch 4 the training accuracy is 0.839\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.31716976591269486\n",
      "At epoch 5 the training accuracy is 0.876\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.30860628373222426\n",
      "At epoch 6 the training accuracy is 0.882\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.26375162495591215\n",
      "At epoch 7 the training accuracy is 0.894\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.24439659020514226\n",
      "At epoch 8 the training accuracy is 0.906\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.20289764361950802\n",
      "At epoch 9 the training accuracy is 0.919\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.17869815727751756\n",
      "At epoch 10 the training accuracy is 0.93\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.14581139207773958\n",
      "At epoch 11 the training accuracy is 0.949\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.12001095302336125\n",
      "At epoch 12 the training accuracy is 0.954\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.11918961418822618\n",
      "At epoch 13 the training accuracy is 0.962\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.11487181854043228\n",
      "At epoch 14 the training accuracy is 0.956\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.09285348216880181\n",
      "At epoch 15 the training accuracy is 0.967\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.10547783388594326\n",
      "At epoch 16 the training accuracy is 0.962\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.06869474332658683\n",
      "At epoch 17 the training accuracy is 0.974\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.053943575950784604\n",
      "At epoch 18 the training accuracy is 0.982\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.053764197190374716\n",
      "At epoch 19 the training accuracy is 0.982\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.07366796656696124\n",
      "At epoch 20 the training accuracy is 0.974\n",
      "epoch 20/20\n",
      "The test loss is 0.26386189460754395\n",
      "The test accuracy is 0.918\n",
      "In epoch 20, on the test set we obtain a loss of 0.26 and an accuracy of 0.92\n",
      "Model for weight_sharing = True and aux loss = True on round 0 with subnet CNN\n",
      "At epoch 1 the training loss is 0.8773178786039353\n",
      "At epoch 1 the training accuracy is 0.717\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.4878978765383363\n",
      "At epoch 2 the training accuracy is 0.814\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.32754168482497337\n",
      "At epoch 3 the training accuracy is 0.861\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.24631963077234104\n",
      "At epoch 4 the training accuracy is 0.901\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.21071493354509585\n",
      "At epoch 5 the training accuracy is 0.922\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.1648861699621193\n",
      "At epoch 6 the training accuracy is 0.936\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.13895264015241993\n",
      "At epoch 7 the training accuracy is 0.949\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.11848076891430537\n",
      "At epoch 8 the training accuracy is 0.958\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.07732881385956716\n",
      "At epoch 9 the training accuracy is 0.972\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.08257577328908156\n",
      "At epoch 10 the training accuracy is 0.977\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.05217073750577129\n",
      "At epoch 11 the training accuracy is 0.984\n",
      "epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 12 the training loss is 0.03848807516533498\n",
      "At epoch 12 the training accuracy is 0.989\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.034784315970059654\n",
      "At epoch 13 the training accuracy is 0.984\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.03228621953584479\n",
      "At epoch 14 the training accuracy is 0.991\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.02250171660027405\n",
      "At epoch 15 the training accuracy is 0.995\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.03103347906705949\n",
      "At epoch 16 the training accuracy is 0.989\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.02256982046402051\n",
      "At epoch 17 the training accuracy is 0.996\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.034192006415547385\n",
      "At epoch 18 the training accuracy is 0.991\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.012163384917477166\n",
      "At epoch 19 the training accuracy is 0.996\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.024940035509267773\n",
      "At epoch 20 the training accuracy is 0.988\n",
      "epoch 20/20\n",
      "The test loss is 0.14380468428134918\n",
      "The test accuracy is 0.974\n",
      "In epoch 20, on the test set we obtain a loss of 0.14 and an accuracy of 0.97\n",
      "Model for weight_sharing = False and aux loss = False on round 1 with subnet CNN\n",
      "At epoch 1 the training loss is 0.6980095042288303\n",
      "At epoch 1 the training accuracy is 0.619\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.5771518107131124\n",
      "At epoch 2 the training accuracy is 0.721\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.479805104326224\n",
      "At epoch 3 the training accuracy is 0.786\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.4447698065266013\n",
      "At epoch 4 the training accuracy is 0.795\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.3970426067709923\n",
      "At epoch 5 the training accuracy is 0.835\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.329661068324931\n",
      "At epoch 6 the training accuracy is 0.863\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.3210991712624673\n",
      "At epoch 7 the training accuracy is 0.866\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.24466841273759202\n",
      "At epoch 8 the training accuracy is 0.903\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.20455704560619778\n",
      "At epoch 9 the training accuracy is 0.917\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.17825293854402843\n",
      "At epoch 10 the training accuracy is 0.932\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.14582314326559412\n",
      "At epoch 11 the training accuracy is 0.95\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.16198280386458463\n",
      "At epoch 12 the training accuracy is 0.941\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.12291352753301112\n",
      "At epoch 13 the training accuracy is 0.956\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.09874095283424139\n",
      "At epoch 14 the training accuracy is 0.969\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.08428565332051903\n",
      "At epoch 15 the training accuracy is 0.961\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.10089022723836023\n",
      "At epoch 16 the training accuracy is 0.961\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.06789722241806885\n",
      "At epoch 17 the training accuracy is 0.98\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.05032783017309612\n",
      "At epoch 18 the training accuracy is 0.985\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.056137012708787334\n",
      "At epoch 19 the training accuracy is 0.975\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.05399322731825576\n",
      "At epoch 20 the training accuracy is 0.982\n",
      "epoch 20/20\n",
      "The test loss is 0.4421676993370056\n",
      "The test accuracy is 0.87\n",
      "In epoch 20, on the test set we obtain a loss of 0.44 and an accuracy of 0.87\n",
      "Model for weight_sharing = False and aux loss = True on round 1 with subnet CNN\n",
      "At epoch 1 the training loss is 1.1109957528114318\n",
      "At epoch 1 the training accuracy is 0.698\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.6403325816988945\n",
      "At epoch 2 the training accuracy is 0.784\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.46238195335492493\n",
      "At epoch 3 the training accuracy is 0.813\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.3293872551433742\n",
      "At epoch 4 the training accuracy is 0.866\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.29270955292508005\n",
      "At epoch 5 the training accuracy is 0.899\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.21677968871896156\n",
      "At epoch 6 the training accuracy is 0.931\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.19642745510849635\n",
      "At epoch 7 the training accuracy is 0.917\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.14530085637466983\n",
      "At epoch 8 the training accuracy is 0.947\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.10111843172475346\n",
      "At epoch 9 the training accuracy is 0.967\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.08905458505963906\n",
      "At epoch 10 the training accuracy is 0.967\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.06971930155944392\n",
      "At epoch 11 the training accuracy is 0.975\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.07959359752880119\n",
      "At epoch 12 the training accuracy is 0.981\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.07318702240274433\n",
      "At epoch 13 the training accuracy is 0.971\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.05631733423106198\n",
      "At epoch 14 the training accuracy is 0.983\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.0469627521975508\n",
      "At epoch 15 the training accuracy is 0.991\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.0289436361355979\n",
      "At epoch 16 the training accuracy is 0.992\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.02257846647211039\n",
      "At epoch 17 the training accuracy is 0.995\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.01881691079877953\n",
      "At epoch 18 the training accuracy is 0.995\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.015461575952478199\n",
      "At epoch 19 the training accuracy is 0.995\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.014445263556605142\n",
      "At epoch 20 the training accuracy is 0.998\n",
      "epoch 20/20\n",
      "The test loss is 0.22298544645309448\n",
      "The test accuracy is 0.971\n",
      "In epoch 20, on the test set we obtain a loss of 0.22 and an accuracy of 0.97\n",
      "Model for weight_sharing = True and aux loss = False on round 1 with subnet CNN\n",
      "At epoch 1 the training loss is 0.6136474607884884\n",
      "At epoch 1 the training accuracy is 0.701\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.5372646380122751\n",
      "At epoch 2 the training accuracy is 0.743\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.47163203223608435\n",
      "At epoch 3 the training accuracy is 0.764\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.43771514592692257\n",
      "At epoch 4 the training accuracy is 0.797\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.4086508177127689\n",
      "At epoch 5 the training accuracy is 0.821\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.3393479692842811\n",
      "At epoch 6 the training accuracy is 0.845\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.3465496166376397\n",
      "At epoch 7 the training accuracy is 0.849\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.28379151404369624\n",
      "At epoch 8 the training accuracy is 0.875\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.2568477063384489\n",
      "At epoch 9 the training accuracy is 0.889\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.2326913414284354\n",
      "At epoch 10 the training accuracy is 0.897\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.21624364797991347\n",
      "At epoch 11 the training accuracy is 0.919\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.1788907422045122\n",
      "At epoch 12 the training accuracy is 0.923\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.19586784710292704\n",
      "At epoch 13 the training accuracy is 0.926\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.13777484954323882\n",
      "At epoch 14 the training accuracy is 0.948\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.147264731230498\n",
      "At epoch 15 the training accuracy is 0.942\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.1177899163725533\n",
      "At epoch 16 the training accuracy is 0.957\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.09309671601113678\n",
      "At epoch 17 the training accuracy is 0.967\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.09425880142781352\n",
      "At epoch 18 the training accuracy is 0.971\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.1094306817847496\n",
      "At epoch 19 the training accuracy is 0.953\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.07717077992833765\n",
      "At epoch 20 the training accuracy is 0.967\n",
      "epoch 20/20\n",
      "The test loss is 0.2838139235973358\n",
      "The test accuracy is 0.914\n",
      "In epoch 20, on the test set we obtain a loss of 0.28 and an accuracy of 0.91\n",
      "Model for weight_sharing = True and aux loss = True on round 1 with subnet CNN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 1 the training loss is 0.9794145985692739\n",
      "At epoch 1 the training accuracy is 0.702\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.48550312958657743\n",
      "At epoch 2 the training accuracy is 0.804\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.3737667489843443\n",
      "At epoch 3 the training accuracy is 0.851\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.2855211043916643\n",
      "At epoch 4 the training accuracy is 0.889\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.24253625522833316\n",
      "At epoch 5 the training accuracy is 0.916\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.18197852573124693\n",
      "At epoch 6 the training accuracy is 0.93\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.132242598249577\n",
      "At epoch 7 the training accuracy is 0.959\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.1359931647160556\n",
      "At epoch 8 the training accuracy is 0.955\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.11200954894520691\n",
      "At epoch 9 the training accuracy is 0.96\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.07480945381168567\n",
      "At epoch 10 the training accuracy is 0.976\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.10051060604859231\n",
      "At epoch 11 the training accuracy is 0.966\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.07501373875721583\n",
      "At epoch 12 the training accuracy is 0.982\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.06279369546871749\n",
      "At epoch 13 the training accuracy is 0.98\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.045397472483509775\n",
      "At epoch 14 the training accuracy is 0.989\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.046469880213026046\n",
      "At epoch 15 the training accuracy is 0.985\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.03313075136763018\n",
      "At epoch 16 the training accuracy is 0.986\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.03966047326760418\n",
      "At epoch 17 the training accuracy is 0.992\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.028169488384100987\n",
      "At epoch 18 the training accuracy is 0.994\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.0361822132208691\n",
      "At epoch 19 the training accuracy is 0.989\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.023882736797085045\n",
      "At epoch 20 the training accuracy is 0.992\n",
      "epoch 20/20\n",
      "The test loss is 0.1537943035364151\n",
      "The test accuracy is 0.97\n",
      "In epoch 20, on the test set we obtain a loss of 0.15 and an accuracy of 0.97\n",
      "Model for weight_sharing = False and aux loss = False on round 2 with subnet CNN\n",
      "At epoch 1 the training loss is 0.6603816894255579\n",
      "At epoch 1 the training accuracy is 0.655\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.5511273415759206\n",
      "At epoch 2 the training accuracy is 0.72\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.5062293943949043\n",
      "At epoch 3 the training accuracy is 0.777\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.45335776610765605\n",
      "At epoch 4 the training accuracy is 0.799\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.42338524389546367\n",
      "At epoch 5 the training accuracy is 0.822\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.3330855879213777\n",
      "At epoch 6 the training accuracy is 0.856\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.3611680055432953\n",
      "At epoch 7 the training accuracy is 0.852\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.2609141114843078\n",
      "At epoch 8 the training accuracy is 0.895\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.2285704277222976\n",
      "At epoch 9 the training accuracy is 0.909\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.20398453599109417\n",
      "At epoch 10 the training accuracy is 0.911\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.187352689288673\n",
      "At epoch 11 the training accuracy is 0.924\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.12975365118747503\n",
      "At epoch 12 the training accuracy is 0.952\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.11456510614264231\n",
      "At epoch 13 the training accuracy is 0.961\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.11691621206996246\n",
      "At epoch 14 the training accuracy is 0.96\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.08633257923430077\n",
      "At epoch 15 the training accuracy is 0.973\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.06562376908720893\n",
      "At epoch 16 the training accuracy is 0.972\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.08452463097845339\n",
      "At epoch 17 the training accuracy is 0.972\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.0654170268312066\n",
      "At epoch 18 the training accuracy is 0.972\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.05288210030822404\n",
      "At epoch 19 the training accuracy is 0.979\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.05877472544097543\n",
      "At epoch 20 the training accuracy is 0.977\n",
      "epoch 20/20\n",
      "The test loss is 0.3846040964126587\n",
      "The test accuracy is 0.88\n",
      "In epoch 20, on the test set we obtain a loss of 0.38 and an accuracy of 0.88\n",
      "Model for weight_sharing = False and aux loss = True on round 2 with subnet CNN\n",
      "At epoch 1 the training loss is 1.1007480864226817\n",
      "At epoch 1 the training accuracy is 0.658\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.6436473543196917\n",
      "At epoch 2 the training accuracy is 0.774\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.4607599172927439\n",
      "At epoch 3 the training accuracy is 0.801\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.3681771728908643\n",
      "At epoch 4 the training accuracy is 0.861\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.2830209832964465\n",
      "At epoch 5 the training accuracy is 0.891\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.23338690721429883\n",
      "At epoch 6 the training accuracy is 0.913\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.18105001169256865\n",
      "At epoch 7 the training accuracy is 0.933\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.15468410551431588\n",
      "At epoch 8 the training accuracy is 0.939\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.12297308873632573\n",
      "At epoch 9 the training accuracy is 0.962\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.1414372517013544\n",
      "At epoch 10 the training accuracy is 0.963\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.07495113715285698\n",
      "At epoch 11 the training accuracy is 0.982\n",
      "epoch 11/20\n",
      "At epoch 12 the training loss is 0.087862590708271\n",
      "At epoch 12 the training accuracy is 0.973\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.06900355005704113\n",
      "At epoch 13 the training accuracy is 0.982\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.05413135262971082\n",
      "At epoch 14 the training accuracy is 0.985\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.04772973992013249\n",
      "At epoch 15 the training accuracy is 0.988\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.029815477469182953\n",
      "At epoch 16 the training accuracy is 0.985\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.038788456878346554\n",
      "At epoch 17 the training accuracy is 0.993\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.048864894786147486\n",
      "At epoch 18 the training accuracy is 0.99\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.01704493983901017\n",
      "At epoch 19 the training accuracy is 0.99\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.02807107770839309\n",
      "At epoch 20 the training accuracy is 0.993\n",
      "epoch 20/20\n",
      "The test loss is 0.26356732845306396\n",
      "The test accuracy is 0.961\n",
      "In epoch 20, on the test set we obtain a loss of 0.26 and an accuracy of 0.96\n",
      "Model for weight_sharing = True and aux loss = False on round 2 with subnet CNN\n",
      "At epoch 1 the training loss is 0.6116292275860906\n",
      "At epoch 1 the training accuracy is 0.691\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.49510388555936513\n",
      "At epoch 2 the training accuracy is 0.763\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.4197429830767214\n",
      "At epoch 3 the training accuracy is 0.825\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.3605456125084311\n",
      "At epoch 4 the training accuracy is 0.827\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.2915167437971104\n",
      "At epoch 5 the training accuracy is 0.873\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.29036597712052753\n",
      "At epoch 6 the training accuracy is 0.877\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.24907223755988525\n",
      "At epoch 7 the training accuracy is 0.901\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.2089303375574673\n",
      "At epoch 8 the training accuracy is 0.918\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.20713718293642158\n",
      "At epoch 9 the training accuracy is 0.928\n",
      "epoch 9/20\n",
      "At epoch 10 the training loss is 0.18791863210883095\n",
      "At epoch 10 the training accuracy is 0.926\n",
      "epoch 10/20\n",
      "At epoch 11 the training loss is 0.16240217634960571\n",
      "At epoch 11 the training accuracy is 0.944\n",
      "epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 12 the training loss is 0.11075276496957258\n",
      "At epoch 12 the training accuracy is 0.955\n",
      "epoch 12/20\n",
      "At epoch 13 the training loss is 0.13526975855502316\n",
      "At epoch 13 the training accuracy is 0.955\n",
      "epoch 13/20\n",
      "At epoch 14 the training loss is 0.09755217124078172\n",
      "At epoch 14 the training accuracy is 0.961\n",
      "epoch 14/20\n",
      "At epoch 15 the training loss is 0.11218881091102957\n",
      "At epoch 15 the training accuracy is 0.962\n",
      "epoch 15/20\n",
      "At epoch 16 the training loss is 0.09920790376884725\n",
      "At epoch 16 the training accuracy is 0.968\n",
      "epoch 16/20\n",
      "At epoch 17 the training loss is 0.06426216426371809\n",
      "At epoch 17 the training accuracy is 0.973\n",
      "epoch 17/20\n",
      "At epoch 18 the training loss is 0.053898075364001555\n",
      "At epoch 18 the training accuracy is 0.981\n",
      "epoch 18/20\n",
      "At epoch 19 the training loss is 0.04770738080499655\n",
      "At epoch 19 the training accuracy is 0.981\n",
      "epoch 19/20\n",
      "At epoch 20 the training loss is 0.048821007660977786\n",
      "At epoch 20 the training accuracy is 0.983\n",
      "epoch 20/20\n",
      "The test loss is 0.3262343108654022\n",
      "The test accuracy is 0.906\n",
      "In epoch 20, on the test set we obtain a loss of 0.33 and an accuracy of 0.91\n",
      "Model for weight_sharing = True and aux loss = True on round 2 with subnet CNN\n",
      "At epoch 1 the training loss is 0.9167101185768842\n",
      "At epoch 1 the training accuracy is 0.701\n",
      "epoch 1/20\n",
      "At epoch 2 the training loss is 0.4626436050049961\n",
      "At epoch 2 the training accuracy is 0.807\n",
      "epoch 2/20\n",
      "At epoch 3 the training loss is 0.3232954219914973\n",
      "At epoch 3 the training accuracy is 0.875\n",
      "epoch 3/20\n",
      "At epoch 4 the training loss is 0.24890662337653338\n",
      "At epoch 4 the training accuracy is 0.915\n",
      "epoch 4/20\n",
      "At epoch 5 the training loss is 0.2193528312840499\n",
      "At epoch 5 the training accuracy is 0.917\n",
      "epoch 5/20\n",
      "At epoch 6 the training loss is 0.15860990437213332\n",
      "At epoch 6 the training accuracy is 0.951\n",
      "epoch 6/20\n",
      "At epoch 7 the training loss is 0.11824683926047327\n",
      "At epoch 7 the training accuracy is 0.962\n",
      "epoch 7/20\n",
      "At epoch 8 the training loss is 0.09855027652301032\n",
      "At epoch 8 the training accuracy is 0.975\n",
      "epoch 8/20\n",
      "At epoch 9 the training loss is 0.09085863614916889\n",
      "At epoch 9 the training accuracy is 0.972\n",
      "epoch 9/20\n"
     ]
    }
   ],
   "source": [
    "round_results_best_CNN = compute_results_cnn('CNN', nb_hid_inner, base_channel, hid_inner, kernel_size, nb_hid_out, hid_outer, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_results(round_results_best_CNN, 'CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_best_CNN = np.array(round_results_best_CNN).mean(axis= 0)\n",
    "means_best_CNN[:,3,19] #test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_best_CNN = np.array(round_results_best_CNN).std(axis= 0)\n",
    "std_best_CNN[:,3,19] #test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
