{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING PROJECT 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "import helpers\n",
    "import config\n",
    "from datasets import PairDataset, SingleDataset\n",
    "\n",
    "from train.train import train_basic\n",
    "from train.train import train_siamese\n",
    "\n",
    "from models.basic_net import BasicNet\n",
    "from models.oscar_net import OscarNet\n",
    "from models.desmond_net import DesmondNet\n",
    "from models.robert_net import RobertNet\n",
    "from models.leonard_net import LeonardNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (2, 14, 14)\n",
    "\n",
    "LEARNING_RATE = 0.00001\n",
    "SUB_CRITERION = nn.CrossEntropyLoss()\n",
    "FINAL_CRITERION = nn.BCELoss()\n",
    "EPOCHS = 20\n",
    "\n",
    "DEF_NET_HIDDEN_LAYER = 275\n",
    "BASE_CHANNEL_SIZE = 8\n",
    "\n",
    "HIDDEN_LAYERS = [100, 200, 300, 400, 500]\n",
    "NB_HIDDENS = [1, 2, 3, 4, 5]\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "\n",
    "ALPHA = 0.5\n",
    "BETA = 0.25\n",
    "GAMMA = 0.25\n",
    "WEIGHTS_LOSS = ALPHA, BETA, GAMMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = helpers.generate_pair_sets(config.NB_SAMPLES)\n",
    "\n",
    "train_dataset = PairDataset(pairs[0], pairs[1], pairs[2])\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = PairDataset(pairs[3], pairs[4], pairs[5])\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=config.TEST_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: \n",
    "## Siamese/TWO FCNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO CUDA\n",
      "[Epoch 1, Batch 0/1000]:  [Loss: 18.45]\n",
      "[Epoch 1, Batch 250/1000]:  [Loss: 6.87]\n",
      "[Epoch 1, Batch 500/1000]:  [Loss: 9.07]\n",
      "[Epoch 1, Batch 750/1000]:  [Loss: 5.29]\n",
      "At epoch 1 the training loss is 8.985044029176235\n",
      "At epoch 1 the training accuracy is 0.483\n",
      "At epoch 1 :\n",
      "The test loss is 5.957577228546143\n",
      "The test accuracy is 0.464\n",
      "[Epoch 2, Batch 0/1000]:  [Loss: 7.31]\n",
      "[Epoch 2, Batch 250/1000]:  [Loss: 0.36]\n",
      "[Epoch 2, Batch 500/1000]:  [Loss: 10.90]\n",
      "[Epoch 2, Batch 750/1000]:  [Loss: 4.32]\n",
      "At epoch 2 the training loss is 5.107849293500185\n",
      "At epoch 2 the training accuracy is 0.492\n",
      "At epoch 2 :\n",
      "The test loss is 3.763021469116211\n",
      "The test accuracy is 0.46\n",
      "[Epoch 3, Batch 0/1000]:  [Loss: 3.95]\n",
      "[Epoch 3, Batch 250/1000]:  [Loss: 4.39]\n",
      "[Epoch 3, Batch 500/1000]:  [Loss: 5.57]\n",
      "[Epoch 3, Batch 750/1000]:  [Loss: 4.58]\n",
      "At epoch 3 the training loss is 3.522123275846243\n",
      "At epoch 3 the training accuracy is 0.491\n",
      "At epoch 3 :\n",
      "The test loss is 2.824117422103882\n",
      "The test accuracy is 0.49\n",
      "[Epoch 4, Batch 0/1000]:  [Loss: 0.35]\n",
      "[Epoch 4, Batch 250/1000]:  [Loss: 3.69]\n",
      "[Epoch 4, Batch 500/1000]:  [Loss: 2.88]\n",
      "[Epoch 4, Batch 750/1000]:  [Loss: 3.81]\n",
      "At epoch 4 the training loss is 2.7068869623541834\n",
      "At epoch 4 the training accuracy is 0.519\n",
      "At epoch 4 :\n",
      "The test loss is 2.2827513217926025\n",
      "The test accuracy is 0.54\n",
      "[Epoch 5, Batch 0/1000]:  [Loss: 2.58]\n",
      "[Epoch 5, Batch 250/1000]:  [Loss: 6.72]\n",
      "[Epoch 5, Batch 500/1000]:  [Loss: 2.74]\n",
      "[Epoch 5, Batch 750/1000]:  [Loss: 4.28]\n",
      "At epoch 5 the training loss is 2.1907039897441862\n",
      "At epoch 5 the training accuracy is 0.545\n",
      "At epoch 5 :\n",
      "The test loss is 1.9361677169799805\n",
      "The test accuracy is 0.576\n",
      "[Epoch 6, Batch 0/1000]:  [Loss: 3.68]\n",
      "[Epoch 6, Batch 250/1000]:  [Loss: 6.73]\n",
      "[Epoch 6, Batch 500/1000]:  [Loss: 4.22]\n",
      "[Epoch 6, Batch 750/1000]:  [Loss: 2.15]\n",
      "At epoch 6 the training loss is 1.8443098254799843\n",
      "At epoch 6 the training accuracy is 0.59\n",
      "At epoch 6 :\n",
      "The test loss is 1.701725721359253\n",
      "The test accuracy is 0.599\n",
      "[Epoch 7, Batch 0/1000]:  [Loss: 5.99]\n",
      "[Epoch 7, Batch 250/1000]:  [Loss: 0.36]\n",
      "[Epoch 7, Batch 500/1000]:  [Loss: 1.25]\n",
      "[Epoch 7, Batch 750/1000]:  [Loss: 1.58]\n",
      "At epoch 7 the training loss is 1.5919881335496902\n",
      "At epoch 7 the training accuracy is 0.618\n",
      "At epoch 7 :\n",
      "The test loss is 1.5496739149093628\n",
      "The test accuracy is 0.631\n",
      "[Epoch 8, Batch 0/1000]:  [Loss: 0.45]\n",
      "[Epoch 8, Batch 250/1000]:  [Loss: 1.75]\n",
      "[Epoch 8, Batch 500/1000]:  [Loss: 2.57]\n",
      "[Epoch 8, Batch 750/1000]:  [Loss: 4.85]\n",
      "At epoch 8 the training loss is 1.407901762932539\n",
      "At epoch 8 the training accuracy is 0.632\n",
      "At epoch 8 :\n",
      "The test loss is 1.4250125885009766\n",
      "The test accuracy is 0.648\n",
      "[Epoch 9, Batch 0/1000]:  [Loss: 7.37]\n",
      "[Epoch 9, Batch 250/1000]:  [Loss: 4.52]\n",
      "[Epoch 9, Batch 500/1000]:  [Loss: 4.75]\n",
      "[Epoch 9, Batch 750/1000]:  [Loss: 1.00]\n"
     ]
    }
   ],
   "source": [
    "models={}\n",
    "\n",
    "for nb_outer in NB_HIDDENS:\n",
    "    for hidden_outer in HIDDEN_LAYERS:\n",
    "        for nb_inner in NB_HIDDENS:\n",
    "            for hidden_inner in HIDDEN_LAYERS:\n",
    "                inner_model = OscarNet(nb_inner, hidden_inner)\n",
    "                outer_model = LeonardNet(nb_outer, inner_model, hidden_outer)\n",
    "                \n",
    "                tr_loss, tr_acc, tr_loss_l, tr_loss_r, te_loss, te_acc, te_loss_l, te_loss_r = train_siamese(model = outer_model,\n",
    "                                     dataloader = train_dataloader,\n",
    "                                     test_dataloader = test_dataloader,\n",
    "                                     epochs = EPOCHS,\n",
    "                                     final_criterion = FINAL_CRITERION, \n",
    "                                     learning_rate = LEARNING_RATE,\n",
    "                                     aux_loss = True,\n",
    "                                     sub_criterion = SUB_CRITERION, \n",
    "                                     weights_loss = WEIGHTS_LOSS)\n",
    "                \n",
    "                run_string = \"{0}_{1}_{2}_{3}\".format(nb_outer, hidden_outer, nb_outer, hidden_inner)\n",
    "                \n",
    "                models[run_string] = {\n",
    "                    'tr_loss' : tr_loss,\n",
    "                    'tr_acc' : tr_acc,\n",
    "                    'tr_loss_l' : tr_loss_l,\n",
    "                    'tr_loss_r' : tr_loss_r,\n",
    "                    'te_loss' : te_loss,\n",
    "                    'te_acc' : te_acc,\n",
    "                    'te_loss_l' : te_loss_l,\n",
    "                    'te_loss_r' : te_loss_r\n",
    "                }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
