{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING PROJECT 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "import helpers\n",
    "import config\n",
    "from datasets import PairDataset, SingleDataset\n",
    "\n",
    "from train.train import train_basic\n",
    "from train.train import train_siamese\n",
    "\n",
    "from models.basic_net import BasicNet\n",
    "from models.oscar_net import OscarNet\n",
    "from models.desmond_net import DesmondNet\n",
    "from models.robert_net import RobertNet\n",
    "from models.leonard_net import LeonardNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (2, 14, 14)\n",
    "\n",
    "LEARNING_RATE = 0.00001\n",
    "SUB_CRITERION = nn.CrossEntropyLoss()\n",
    "FINAL_CRITERION = nn.BCELoss()\n",
    "EPOCHS = 20\n",
    "\n",
    "DEF_NET_HIDDEN_LAYER = 275\n",
    "BASE_CHANNEL_SIZE = 8\n",
    "\n",
    "HIDDEN_LAYERS = [100, 200, 300, 400, 500]\n",
    "NB_HIDDENS = [1, 2, 3, 4, 5]\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "\n",
    "ALPHA = 0.5\n",
    "BETA = 0.25\n",
    "GAMMA = 0.25\n",
    "WEIGHTS_LOSS = ALPHA, BETA, GAMMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = helpers.generate_pair_sets(config.NB_SAMPLES)\n",
    "\n",
    "train_dataset = PairDataset(pairs[0], pairs[1], pairs[2])\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = PairDataset(pairs[3], pairs[4], pairs[5])\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=config.TEST_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: \n",
    "## Siamese/TWO FCNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO CUDA\n",
      "[Epoch 1, Batch 0/1000]:  [Loss: 18.45]\n",
      "[Epoch 1, Batch 250/1000]:  [Loss: 6.87]\n",
      "[Epoch 1, Batch 500/1000]:  [Loss: 9.07]\n",
      "[Epoch 1, Batch 750/1000]:  [Loss: 5.29]\n",
      "At epoch 1 the training loss is 8.985044029176235\n",
      "At epoch 1 the training accuracy is 0.483\n",
      "At epoch 1 :\n",
      "The test loss is 5.957577228546143\n",
      "The test accuracy is 0.464\n",
      "[Epoch 2, Batch 0/1000]:  [Loss: 7.31]\n",
      "[Epoch 2, Batch 250/1000]:  [Loss: 0.36]\n",
      "[Epoch 2, Batch 500/1000]:  [Loss: 10.90]\n",
      "[Epoch 2, Batch 750/1000]:  [Loss: 4.32]\n",
      "At epoch 2 the training loss is 5.107849293500185\n",
      "At epoch 2 the training accuracy is 0.492\n",
      "At epoch 2 :\n",
      "The test loss is 3.763021469116211\n",
      "The test accuracy is 0.46\n",
      "[Epoch 3, Batch 0/1000]:  [Loss: 3.95]\n",
      "[Epoch 3, Batch 250/1000]:  [Loss: 4.39]\n",
      "[Epoch 3, Batch 500/1000]:  [Loss: 5.57]\n",
      "[Epoch 3, Batch 750/1000]:  [Loss: 4.58]\n",
      "At epoch 3 the training loss is 3.522123275846243\n",
      "At epoch 3 the training accuracy is 0.491\n",
      "At epoch 3 :\n",
      "The test loss is 2.824117422103882\n",
      "The test accuracy is 0.49\n",
      "[Epoch 4, Batch 0/1000]:  [Loss: 0.35]\n",
      "[Epoch 4, Batch 250/1000]:  [Loss: 3.69]\n",
      "[Epoch 4, Batch 500/1000]:  [Loss: 2.88]\n",
      "[Epoch 4, Batch 750/1000]:  [Loss: 3.81]\n",
      "At epoch 4 the training loss is 2.7068869623541834\n",
      "At epoch 4 the training accuracy is 0.519\n",
      "At epoch 4 :\n",
      "The test loss is 2.2827513217926025\n",
      "The test accuracy is 0.54\n",
      "[Epoch 5, Batch 0/1000]:  [Loss: 2.58]\n",
      "[Epoch 5, Batch 250/1000]:  [Loss: 6.72]\n",
      "[Epoch 5, Batch 500/1000]:  [Loss: 2.74]\n",
      "[Epoch 5, Batch 750/1000]:  [Loss: 4.28]\n",
      "At epoch 5 the training loss is 2.1907039897441862\n",
      "At epoch 5 the training accuracy is 0.545\n",
      "At epoch 5 :\n",
      "The test loss is 1.9361677169799805\n",
      "The test accuracy is 0.576\n",
      "[Epoch 6, Batch 0/1000]:  [Loss: 3.68]\n",
      "[Epoch 6, Batch 250/1000]:  [Loss: 6.73]\n",
      "[Epoch 6, Batch 500/1000]:  [Loss: 4.22]\n",
      "[Epoch 6, Batch 750/1000]:  [Loss: 2.15]\n",
      "At epoch 6 the training loss is 1.8443098254799843\n",
      "At epoch 6 the training accuracy is 0.59\n",
      "At epoch 6 :\n",
      "The test loss is 1.701725721359253\n",
      "The test accuracy is 0.599\n",
      "[Epoch 7, Batch 0/1000]:  [Loss: 5.99]\n",
      "[Epoch 7, Batch 250/1000]:  [Loss: 0.36]\n",
      "[Epoch 7, Batch 500/1000]:  [Loss: 1.25]\n",
      "[Epoch 7, Batch 750/1000]:  [Loss: 1.58]\n",
      "At epoch 7 the training loss is 1.5919881335496902\n",
      "At epoch 7 the training accuracy is 0.618\n",
      "At epoch 7 :\n",
      "The test loss is 1.5496739149093628\n",
      "The test accuracy is 0.631\n",
      "[Epoch 8, Batch 0/1000]:  [Loss: 0.45]\n",
      "[Epoch 8, Batch 250/1000]:  [Loss: 1.75]\n",
      "[Epoch 8, Batch 500/1000]:  [Loss: 2.57]\n",
      "[Epoch 8, Batch 750/1000]:  [Loss: 4.85]\n",
      "At epoch 8 the training loss is 1.407901762932539\n",
      "At epoch 8 the training accuracy is 0.632\n",
      "At epoch 8 :\n",
      "The test loss is 1.4250125885009766\n",
      "The test accuracy is 0.648\n",
      "[Epoch 9, Batch 0/1000]:  [Loss: 7.37]\n",
      "[Epoch 9, Batch 250/1000]:  [Loss: 4.52]\n",
      "[Epoch 9, Batch 500/1000]:  [Loss: 4.75]\n",
      "[Epoch 9, Batch 750/1000]:  [Loss: 1.00]\n",
      "At epoch 9 the training loss is 1.265246428400278\n",
      "At epoch 9 the training accuracy is 0.635\n",
      "At epoch 9 :\n",
      "The test loss is 1.3281245231628418\n",
      "The test accuracy is 0.657\n",
      "[Epoch 10, Batch 0/1000]:  [Loss: 5.77]\n",
      "[Epoch 10, Batch 250/1000]:  [Loss: 0.57]\n",
      "[Epoch 10, Batch 500/1000]:  [Loss: 0.34]\n",
      "[Epoch 10, Batch 750/1000]:  [Loss: 0.33]\n",
      "At epoch 10 the training loss is 1.150359588444233\n",
      "At epoch 10 the training accuracy is 0.649\n",
      "At epoch 10 :\n",
      "The test loss is 1.2526434659957886\n",
      "The test accuracy is 0.671\n",
      "[Epoch 11, Batch 0/1000]:  [Loss: 0.45]\n",
      "[Epoch 11, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 11, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 11, Batch 750/1000]:  [Loss: 1.16]\n",
      "At epoch 11 the training loss is 1.0545234632194043\n",
      "At epoch 11 the training accuracy is 0.651\n",
      "At epoch 11 :\n",
      "The test loss is 1.1975293159484863\n",
      "The test accuracy is 0.673\n",
      "[Epoch 12, Batch 0/1000]:  [Loss: 0.39]\n",
      "[Epoch 12, Batch 250/1000]:  [Loss: 0.35]\n",
      "[Epoch 12, Batch 500/1000]:  [Loss: 0.34]\n",
      "[Epoch 12, Batch 750/1000]:  [Loss: 2.04]\n",
      "At epoch 12 the training loss is 0.981644660949707\n",
      "At epoch 12 the training accuracy is 0.661\n",
      "At epoch 12 :\n",
      "The test loss is 1.156657099723816\n",
      "The test accuracy is 0.686\n",
      "[Epoch 13, Batch 0/1000]:  [Loss: 0.50]\n",
      "[Epoch 13, Batch 250/1000]:  [Loss: 0.35]\n",
      "[Epoch 13, Batch 500/1000]:  [Loss: 0.44]\n",
      "[Epoch 13, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 13 the training loss is 0.9133335111439228\n",
      "At epoch 13 the training accuracy is 0.671\n",
      "At epoch 13 :\n",
      "The test loss is 1.1085517406463623\n",
      "The test accuracy is 0.686\n",
      "[Epoch 14, Batch 0/1000]:  [Loss: 3.23]\n",
      "[Epoch 14, Batch 250/1000]:  [Loss: 2.01]\n",
      "[Epoch 14, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 14, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 14 the training loss is 0.855543310970068\n",
      "At epoch 14 the training accuracy is 0.679\n",
      "At epoch 14 :\n",
      "The test loss is 1.0736899375915527\n",
      "The test accuracy is 0.691\n",
      "[Epoch 15, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 15, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 15, Batch 500/1000]:  [Loss: 0.31]\n",
      "[Epoch 15, Batch 750/1000]:  [Loss: 1.43]\n",
      "At epoch 15 the training loss is 0.802625165104866\n",
      "At epoch 15 the training accuracy is 0.685\n",
      "At epoch 15 :\n",
      "The test loss is 1.048501968383789\n",
      "The test accuracy is 0.693\n",
      "[Epoch 16, Batch 0/1000]:  [Loss: 0.28]\n",
      "[Epoch 16, Batch 250/1000]:  [Loss: 2.74]\n",
      "[Epoch 16, Batch 500/1000]:  [Loss: 0.27]\n",
      "[Epoch 16, Batch 750/1000]:  [Loss: 0.36]\n",
      "At epoch 16 the training loss is 0.7597029570937157\n",
      "At epoch 16 the training accuracy is 0.695\n",
      "At epoch 16 :\n",
      "The test loss is 1.0230976343154907\n",
      "The test accuracy is 0.707\n",
      "[Epoch 17, Batch 0/1000]:  [Loss: 0.30]\n",
      "[Epoch 17, Batch 250/1000]:  [Loss: 1.45]\n",
      "[Epoch 17, Batch 500/1000]:  [Loss: 0.37]\n",
      "[Epoch 17, Batch 750/1000]:  [Loss: 1.04]\n",
      "At epoch 17 the training loss is 0.7194373880326748\n",
      "At epoch 17 the training accuracy is 0.708\n",
      "At epoch 17 :\n",
      "The test loss is 0.999544620513916\n",
      "The test accuracy is 0.717\n",
      "[Epoch 18, Batch 0/1000]:  [Loss: 5.08]\n",
      "[Epoch 18, Batch 250/1000]:  [Loss: 0.31]\n",
      "[Epoch 18, Batch 500/1000]:  [Loss: 1.87]\n",
      "[Epoch 18, Batch 750/1000]:  [Loss: 0.47]\n",
      "At epoch 18 the training loss is 0.6834386371672153\n",
      "At epoch 18 the training accuracy is 0.724\n",
      "At epoch 18 :\n",
      "The test loss is 0.977888822555542\n",
      "The test accuracy is 0.73\n",
      "[Epoch 19, Batch 0/1000]:  [Loss: 0.36]\n",
      "[Epoch 19, Batch 250/1000]:  [Loss: 0.40]\n",
      "[Epoch 19, Batch 500/1000]:  [Loss: 0.28]\n",
      "[Epoch 19, Batch 750/1000]:  [Loss: 2.97]\n",
      "At epoch 19 the training loss is 0.6497667972147465\n",
      "At epoch 19 the training accuracy is 0.742\n",
      "At epoch 19 :\n",
      "The test loss is 0.96659255027771\n",
      "The test accuracy is 0.735\n",
      "[Epoch 20, Batch 0/1000]:  [Loss: 0.32]\n",
      "[Epoch 20, Batch 250/1000]:  [Loss: 0.39]\n",
      "[Epoch 20, Batch 500/1000]:  [Loss: 2.41]\n",
      "[Epoch 20, Batch 750/1000]:  [Loss: 0.29]\n",
      "At epoch 20 the training loss is 0.6201978612393141\n",
      "At epoch 20 the training accuracy is 0.749\n",
      "At epoch 20 :\n",
      "The test loss is 0.9462481737136841\n",
      "The test accuracy is 0.742\n",
      "NO CUDA\n",
      "[Epoch 1, Batch 0/1000]:  [Loss: 16.86]\n",
      "[Epoch 1, Batch 250/1000]:  [Loss: 3.83]\n",
      "[Epoch 1, Batch 500/1000]:  [Loss: 5.10]\n",
      "[Epoch 1, Batch 750/1000]:  [Loss: 2.90]\n",
      "At epoch 1 the training loss is 7.492637197822332\n",
      "At epoch 1 the training accuracy is 0.485\n",
      "At epoch 1 :\n",
      "The test loss is 4.726393699645996\n",
      "The test accuracy is 0.476\n",
      "[Epoch 2, Batch 0/1000]:  [Loss: 4.80]\n",
      "[Epoch 2, Batch 250/1000]:  [Loss: 1.57]\n",
      "[Epoch 2, Batch 500/1000]:  [Loss: 8.89]\n",
      "[Epoch 2, Batch 750/1000]:  [Loss: 4.74]\n",
      "At epoch 2 the training loss is 3.7835345421135425\n",
      "At epoch 2 the training accuracy is 0.492\n",
      "At epoch 2 :\n",
      "The test loss is 2.8949413299560547\n",
      "The test accuracy is 0.487\n",
      "[Epoch 3, Batch 0/1000]:  [Loss: 1.02]\n",
      "[Epoch 3, Batch 250/1000]:  [Loss: 0.44]\n",
      "[Epoch 3, Batch 500/1000]:  [Loss: 2.91]\n",
      "[Epoch 3, Batch 750/1000]:  [Loss: 0.37]\n",
      "At epoch 3 the training loss is 2.4573564583063128\n",
      "At epoch 3 the training accuracy is 0.497\n",
      "At epoch 3 :\n",
      "The test loss is 2.0525808334350586\n",
      "The test accuracy is 0.492\n",
      "[Epoch 4, Batch 0/1000]:  [Loss: 0.38]\n",
      "[Epoch 4, Batch 250/1000]:  [Loss: 3.16]\n",
      "[Epoch 4, Batch 500/1000]:  [Loss: 1.36]\n",
      "[Epoch 4, Batch 750/1000]:  [Loss: 2.25]\n",
      "At epoch 4 the training loss is 1.8053814277350904\n",
      "At epoch 4 the training accuracy is 0.487\n",
      "At epoch 4 :\n",
      "The test loss is 1.6411652565002441\n",
      "The test accuracy is 0.53\n",
      "[Epoch 5, Batch 0/1000]:  [Loss: 0.49]\n",
      "[Epoch 5, Batch 250/1000]:  [Loss: 0.50]\n",
      "[Epoch 5, Batch 500/1000]:  [Loss: 0.36]\n",
      "[Epoch 5, Batch 750/1000]:  [Loss: 0.31]\n",
      "At epoch 5 the training loss is 1.4398961883485317\n",
      "At epoch 5 the training accuracy is 0.524\n",
      "At epoch 5 :\n",
      "The test loss is 1.394709587097168\n",
      "The test accuracy is 0.577\n",
      "[Epoch 6, Batch 0/1000]:  [Loss: 1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6, Batch 250/1000]:  [Loss: 0.35]\n",
      "[Epoch 6, Batch 500/1000]:  [Loss: 0.39]\n",
      "[Epoch 6, Batch 750/1000]:  [Loss: 5.40]\n",
      "At epoch 6 the training loss is 1.2101511539518832\n",
      "At epoch 6 the training accuracy is 0.574\n",
      "At epoch 6 :\n",
      "The test loss is 1.2553205490112305\n",
      "The test accuracy is 0.589\n",
      "[Epoch 7, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 7, Batch 250/1000]:  [Loss: 5.80]\n",
      "[Epoch 7, Batch 500/1000]:  [Loss: 1.18]\n",
      "[Epoch 7, Batch 750/1000]:  [Loss: 1.73]\n",
      "At epoch 7 the training loss is 1.0547651257812978\n",
      "At epoch 7 the training accuracy is 0.582\n",
      "At epoch 7 :\n",
      "The test loss is 1.1550334692001343\n",
      "The test accuracy is 0.61\n",
      "[Epoch 8, Batch 0/1000]:  [Loss: 0.37]\n",
      "[Epoch 8, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 8, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 8, Batch 750/1000]:  [Loss: 0.34]\n",
      "At epoch 8 the training loss is 0.9376465029418468\n",
      "At epoch 8 the training accuracy is 0.641\n",
      "At epoch 8 :\n",
      "The test loss is 1.0856037139892578\n",
      "The test accuracy is 0.663\n",
      "[Epoch 9, Batch 0/1000]:  [Loss: 0.35]\n",
      "[Epoch 9, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 9, Batch 500/1000]:  [Loss: 0.38]\n",
      "[Epoch 9, Batch 750/1000]:  [Loss: 0.36]\n",
      "At epoch 9 the training loss is 0.8510250151455402\n",
      "At epoch 9 the training accuracy is 0.662\n",
      "At epoch 9 :\n",
      "The test loss is 1.026292324066162\n",
      "The test accuracy is 0.679\n",
      "[Epoch 10, Batch 0/1000]:  [Loss: 0.31]\n",
      "[Epoch 10, Batch 250/1000]:  [Loss: 0.31]\n",
      "[Epoch 10, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 10, Batch 750/1000]:  [Loss: 0.36]\n",
      "At epoch 10 the training loss is 0.7755183885395527\n",
      "At epoch 10 the training accuracy is 0.694\n",
      "At epoch 10 :\n",
      "The test loss is 0.987278938293457\n",
      "The test accuracy is 0.708\n",
      "[Epoch 11, Batch 0/1000]:  [Loss: 0.41]\n",
      "[Epoch 11, Batch 250/1000]:  [Loss: 0.30]\n",
      "[Epoch 11, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 11, Batch 750/1000]:  [Loss: 0.32]\n",
      "At epoch 11 the training loss is 0.7180227805972099\n",
      "At epoch 11 the training accuracy is 0.708\n",
      "At epoch 11 :\n",
      "The test loss is 0.9588552713394165\n",
      "The test accuracy is 0.726\n",
      "[Epoch 12, Batch 0/1000]:  [Loss: 0.38]\n",
      "[Epoch 12, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 12, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 12, Batch 750/1000]:  [Loss: 0.76]\n",
      "At epoch 12 the training loss is 0.6673227676451207\n",
      "At epoch 12 the training accuracy is 0.727\n",
      "At epoch 12 :\n",
      "The test loss is 0.9246015548706055\n",
      "The test accuracy is 0.728\n",
      "[Epoch 13, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 13, Batch 250/1000]:  [Loss: 0.37]\n",
      "[Epoch 13, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 13, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 13 the training loss is 0.6245795388221741\n",
      "At epoch 13 the training accuracy is 0.732\n",
      "At epoch 13 :\n",
      "The test loss is 0.9047694206237793\n",
      "The test accuracy is 0.765\n",
      "[Epoch 14, Batch 0/1000]:  [Loss: 0.36]\n",
      "[Epoch 14, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 14, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 14, Batch 750/1000]:  [Loss: 0.39]\n",
      "At epoch 14 the training loss is 0.5843682547807694\n",
      "At epoch 14 the training accuracy is 0.771\n",
      "At epoch 14 :\n",
      "The test loss is 0.8877684473991394\n",
      "The test accuracy is 0.791\n",
      "[Epoch 15, Batch 0/1000]:  [Loss: 0.29]\n",
      "[Epoch 15, Batch 250/1000]:  [Loss: 0.84]\n",
      "[Epoch 15, Batch 500/1000]:  [Loss: 0.36]\n",
      "[Epoch 15, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 15 the training loss is 0.5494249823093414\n",
      "At epoch 15 the training accuracy is 0.797\n",
      "At epoch 15 :\n",
      "The test loss is 0.8676474094390869\n",
      "The test accuracy is 0.796\n",
      "[Epoch 16, Batch 0/1000]:  [Loss: 0.36]\n",
      "[Epoch 16, Batch 250/1000]:  [Loss: 0.35]\n",
      "[Epoch 16, Batch 500/1000]:  [Loss: 0.97]\n",
      "[Epoch 16, Batch 750/1000]:  [Loss: 1.30]\n",
      "At epoch 16 the training loss is 0.5202036353796721\n",
      "At epoch 16 the training accuracy is 0.807\n",
      "At epoch 16 :\n",
      "The test loss is 0.8586025238037109\n",
      "The test accuracy is 0.816\n",
      "[Epoch 17, Batch 0/1000]:  [Loss: 0.35]\n",
      "[Epoch 17, Batch 250/1000]:  [Loss: 0.51]\n",
      "[Epoch 17, Batch 500/1000]:  [Loss: 0.31]\n",
      "[Epoch 17, Batch 750/1000]:  [Loss: 0.34]\n",
      "At epoch 17 the training loss is 0.48986864133179187\n",
      "At epoch 17 the training accuracy is 0.826\n",
      "At epoch 17 :\n",
      "The test loss is 0.8464552760124207\n",
      "The test accuracy is 0.825\n",
      "[Epoch 18, Batch 0/1000]:  [Loss: 0.30]\n",
      "[Epoch 18, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 18, Batch 500/1000]:  [Loss: 0.30]\n",
      "[Epoch 18, Batch 750/1000]:  [Loss: 0.33]\n",
      "At epoch 18 the training loss is 0.46834705881774424\n",
      "At epoch 18 the training accuracy is 0.839\n",
      "At epoch 18 :\n",
      "The test loss is 0.8348857164382935\n",
      "The test accuracy is 0.832\n",
      "[Epoch 19, Batch 0/1000]:  [Loss: 0.36]\n",
      "[Epoch 19, Batch 250/1000]:  [Loss: 0.37]\n",
      "[Epoch 19, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 19, Batch 750/1000]:  [Loss: 0.33]\n",
      "At epoch 19 the training loss is 0.44380406698584557\n",
      "At epoch 19 the training accuracy is 0.845\n",
      "At epoch 19 :\n",
      "The test loss is 0.8270447254180908\n",
      "The test accuracy is 0.838\n",
      "[Epoch 20, Batch 0/1000]:  [Loss: 0.31]\n",
      "[Epoch 20, Batch 250/1000]:  [Loss: 0.28]\n",
      "[Epoch 20, Batch 500/1000]:  [Loss: 0.34]\n",
      "[Epoch 20, Batch 750/1000]:  [Loss: 0.28]\n",
      "At epoch 20 the training loss is 0.42558539265394213\n",
      "At epoch 20 the training accuracy is 0.856\n",
      "At epoch 20 :\n",
      "The test loss is 0.8059028387069702\n",
      "The test accuracy is 0.846\n",
      "NO CUDA\n",
      "[Epoch 1, Batch 0/1000]:  [Loss: 20.72]\n",
      "[Epoch 1, Batch 250/1000]:  [Loss: 11.63]\n",
      "[Epoch 1, Batch 500/1000]:  [Loss: 8.27]\n",
      "[Epoch 1, Batch 750/1000]:  [Loss: 5.81]\n",
      "At epoch 1 the training loss is 7.282315703600645\n",
      "At epoch 1 the training accuracy is 0.535\n",
      "At epoch 1 :\n",
      "The test loss is 4.300959587097168\n",
      "The test accuracy is 0.548\n",
      "[Epoch 2, Batch 0/1000]:  [Loss: 3.69]\n",
      "[Epoch 2, Batch 250/1000]:  [Loss: 0.42]\n",
      "[Epoch 2, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 2, Batch 750/1000]:  [Loss: 1.93]\n",
      "At epoch 2 the training loss is 3.1386667897999287\n",
      "At epoch 2 the training accuracy is 0.633\n",
      "At epoch 2 :\n",
      "The test loss is 2.4435477256774902\n",
      "The test accuracy is 0.616\n",
      "[Epoch 3, Batch 0/1000]:  [Loss: 1.02]\n",
      "[Epoch 3, Batch 250/1000]:  [Loss: 1.46]\n",
      "[Epoch 3, Batch 500/1000]:  [Loss: 1.96]\n",
      "[Epoch 3, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 3 the training loss is 1.9983331967294216\n",
      "At epoch 3 the training accuracy is 0.665\n",
      "At epoch 3 :\n",
      "The test loss is 1.8195109367370605\n",
      "The test accuracy is 0.675\n",
      "[Epoch 4, Batch 0/1000]:  [Loss: 0.39]\n",
      "[Epoch 4, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 4, Batch 500/1000]:  [Loss: 0.56]\n",
      "[Epoch 4, Batch 750/1000]:  [Loss: 0.49]\n",
      "At epoch 4 the training loss is 1.513316503584385\n",
      "At epoch 4 the training accuracy is 0.703\n",
      "At epoch 4 :\n",
      "The test loss is 1.5269886255264282\n",
      "The test accuracy is 0.708\n",
      "[Epoch 5, Batch 0/1000]:  [Loss: 0.85]\n",
      "[Epoch 5, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 5, Batch 500/1000]:  [Loss: 1.14]\n",
      "[Epoch 5, Batch 750/1000]:  [Loss: 0.44]\n",
      "At epoch 5 the training loss is 1.2486792166829108\n",
      "At epoch 5 the training accuracy is 0.723\n",
      "At epoch 5 :\n",
      "The test loss is 1.36887788772583\n",
      "The test accuracy is 0.73\n",
      "[Epoch 6, Batch 0/1000]:  [Loss: 4.44]\n",
      "[Epoch 6, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 6, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 6, Batch 750/1000]:  [Loss: 2.24]\n",
      "At epoch 6 the training loss is 1.0672458733022212\n",
      "At epoch 6 the training accuracy is 0.735\n",
      "At epoch 6 :\n",
      "The test loss is 1.2478433847427368\n",
      "The test accuracy is 0.75\n",
      "[Epoch 7, Batch 0/1000]:  [Loss: 0.90]\n",
      "[Epoch 7, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 7, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 7, Batch 750/1000]:  [Loss: 0.41]\n",
      "At epoch 7 the training loss is 0.9276445927023887\n",
      "At epoch 7 the training accuracy is 0.768\n",
      "At epoch 7 :\n",
      "The test loss is 1.147104263305664\n",
      "The test accuracy is 0.781\n",
      "[Epoch 8, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 8, Batch 250/1000]:  [Loss: 0.31]\n",
      "[Epoch 8, Batch 500/1000]:  [Loss: 1.60]\n",
      "[Epoch 8, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 8 the training loss is 0.8214682770371438\n",
      "At epoch 8 the training accuracy is 0.77\n",
      "At epoch 8 :\n",
      "The test loss is 1.088010549545288\n",
      "The test accuracy is 0.779\n",
      "[Epoch 9, Batch 0/1000]:  [Loss: 0.89]\n",
      "[Epoch 9, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 9, Batch 500/1000]:  [Loss: 2.16]\n",
      "[Epoch 9, Batch 750/1000]:  [Loss: 0.39]\n",
      "At epoch 9 the training loss is 0.7342695297300815\n",
      "At epoch 9 the training accuracy is 0.772\n",
      "At epoch 9 :\n",
      "The test loss is 1.071806788444519\n",
      "The test accuracy is 0.79\n",
      "[Epoch 10, Batch 0/1000]:  [Loss: 0.32]\n",
      "[Epoch 10, Batch 250/1000]:  [Loss: 1.65]\n",
      "[Epoch 10, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 10, Batch 750/1000]:  [Loss: 1.45]\n",
      "At epoch 10 the training loss is 0.6730838059186935\n",
      "At epoch 10 the training accuracy is 0.789\n",
      "At epoch 10 :\n",
      "The test loss is 1.0054271221160889\n",
      "The test accuracy is 0.814\n",
      "[Epoch 11, Batch 0/1000]:  [Loss: 0.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 11, Batch 500/1000]:  [Loss: 0.34]\n",
      "[Epoch 11, Batch 750/1000]:  [Loss: 0.34]\n",
      "At epoch 11 the training loss is 0.615587476760149\n",
      "At epoch 11 the training accuracy is 0.809\n",
      "At epoch 11 :\n",
      "The test loss is 0.9812619686126709\n",
      "The test accuracy is 0.81\n",
      "[Epoch 12, Batch 0/1000]:  [Loss: 3.31]\n",
      "[Epoch 12, Batch 250/1000]:  [Loss: 0.30]\n",
      "[Epoch 12, Batch 500/1000]:  [Loss: 0.31]\n",
      "[Epoch 12, Batch 750/1000]:  [Loss: 0.34]\n",
      "At epoch 12 the training loss is 0.5665836004018784\n",
      "At epoch 12 the training accuracy is 0.817\n",
      "At epoch 12 :\n",
      "The test loss is 0.9606000185012817\n",
      "The test accuracy is 0.818\n",
      "[Epoch 13, Batch 0/1000]:  [Loss: 1.36]\n",
      "[Epoch 13, Batch 250/1000]:  [Loss: 0.30]\n",
      "[Epoch 13, Batch 500/1000]:  [Loss: 0.31]\n",
      "[Epoch 13, Batch 750/1000]:  [Loss: 1.99]\n",
      "At epoch 13 the training loss is 0.5252539564222097\n",
      "At epoch 13 the training accuracy is 0.823\n",
      "At epoch 13 :\n",
      "The test loss is 0.9390652179718018\n",
      "The test accuracy is 0.816\n",
      "[Epoch 14, Batch 0/1000]:  [Loss: 0.35]\n",
      "[Epoch 14, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 14, Batch 500/1000]:  [Loss: 0.30]\n",
      "[Epoch 14, Batch 750/1000]:  [Loss: 0.30]\n",
      "At epoch 14 the training loss is 0.48860281479358675\n",
      "At epoch 14 the training accuracy is 0.826\n",
      "At epoch 14 :\n",
      "The test loss is 0.9241784811019897\n",
      "The test accuracy is 0.82\n",
      "[Epoch 15, Batch 0/1000]:  [Loss: 0.25]\n",
      "[Epoch 15, Batch 250/1000]:  [Loss: 0.30]\n",
      "[Epoch 15, Batch 500/1000]:  [Loss: 3.11]\n",
      "[Epoch 15, Batch 750/1000]:  [Loss: 0.89]\n",
      "At epoch 15 the training loss is 0.4616440808922052\n",
      "At epoch 15 the training accuracy is 0.84\n",
      "At epoch 15 :\n",
      "The test loss is 0.8940426111221313\n",
      "The test accuracy is 0.83\n",
      "[Epoch 16, Batch 0/1000]:  [Loss: 0.34]\n",
      "[Epoch 16, Batch 250/1000]:  [Loss: 0.28]\n",
      "[Epoch 16, Batch 500/1000]:  [Loss: 0.30]\n",
      "[Epoch 16, Batch 750/1000]:  [Loss: 0.36]\n",
      "At epoch 16 the training loss is 0.4342720825523138\n",
      "At epoch 16 the training accuracy is 0.856\n",
      "At epoch 16 :\n",
      "The test loss is 0.880824089050293\n",
      "The test accuracy is 0.826\n",
      "[Epoch 17, Batch 0/1000]:  [Loss: 0.41]\n",
      "[Epoch 17, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 17, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 17, Batch 750/1000]:  [Loss: 0.31]\n",
      "At epoch 17 the training loss is 0.41098486521840094\n",
      "At epoch 17 the training accuracy is 0.852\n",
      "At epoch 17 :\n",
      "The test loss is 0.8652951717376709\n",
      "The test accuracy is 0.831\n",
      "[Epoch 18, Batch 0/1000]:  [Loss: 0.35]\n",
      "[Epoch 18, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 18, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 18, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 18 the training loss is 0.3895462759137154\n",
      "At epoch 18 the training accuracy is 0.86\n",
      "At epoch 18 :\n",
      "The test loss is 0.8539322018623352\n",
      "The test accuracy is 0.838\n",
      "[Epoch 19, Batch 0/1000]:  [Loss: 0.22]\n",
      "[Epoch 19, Batch 250/1000]:  [Loss: 0.30]\n",
      "[Epoch 19, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 19, Batch 750/1000]:  [Loss: 0.28]\n",
      "At epoch 19 the training loss is 0.37274822205305097\n",
      "At epoch 19 the training accuracy is 0.871\n",
      "At epoch 19 :\n",
      "The test loss is 0.8492058515548706\n",
      "The test accuracy is 0.842\n",
      "[Epoch 20, Batch 0/1000]:  [Loss: 0.34]\n",
      "[Epoch 20, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 20, Batch 500/1000]:  [Loss: 0.29]\n",
      "[Epoch 20, Batch 750/1000]:  [Loss: 0.29]\n",
      "At epoch 20 the training loss is 0.35577361612021924\n",
      "At epoch 20 the training accuracy is 0.872\n",
      "At epoch 20 :\n",
      "The test loss is 0.8297044038772583\n",
      "The test accuracy is 0.839\n",
      "NO CUDA\n",
      "[Epoch 1, Batch 0/1000]:  [Loss: 9.29]\n",
      "[Epoch 1, Batch 250/1000]:  [Loss: 3.47]\n",
      "[Epoch 1, Batch 500/1000]:  [Loss: 11.31]\n",
      "[Epoch 1, Batch 750/1000]:  [Loss: 0.87]\n",
      "At epoch 1 the training loss is 6.686736354529858\n",
      "At epoch 1 the training accuracy is 0.491\n",
      "At epoch 1 :\n",
      "The test loss is 3.3731141090393066\n",
      "The test accuracy is 0.499\n",
      "[Epoch 2, Batch 0/1000]:  [Loss: 0.34]\n",
      "[Epoch 2, Batch 250/1000]:  [Loss: 4.13]\n",
      "[Epoch 2, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 2, Batch 750/1000]:  [Loss: 3.89]\n",
      "At epoch 2 the training loss is 2.5924089758992195\n",
      "At epoch 2 the training accuracy is 0.489\n",
      "At epoch 2 :\n",
      "The test loss is 2.123307704925537\n",
      "The test accuracy is 0.522\n",
      "[Epoch 3, Batch 0/1000]:  [Loss: 0.61]\n",
      "[Epoch 3, Batch 250/1000]:  [Loss: 2.07]\n",
      "[Epoch 3, Batch 500/1000]:  [Loss: 0.81]\n",
      "[Epoch 3, Batch 750/1000]:  [Loss: 1.80]\n",
      "At epoch 3 the training loss is 1.703510658353567\n",
      "At epoch 3 the training accuracy is 0.493\n",
      "At epoch 3 :\n",
      "The test loss is 1.6433261632919312\n",
      "The test accuracy is 0.581\n",
      "[Epoch 4, Batch 0/1000]:  [Loss: 1.02]\n",
      "[Epoch 4, Batch 250/1000]:  [Loss: 0.43]\n",
      "[Epoch 4, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 4, Batch 750/1000]:  [Loss: 0.40]\n",
      "At epoch 4 the training loss is 1.2915731046199799\n",
      "At epoch 4 the training accuracy is 0.532\n",
      "At epoch 4 :\n",
      "The test loss is 1.4134418964385986\n",
      "The test accuracy is 0.623\n",
      "[Epoch 5, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 5, Batch 250/1000]:  [Loss: 1.58]\n",
      "[Epoch 5, Batch 500/1000]:  [Loss: 0.36]\n",
      "[Epoch 5, Batch 750/1000]:  [Loss: 0.32]\n",
      "At epoch 5 the training loss is 1.049703700453043\n",
      "At epoch 5 the training accuracy is 0.59\n",
      "At epoch 5 :\n",
      "The test loss is 1.251242756843567\n",
      "The test accuracy is 0.648\n",
      "[Epoch 6, Batch 0/1000]:  [Loss: 0.39]\n",
      "[Epoch 6, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 6, Batch 500/1000]:  [Loss: 3.01]\n",
      "[Epoch 6, Batch 750/1000]:  [Loss: 0.36]\n",
      "At epoch 6 the training loss is 0.8779127242565155\n",
      "At epoch 6 the training accuracy is 0.614\n",
      "At epoch 6 :\n",
      "The test loss is 1.1446532011032104\n",
      "The test accuracy is 0.674\n",
      "[Epoch 7, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 7, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 7, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 7, Batch 750/1000]:  [Loss: 3.08]\n",
      "At epoch 7 the training loss is 0.7592975656092167\n",
      "At epoch 7 the training accuracy is 0.649\n",
      "At epoch 7 :\n",
      "The test loss is 1.0664955377578735\n",
      "The test accuracy is 0.696\n",
      "[Epoch 8, Batch 0/1000]:  [Loss: 0.31]\n",
      "[Epoch 8, Batch 250/1000]:  [Loss: 0.46]\n",
      "[Epoch 8, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 8, Batch 750/1000]:  [Loss: 0.34]\n",
      "At epoch 8 the training loss is 0.6741174025535583\n",
      "At epoch 8 the training accuracy is 0.683\n",
      "At epoch 8 :\n",
      "The test loss is 1.0307399034500122\n",
      "The test accuracy is 0.716\n",
      "[Epoch 9, Batch 0/1000]:  [Loss: 0.62]\n",
      "[Epoch 9, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 9, Batch 500/1000]:  [Loss: 2.04]\n",
      "[Epoch 9, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 9 the training loss is 0.6131118471324444\n",
      "At epoch 9 the training accuracy is 0.73\n",
      "At epoch 9 :\n",
      "The test loss is 0.9843970537185669\n",
      "The test accuracy is 0.756\n",
      "[Epoch 10, Batch 0/1000]:  [Loss: 1.18]\n",
      "[Epoch 10, Batch 250/1000]:  [Loss: 1.77]\n",
      "[Epoch 10, Batch 500/1000]:  [Loss: 0.43]\n",
      "[Epoch 10, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 10 the training loss is 0.5558319571316243\n",
      "At epoch 10 the training accuracy is 0.751\n",
      "At epoch 10 :\n",
      "The test loss is 0.9585373997688293\n",
      "The test accuracy is 0.774\n",
      "[Epoch 11, Batch 0/1000]:  [Loss: 2.08]\n",
      "[Epoch 11, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 11, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 11, Batch 750/1000]:  [Loss: 0.32]\n",
      "At epoch 11 the training loss is 0.5151540694236756\n",
      "At epoch 11 the training accuracy is 0.768\n",
      "At epoch 11 :\n",
      "The test loss is 0.9246558547019958\n",
      "The test accuracy is 0.77\n",
      "[Epoch 12, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 12, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 12, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 12, Batch 750/1000]:  [Loss: 0.44]\n",
      "At epoch 12 the training loss is 0.47627607569098473\n",
      "At epoch 12 the training accuracy is 0.778\n",
      "At epoch 12 :\n",
      "The test loss is 0.9134902358055115\n",
      "The test accuracy is 0.781\n",
      "[Epoch 13, Batch 0/1000]:  [Loss: 0.38]\n",
      "[Epoch 13, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 13, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 13, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 13 the training loss is 0.44544071301817895\n",
      "At epoch 13 the training accuracy is 0.8\n",
      "At epoch 13 :\n",
      "The test loss is 0.9204707145690918\n",
      "The test accuracy is 0.802\n",
      "[Epoch 14, Batch 0/1000]:  [Loss: 0.32]\n",
      "[Epoch 14, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 14, Batch 500/1000]:  [Loss: 0.34]\n",
      "[Epoch 14, Batch 750/1000]:  [Loss: 0.34]\n",
      "At epoch 14 the training loss is 0.4201176231503487\n",
      "At epoch 14 the training accuracy is 0.806\n",
      "At epoch 14 :\n",
      "The test loss is 0.8861101865768433\n",
      "The test accuracy is 0.81\n",
      "[Epoch 15, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 15, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 15, Batch 500/1000]:  [Loss: 0.37]\n",
      "[Epoch 15, Batch 750/1000]:  [Loss: 0.36]\n",
      "At epoch 15 the training loss is 0.39235938793420794\n",
      "At epoch 15 the training accuracy is 0.817\n",
      "At epoch 15 :\n",
      "The test loss is 0.8832597732543945\n",
      "The test accuracy is 0.814\n",
      "[Epoch 16, Batch 0/1000]:  [Loss: 0.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16, Batch 250/1000]:  [Loss: 0.31]\n",
      "[Epoch 16, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 16, Batch 750/1000]:  [Loss: 0.27]\n",
      "At epoch 16 the training loss is 0.3731787416934967\n",
      "At epoch 16 the training accuracy is 0.832\n",
      "At epoch 16 :\n",
      "The test loss is 0.8595101833343506\n",
      "The test accuracy is 0.83\n",
      "[Epoch 17, Batch 0/1000]:  [Loss: 0.35]\n",
      "[Epoch 17, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 17, Batch 500/1000]:  [Loss: 0.27]\n",
      "[Epoch 17, Batch 750/1000]:  [Loss: 0.26]\n",
      "At epoch 17 the training loss is 0.35575792081654073\n",
      "At epoch 17 the training accuracy is 0.844\n",
      "At epoch 17 :\n",
      "The test loss is 0.8491383790969849\n",
      "The test accuracy is 0.826\n",
      "[Epoch 18, Batch 0/1000]:  [Loss: 0.34]\n",
      "[Epoch 18, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 18, Batch 500/1000]:  [Loss: 0.39]\n",
      "[Epoch 18, Batch 750/1000]:  [Loss: 0.39]\n",
      "At epoch 18 the training loss is 0.34226611395180223\n",
      "At epoch 18 the training accuracy is 0.853\n",
      "At epoch 18 :\n",
      "The test loss is 0.8483726978302002\n",
      "The test accuracy is 0.83\n",
      "[Epoch 19, Batch 0/1000]:  [Loss: 0.32]\n",
      "[Epoch 19, Batch 250/1000]:  [Loss: 0.30]\n",
      "[Epoch 19, Batch 500/1000]:  [Loss: 0.31]\n",
      "[Epoch 19, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 19 the training loss is 0.3320474044382572\n",
      "At epoch 19 the training accuracy is 0.856\n",
      "At epoch 19 :\n",
      "The test loss is 0.8187073469161987\n",
      "The test accuracy is 0.83\n",
      "[Epoch 20, Batch 0/1000]:  [Loss: 0.34]\n",
      "[Epoch 20, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 20, Batch 500/1000]:  [Loss: 0.27]\n",
      "[Epoch 20, Batch 750/1000]:  [Loss: 0.31]\n",
      "At epoch 20 the training loss is 0.320766904309392\n",
      "At epoch 20 the training accuracy is 0.856\n",
      "At epoch 20 :\n",
      "The test loss is 0.8103634715080261\n",
      "The test accuracy is 0.832\n",
      "NO CUDA\n",
      "[Epoch 1, Batch 0/1000]:  [Loss: 11.42]\n",
      "[Epoch 1, Batch 250/1000]:  [Loss: 11.34]\n",
      "[Epoch 1, Batch 500/1000]:  [Loss: 2.55]\n",
      "[Epoch 1, Batch 750/1000]:  [Loss: 6.35]\n",
      "At epoch 1 the training loss is 6.825452563941479\n",
      "At epoch 1 the training accuracy is 0.53\n",
      "At epoch 1 :\n",
      "The test loss is 3.4195165634155273\n",
      "The test accuracy is 0.549\n",
      "[Epoch 2, Batch 0/1000]:  [Loss: 10.37]\n",
      "[Epoch 2, Batch 250/1000]:  [Loss: 6.71]\n",
      "[Epoch 2, Batch 500/1000]:  [Loss: 0.49]\n",
      "[Epoch 2, Batch 750/1000]:  [Loss: 0.99]\n",
      "At epoch 2 the training loss is 2.5134377068281175\n",
      "At epoch 2 the training accuracy is 0.531\n",
      "At epoch 2 :\n",
      "The test loss is 1.9618868827819824\n",
      "The test accuracy is 0.555\n",
      "[Epoch 3, Batch 0/1000]:  [Loss: 1.24]\n",
      "[Epoch 3, Batch 250/1000]:  [Loss: 2.25]\n",
      "[Epoch 3, Batch 500/1000]:  [Loss: 4.95]\n",
      "[Epoch 3, Batch 750/1000]:  [Loss: 0.41]\n",
      "At epoch 3 the training loss is 1.5557729651629926\n",
      "At epoch 3 the training accuracy is 0.539\n",
      "At epoch 3 :\n",
      "The test loss is 1.4850857257843018\n",
      "The test accuracy is 0.559\n",
      "[Epoch 4, Batch 0/1000]:  [Loss: 1.11]\n",
      "[Epoch 4, Batch 250/1000]:  [Loss: 5.49]\n",
      "[Epoch 4, Batch 500/1000]:  [Loss: 0.94]\n",
      "[Epoch 4, Batch 750/1000]:  [Loss: 0.36]\n",
      "At epoch 4 the training loss is 1.1582629384994507\n",
      "At epoch 4 the training accuracy is 0.541\n",
      "At epoch 4 :\n",
      "The test loss is 1.2632887363433838\n",
      "The test accuracy is 0.56\n",
      "[Epoch 5, Batch 0/1000]:  [Loss: 0.32]\n",
      "[Epoch 5, Batch 250/1000]:  [Loss: 0.43]\n",
      "[Epoch 5, Batch 500/1000]:  [Loss: 0.41]\n",
      "[Epoch 5, Batch 750/1000]:  [Loss: 0.40]\n",
      "At epoch 5 the training loss is 0.9349449077248573\n",
      "At epoch 5 the training accuracy is 0.549\n",
      "At epoch 5 :\n",
      "The test loss is 1.1331754922866821\n",
      "The test accuracy is 0.573\n",
      "[Epoch 6, Batch 0/1000]:  [Loss: 0.47]\n",
      "[Epoch 6, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 6, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 6, Batch 750/1000]:  [Loss: 0.31]\n",
      "At epoch 6 the training loss is 0.801313110023737\n",
      "At epoch 6 the training accuracy is 0.556\n",
      "At epoch 6 :\n",
      "The test loss is 1.066828727722168\n",
      "The test accuracy is 0.575\n",
      "[Epoch 7, Batch 0/1000]:  [Loss: 0.32]\n",
      "[Epoch 7, Batch 250/1000]:  [Loss: 0.36]\n",
      "[Epoch 7, Batch 500/1000]:  [Loss: 3.11]\n",
      "[Epoch 7, Batch 750/1000]:  [Loss: 0.35]\n",
      "At epoch 7 the training loss is 0.6991124179065228\n",
      "At epoch 7 the training accuracy is 0.561\n",
      "At epoch 7 :\n",
      "The test loss is 1.0237059593200684\n",
      "The test accuracy is 0.585\n",
      "[Epoch 8, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 8, Batch 250/1000]:  [Loss: 6.30]\n",
      "[Epoch 8, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 8, Batch 750/1000]:  [Loss: 1.12]\n",
      "At epoch 8 the training loss is 0.6193977368175984\n",
      "At epoch 8 the training accuracy is 0.566\n",
      "At epoch 8 :\n",
      "The test loss is 0.9996204376220703\n",
      "The test accuracy is 0.589\n",
      "[Epoch 9, Batch 0/1000]:  [Loss: 2.06]\n",
      "[Epoch 9, Batch 250/1000]:  [Loss: 0.30]\n",
      "[Epoch 9, Batch 500/1000]:  [Loss: 0.44]\n",
      "[Epoch 9, Batch 750/1000]:  [Loss: 0.33]\n",
      "At epoch 9 the training loss is 0.5652839162349701\n",
      "At epoch 9 the training accuracy is 0.579\n",
      "At epoch 9 :\n",
      "The test loss is 0.9525274634361267\n",
      "The test accuracy is 0.606\n",
      "[Epoch 10, Batch 0/1000]:  [Loss: 0.35]\n",
      "[Epoch 10, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 10, Batch 500/1000]:  [Loss: 0.30]\n",
      "[Epoch 10, Batch 750/1000]:  [Loss: 0.38]\n",
      "At epoch 10 the training loss is 0.5172332617640495\n",
      "At epoch 10 the training accuracy is 0.595\n",
      "At epoch 10 :\n",
      "The test loss is 0.9253305196762085\n",
      "The test accuracy is 0.622\n",
      "[Epoch 11, Batch 0/1000]:  [Loss: 0.31]\n",
      "[Epoch 11, Batch 250/1000]:  [Loss: 0.61]\n",
      "[Epoch 11, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 11, Batch 750/1000]:  [Loss: 0.54]\n",
      "At epoch 11 the training loss is 0.47363008791208266\n",
      "At epoch 11 the training accuracy is 0.626\n",
      "At epoch 11 :\n",
      "The test loss is 0.9135804772377014\n",
      "The test accuracy is 0.655\n",
      "[Epoch 12, Batch 0/1000]:  [Loss: 0.44]\n",
      "[Epoch 12, Batch 250/1000]:  [Loss: 0.38]\n",
      "[Epoch 12, Batch 500/1000]:  [Loss: 0.37]\n",
      "[Epoch 12, Batch 750/1000]:  [Loss: 0.33]\n",
      "At epoch 12 the training loss is 0.4412010001242161\n",
      "At epoch 12 the training accuracy is 0.651\n",
      "At epoch 12 :\n",
      "The test loss is 0.8832597732543945\n",
      "The test accuracy is 0.673\n",
      "[Epoch 13, Batch 0/1000]:  [Loss: 0.41]\n",
      "[Epoch 13, Batch 250/1000]:  [Loss: 1.16]\n",
      "[Epoch 13, Batch 500/1000]:  [Loss: 0.33]\n",
      "[Epoch 13, Batch 750/1000]:  [Loss: 0.38]\n",
      "At epoch 13 the training loss is 0.41283992731571195\n",
      "At epoch 13 the training accuracy is 0.684\n",
      "At epoch 13 :\n",
      "The test loss is 0.8916387557983398\n",
      "The test accuracy is 0.685\n",
      "[Epoch 14, Batch 0/1000]:  [Loss: 0.32]\n",
      "[Epoch 14, Batch 250/1000]:  [Loss: 0.37]\n",
      "[Epoch 14, Batch 500/1000]:  [Loss: 0.30]\n",
      "[Epoch 14, Batch 750/1000]:  [Loss: 0.50]\n",
      "At epoch 14 the training loss is 0.389512011796236\n",
      "At epoch 14 the training accuracy is 0.708\n",
      "At epoch 14 :\n",
      "The test loss is 0.8709594011306763\n",
      "The test accuracy is 0.737\n",
      "[Epoch 15, Batch 0/1000]:  [Loss: 0.34]\n",
      "[Epoch 15, Batch 250/1000]:  [Loss: 0.28]\n",
      "[Epoch 15, Batch 500/1000]:  [Loss: 0.27]\n",
      "[Epoch 15, Batch 750/1000]:  [Loss: 0.30]\n",
      "At epoch 15 the training loss is 0.3733209437429905\n",
      "At epoch 15 the training accuracy is 0.73\n",
      "At epoch 15 :\n",
      "The test loss is 0.8535200357437134\n",
      "The test accuracy is 0.755\n",
      "[Epoch 16, Batch 0/1000]:  [Loss: 0.37]\n",
      "[Epoch 16, Batch 250/1000]:  [Loss: 0.31]\n",
      "[Epoch 16, Batch 500/1000]:  [Loss: 0.37]\n",
      "[Epoch 16, Batch 750/1000]:  [Loss: 0.33]\n",
      "At epoch 16 the training loss is 0.35798298740386963\n",
      "At epoch 16 the training accuracy is 0.765\n",
      "At epoch 16 :\n",
      "The test loss is 0.8437579274177551\n",
      "The test accuracy is 0.766\n",
      "[Epoch 17, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 17, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 17, Batch 500/1000]:  [Loss: 0.35]\n",
      "[Epoch 17, Batch 750/1000]:  [Loss: 0.39]\n",
      "At epoch 17 the training loss is 0.34646262738108635\n",
      "At epoch 17 the training accuracy is 0.778\n",
      "At epoch 17 :\n",
      "The test loss is 0.828713059425354\n",
      "The test accuracy is 0.773\n",
      "[Epoch 18, Batch 0/1000]:  [Loss: 0.33]\n",
      "[Epoch 18, Batch 250/1000]:  [Loss: 0.29]\n",
      "[Epoch 18, Batch 500/1000]:  [Loss: 0.28]\n",
      "[Epoch 18, Batch 750/1000]:  [Loss: 0.36]\n",
      "At epoch 18 the training loss is 0.3363768141269684\n",
      "At epoch 18 the training accuracy is 0.779\n",
      "At epoch 18 :\n",
      "The test loss is 0.8381161689758301\n",
      "The test accuracy is 0.775\n",
      "[Epoch 19, Batch 0/1000]:  [Loss: 0.31]\n",
      "[Epoch 19, Batch 250/1000]:  [Loss: 0.31]\n",
      "[Epoch 19, Batch 500/1000]:  [Loss: 0.58]\n",
      "[Epoch 19, Batch 750/1000]:  [Loss: 0.38]\n",
      "At epoch 19 the training loss is 0.3296159988939762\n",
      "At epoch 19 the training accuracy is 0.784\n",
      "At epoch 19 :\n",
      "The test loss is 0.8265990018844604\n",
      "The test accuracy is 0.781\n",
      "[Epoch 20, Batch 0/1000]:  [Loss: 0.36]\n",
      "[Epoch 20, Batch 250/1000]:  [Loss: 0.35]\n",
      "[Epoch 20, Batch 500/1000]:  [Loss: 0.29]\n",
      "[Epoch 20, Batch 750/1000]:  [Loss: 0.31]\n",
      "At epoch 20 the training loss is 0.3219615567326546\n",
      "At epoch 20 the training accuracy is 0.796\n",
      "At epoch 20 :\n",
      "The test loss is 0.8205851316452026\n",
      "The test accuracy is 0.796\n",
      "NO CUDA\n",
      "[Epoch 1, Batch 0/1000]:  [Loss: 6.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 250/1000]:  [Loss: 2.21]\n",
      "[Epoch 1, Batch 500/1000]:  [Loss: 3.11]\n",
      "[Epoch 1, Batch 750/1000]:  [Loss: 1.97]\n",
      "At epoch 1 the training loss is 2.887934272021055\n",
      "At epoch 1 the training accuracy is 0.53\n",
      "At epoch 1 :\n",
      "The test loss is 1.9336130619049072\n",
      "The test accuracy is 0.547\n",
      "[Epoch 2, Batch 0/1000]:  [Loss: 0.81]\n",
      "[Epoch 2, Batch 250/1000]:  [Loss: 2.31]\n",
      "[Epoch 2, Batch 500/1000]:  [Loss: 1.59]\n",
      "[Epoch 2, Batch 750/1000]:  [Loss: 1.83]\n",
      "At epoch 2 the training loss is 1.6658391935825347\n",
      "At epoch 2 the training accuracy is 0.527\n",
      "At epoch 2 :\n",
      "The test loss is 1.3871643543243408\n",
      "The test accuracy is 0.551\n",
      "[Epoch 3, Batch 0/1000]:  [Loss: 2.40]\n",
      "[Epoch 3, Batch 250/1000]:  [Loss: 0.59]\n",
      "[Epoch 3, Batch 500/1000]:  [Loss: 2.46]\n",
      "[Epoch 3, Batch 750/1000]:  [Loss: 1.94]\n",
      "At epoch 3 the training loss is 1.2549116535782814\n",
      "At epoch 3 the training accuracy is 0.528\n",
      "At epoch 3 :\n",
      "The test loss is 1.1238963603973389\n",
      "The test accuracy is 0.552\n",
      "[Epoch 4, Batch 0/1000]:  [Loss: 0.74]\n",
      "[Epoch 4, Batch 250/1000]:  [Loss: 0.52]\n",
      "[Epoch 4, Batch 500/1000]:  [Loss: 0.53]\n",
      "[Epoch 4, Batch 750/1000]:  [Loss: 1.13]\n",
      "At epoch 4 the training loss is 1.037973179012537\n",
      "At epoch 4 the training accuracy is 0.536\n",
      "At epoch 4 :\n",
      "The test loss is 0.967235803604126\n",
      "The test accuracy is 0.556\n",
      "[Epoch 5, Batch 0/1000]:  [Loss: 0.99]\n",
      "[Epoch 5, Batch 250/1000]:  [Loss: 0.76]\n",
      "[Epoch 5, Batch 500/1000]:  [Loss: 0.62]\n",
      "[Epoch 5, Batch 750/1000]:  [Loss: 0.37]\n",
      "At epoch 5 the training loss is 0.9039330210387707\n",
      "At epoch 5 the training accuracy is 0.537\n",
      "At epoch 5 :\n",
      "The test loss is 0.8718267679214478\n",
      "The test accuracy is 0.562\n",
      "[Epoch 6, Batch 0/1000]:  [Loss: 0.50]\n",
      "[Epoch 6, Batch 250/1000]:  [Loss: 0.32]\n",
      "[Epoch 6, Batch 500/1000]:  [Loss: 1.42]\n",
      "[Epoch 6, Batch 750/1000]:  [Loss: 1.37]\n",
      "At epoch 6 the training loss is 0.8118880192041397\n",
      "At epoch 6 the training accuracy is 0.544\n",
      "At epoch 6 :\n",
      "The test loss is 0.8005599975585938\n",
      "The test accuracy is 0.573\n",
      "[Epoch 7, Batch 0/1000]:  [Loss: 1.14]\n",
      "[Epoch 7, Batch 250/1000]:  [Loss: 0.39]\n",
      "[Epoch 7, Batch 500/1000]:  [Loss: 0.90]\n",
      "[Epoch 7, Batch 750/1000]:  [Loss: 0.56]\n",
      "At epoch 7 the training loss is 0.7431173002421856\n",
      "At epoch 7 the training accuracy is 0.559\n",
      "At epoch 7 :\n",
      "The test loss is 0.7538601756095886\n",
      "The test accuracy is 0.591\n",
      "[Epoch 8, Batch 0/1000]:  [Loss: 0.37]\n",
      "[Epoch 8, Batch 250/1000]:  [Loss: 0.56]\n",
      "[Epoch 8, Batch 500/1000]:  [Loss: 1.02]\n",
      "[Epoch 8, Batch 750/1000]:  [Loss: 0.38]\n",
      "At epoch 8 the training loss is 0.6909148398935795\n",
      "At epoch 8 the training accuracy is 0.575\n",
      "At epoch 8 :\n",
      "The test loss is 0.7192325592041016\n",
      "The test accuracy is 0.608\n",
      "[Epoch 9, Batch 0/1000]:  [Loss: 0.38]\n",
      "[Epoch 9, Batch 250/1000]:  [Loss: 0.68]\n",
      "[Epoch 9, Batch 500/1000]:  [Loss: 0.32]\n",
      "[Epoch 9, Batch 750/1000]:  [Loss: 0.33]\n",
      "At epoch 9 the training loss is 0.6498245447278023\n",
      "At epoch 9 the training accuracy is 0.588\n",
      "At epoch 9 :\n",
      "The test loss is 0.6873271465301514\n",
      "The test accuracy is 0.615\n",
      "[Epoch 10, Batch 0/1000]:  [Loss: 1.87]\n",
      "[Epoch 10, Batch 250/1000]:  [Loss: 0.34]\n",
      "[Epoch 10, Batch 500/1000]:  [Loss: 0.76]\n",
      "[Epoch 10, Batch 750/1000]:  [Loss: 0.44]\n",
      "At epoch 10 the training loss is 0.6141012817025184\n",
      "At epoch 10 the training accuracy is 0.603\n",
      "At epoch 10 :\n",
      "The test loss is 0.6650142669677734\n",
      "The test accuracy is 0.621\n",
      "[Epoch 11, Batch 0/1000]:  [Loss: 0.50]\n",
      "[Epoch 11, Batch 250/1000]:  [Loss: 0.43]\n",
      "[Epoch 11, Batch 500/1000]:  [Loss: 0.36]\n",
      "[Epoch 11, Batch 750/1000]:  [Loss: 0.33]\n",
      "At epoch 11 the training loss is 0.5848580068349838\n",
      "At epoch 11 the training accuracy is 0.62\n",
      "At epoch 11 :\n",
      "The test loss is 0.6447170972824097\n",
      "The test accuracy is 0.637\n",
      "[Epoch 12, Batch 0/1000]:  [Loss: 0.47]\n",
      "[Epoch 12, Batch 250/1000]:  [Loss: 0.33]\n",
      "[Epoch 12, Batch 500/1000]:  [Loss: 1.08]\n",
      "[Epoch 12, Batch 750/1000]:  [Loss: 0.51]\n",
      "At epoch 12 the training loss is 0.560254512578249\n",
      "At epoch 12 the training accuracy is 0.638\n",
      "At epoch 12 :\n",
      "The test loss is 0.6283165812492371\n",
      "The test accuracy is 0.659\n",
      "[Epoch 13, Batch 0/1000]:  [Loss: 0.35]\n",
      "[Epoch 13, Batch 250/1000]:  [Loss: 0.39]\n",
      "[Epoch 13, Batch 500/1000]:  [Loss: 0.39]\n",
      "[Epoch 13, Batch 750/1000]:  [Loss: 0.33]\n",
      "At epoch 13 the training loss is 0.5377578214406967\n",
      "At epoch 13 the training accuracy is 0.657\n",
      "At epoch 13 :\n",
      "The test loss is 0.6137158274650574\n",
      "The test accuracy is 0.68\n",
      "[Epoch 14, Batch 0/1000]:  [Loss: 0.46]\n",
      "[Epoch 14, Batch 250/1000]:  [Loss: 0.29]\n",
      "[Epoch 14, Batch 500/1000]:  [Loss: 1.57]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bfa62233e64b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                      \u001b[0maux_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                      \u001b[0msub_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSUB_CRITERION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                      weights_loss = WEIGHTS_LOSS)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mrun_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{0}_{1}_{2}_{3}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_outer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_outer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_outer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_inner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/EPFL/Master1/Deep Learning/Projects1/DeepLearning/project_1/train/train.py\u001b[0m in \u001b[0;36mtrain_siamese\u001b[0;34m(model, dataloader, test_dataloader, epochs, final_criterion, learning_rate, aux_loss, sub_criterion, weights_loss)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m#update the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/Python/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models={}\n",
    "\n",
    "for nb_outer in NB_HIDDENS:\n",
    "    for hidden_outer in HIDDEN_LAYERS:\n",
    "        for nb_inner in NB_HIDDENS:\n",
    "            for hidden_inner in HIDDEN_LAYERS:\n",
    "                inner_model = OscarNet(nb_inner, hidden_inner)\n",
    "                outer_model = LeonardNet(nb_outer, inner_model, hidden_outer)\n",
    "                \n",
    "                tr_loss, tr_acc, tr_loss_l, tr_loss_r, te_loss, te_acc, te_loss_l, te_loss_r = train_siamese(model = outer_model,\n",
    "                                     dataloader = train_dataloader,\n",
    "                                     test_dataloader = test_dataloader,\n",
    "                                     epochs = EPOCHS,\n",
    "                                     final_criterion = FINAL_CRITERION, \n",
    "                                     learning_rate = LEARNING_RATE,\n",
    "                                     aux_loss = True,\n",
    "                                     sub_criterion = SUB_CRITERION, \n",
    "                                     weights_loss = WEIGHTS_LOSS)\n",
    "                \n",
    "                run_string = \"{0}_{1}_{2}_{3}\".format(nb_outer, hidden_outer, nb_inner, hidden_inner)\n",
    "                \n",
    "                models[run_string] = {\n",
    "                    'tr_loss' : tr_loss,\n",
    "                    'tr_acc' : tr_acc,\n",
    "                    'tr_loss_l' : tr_loss_l,\n",
    "                    'tr_loss_r' : tr_loss_r,\n",
    "                    'te_loss' : te_loss,\n",
    "                    'te_acc' : te_acc,\n",
    "                    'te_loss_l' : te_loss_l,\n",
    "                    'te_loss_r' : te_loss_r\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nb_outer in NB_HIDDENS:\n",
    "    for hidden_outer in HIDDEN_LAYERS:\n",
    "        for nb_inner in NB_HIDDENS:\n",
    "            for hidden_inner in HIDDEN_LAYERS:\n",
    "                run_string = \"{0}_{1}_{2}_{3}\".format(nb_outer, hidden_outer, nb_inner, hidden_inner)\n",
    "                \n",
    "                model = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
